{
  
    
        "post0": {
            "title": "Coronavirus Brasil vs Mundo - Gráficos Interativos",
            "content": "Fonte: https://opendata.ecdc.europa.eu/covid19/casedistribution/csv . Gráficos de contaminação . Os gráficos a seguir apresentam curvas de contaminação de diversos países. Foram criados com o intuito de comparar estratégias de combate à disseminação do vírus. É importante notar que as curvas de contaminação estão amplamente relacionadas à quantidade de testes que os países tem realizado. A seção contem duas aproximações e duas versões do gáfico completo: nas escalas aritmética e logarítmica. . . . . . Contaminação Relativa . Essa seção conta com gráficos em que o número de casos é dívidido pela população dos países para que se tenha uma ideia da proporção de infectados por país. . . . . . Mortes . Aqui, os gráficos das curvas de mortes em uma aproximação de até 500 e, posteriormente, os completos, nas escalas aritmética e logarítmica. . . . . . . . Letalidade . O gráfco a seguir aponta o número de mortes dividido pelo número de casos confirmados. É importantíssimo notar a grande dependência desses números da quantidade de testes disponíveis. Quanto mais testes realizados, mais confiáveis os dados. . . . O gráfico abaixo representa uma estimativa simples da quantidade de casos atualmente no Brasil. Uma vez que a baixa quantidade de testes tem levado os números a uma subnotificação, o cálculo foi realizado com base no número de óbitos registrados por COVID-19 no Brasil e na taxa da Alemanha, país que tem testado massivamente sua população. Desse modo os números são os seguintes: . Número atual de casos registrados no Brasil hoje: 553 Estimativa de casos no Brasil hoje caso a letalidade seja próxima à da Alemanha: 12056 Estimativa de casos no Brasil hoje caso a letalidade seja próxima à da Coréia do Sul: 34135 . . .",
            "url": "https://covid19graficos.github.io/relatorio/coronavirus/2020/04/07/corona-mundo-interativo.html",
            "relUrl": "/coronavirus/2020/04/07/corona-mundo-interativo.html",
            "date": " • Apr 7, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Coronavirus Brasil - Gráficos interativos",
            "content": "Gráficos de contaminação . Casos novos no país. . . . Os gráficos a seguir apresentam curvas de contaminação dos estados brasileiros. É importante notar que as curvas de contaminação estão amplamente relacionadas à quantidade de testes que os países tem realizado. Até o momento estarão apenas na escala aritmética. . . . Essa seção conta com gráficos em que o número de casos é dívidido pela população dos estados para que se tenha uma ideia da proporção de infectados por país. . . . O gráfico a seguir é um comparativo de casos totais por estado no Brasil. . . . O gráfico a seguir é um comparativo a proporção de habitantes infectados por estado no Brasil. . . . Curvas de contaminação por regiões . Comparações entre as regiões do Brasil. Primeiramente uma soma dos casos por regiões e, posteriormente, uma comparação entre os estados das regiões. . . . . . . . . . . . . . . . . . . . . . . . Óbitos . /usr/local/lib/python3.6/dist-packages/plotly/graph_objs/_deprecations.py:385: DeprecationWarning: plotly.graph_objs.Line is deprecated. Please replace it with one of the following more specific types - plotly.graph_objs.scatter.Line - plotly.graph_objs.layout.shape.Line - etc. . . . Comparações entre as regiões do Brasil. Primeiramente uma soma dos casos por regiões e, posteriormente, uma comparação entre os estados das regiões. . . . Óbitos por regiões . . . . . . . . . . . . . Letalidade por estado brasileiro . . . Capitais brasileiras . Comparações entre as capitais de estados do Brasil . . . 200 cidades com maiores números de casos . Estado Cidade Casos Mortes . date . 2020-04-06 SP | São Paulo | 3754 | 244.0 | . 2020-04-06 RJ | Rio de Janeiro | 1110 | 47.0 | . 2020-04-06 DF | Brasília | 485 | 10.0 | . 2020-04-06 AM | Manaus | 473 | 11.0 | . 2020-04-06 MG | Belo Horizonte | 264 | 4.0 | . 2020-04-06 BA | Salvador | 263 | 8.0 | . 2020-04-06 RS | Porto Alegre | 253 | 5.0 | . 2020-04-06 PR | Curitiba | 175 | 3.0 | . 2020-04-06 MA | São Luís | 152 | 4.0 | . 2020-04-06 PE | Recife | 146 | 16.0 | . 2020-04-06 SC | Florianópolis | 99 | 2.0 | . 2020-04-06 RJ | Niterói | 92 | 2.0 | . 2020-04-06 SP | São Bernardo do Campo | 89 | 5.0 | . 2020-04-06 SP | Santos | 75 | 2.0 | . 2020-04-06 SP | Importados/Indefinidos | 75 | 0.0 | . 2020-04-06 SP | Santo André | 74 | 3.0 | . 2020-04-06 GO | Goiânia | 73 | 4.0 | . 2020-04-06 SP | Osasco | 71 | 3.0 | . 2020-04-06 PA | Belém | 68 | 3.0 | . 2020-04-06 ES | Vitória | 64 | 2.0 | . 2020-04-06 SP | Guarulhos | 63 | 6.0 | . 2020-04-06 ES | Vila Velha | 62 | 2.0 | . 2020-04-06 RJ | Volta Redonda | 55 | 2.0 | . 2020-04-06 SC | Blumenau | 52 | 0.0 | . 2020-04-06 SP | São José dos Campos | 48 | 0.0 | . 2020-04-06 PR | Londrina | 47 | 1.0 | . 2020-04-06 SP | Taboão da Serra | 45 | 3.0 | . 2020-04-06 MS | Campo Grande | 44 | 0.0 | . 2020-04-06 MT | Cuiabá | 43 | 0.0 | . 2020-04-06 MG | Juiz de Fora | 39 | 0.0 | . 2020-04-06 AC | Rio Branco | 39 | 1.0 | . 2020-04-06 SP | São Caetano do Sul | 39 | 1.0 | . 2020-04-06 MG | Nova Lima | 37 | 0.0 | . 2020-04-06 PR | Cascavel | 36 | 1.0 | . 2020-04-06 RR | Boa Vista | 36 | 1.0 | . 2020-04-06 AP | Macapá | 35 | 1.0 | . 2020-04-06 MG | Uberlândia | 35 | 2.0 | . 2020-04-06 ES | Serra | 33 | 1.0 | . 2020-04-06 BA | Feira de Santana | 31 | 0.0 | . 2020-04-06 SP | Barueri | 31 | 1.0 | . 2020-04-06 SP | Cotia | 31 | 3.0 | . 2020-04-06 RJ | Nova Iguaçu | 29 | 2.0 | . 2020-04-06 SP | Campinas | 28 | 4.0 | . 2020-04-06 SP | Ribeirão Preto | 28 | 1.0 | . 2020-04-06 AM | Manacapuru | 28 | 3.0 | . 2020-04-06 SC | Criciúma | 27 | 1.0 | . 2020-04-06 PB | João Pessoa | 27 | 2.0 | . 2020-04-06 RS | Bagé | 26 | 0.0 | . 2020-04-06 SP | Santana de Parnaíba | 25 | 0.0 | . 2020-04-06 SC | Joinville | 25 | 1.0 | . 2020-04-06 PR | Foz do Iguaçu | 25 | 0.0 | . 2020-04-06 SP | Diadema | 25 | 1.0 | . 2020-04-06 PR | Maringá | 23 | 2.0 | . 2020-04-06 AL | Maceió | 22 | 2.0 | . 2020-04-06 PI | Teresina | 22 | 2.0 | . 2020-04-06 SP | Caieiras | 22 | 4.0 | . 2020-04-06 RS | Caxias do Sul | 21 | 0.0 | . 2020-04-06 RJ | Duque de Caxias | 21 | 3.0 | . 2020-04-06 SC | Itajaí | 21 | 1.0 | . 2020-04-06 RS | Novo Hamburgo | 20 | 2.0 | . 2020-04-06 SP | Embu das Artes | 20 | 1.0 | . 2020-04-06 SC | Tubarão | 19 | 0.0 | . 2020-04-06 BA | Lauro de Freitas | 19 | 0.0 | . 2020-04-06 SP | Mogi das Cruzes | 19 | 1.0 | . 2020-04-06 SP | Mauá | 18 | 0.0 | . 2020-04-06 ES | Cariacica | 17 | 0.0 | . 2020-04-06 SC | São José | 17 | 1.0 | . 2020-04-06 RJ | Petrópolis | 16 | 1.0 | . 2020-04-06 SC | Braço do Norte | 16 | 0.0 | . 2020-04-06 SP | Carapicuíba | 16 | 1.0 | . 2020-04-06 SP | Ferraz de Vasconcelos | 16 | 0.0 | . 2020-04-06 PE | Jaboatão dos Guararapes | 15 | 1.0 | . 2020-04-06 MG | Divinópolis | 15 | 0.0 | . 2020-04-06 RJ | Itaboraí | 14 | 2.0 | . 2020-04-06 RJ | Belford Roxo | 14 | 3.0 | . 2020-04-06 RO | Porto Velho | 14 | 1.0 | . 2020-04-06 BA | Ilhéus | 14 | 0.0 | . 2020-04-06 MG | Contagem | 13 | 0.0 | . 2020-04-06 TO | Palmas | 13 | 0.0 | . 2020-04-06 PR | Campo Mourão | 13 | 3.0 | . 2020-04-06 RJ | São Gonçalo | 13 | 1.0 | . 2020-04-06 SP | São José do Rio Preto | 13 | 0.0 | . 2020-04-06 SP | Itaquaquecetuba | 12 | 0.0 | . 2020-04-06 SC | Balneário Camboriú | 12 | 0.0 | . 2020-04-06 RS | Canoas | 11 | 0.0 | . 2020-04-06 MG | Uberaba | 11 | 0.0 | . 2020-04-06 RS | Passo Fundo | 11 | 0.0 | . 2020-04-06 SP | Itapevi | 11 | 1.0 | . 2020-04-06 PA | Ananindeua | 11 | 0.0 | . 2020-04-06 PE | Olinda | 11 | 3.0 | . 2020-04-06 PR | Cianorte | 11 | 1.0 | . 2020-04-06 RJ | São João de Meriti | 10 | 1.0 | . 2020-04-06 BA | Porto Seguro | 10 | 0.0 | . 2020-04-06 SC | Importados/Indefinidos | 10 | 0.0 | . 2020-04-06 SP | Sorocaba | 10 | 2.0 | . 2020-04-06 RS | Gravataí | 10 | 0.0 | . 2020-04-06 SP | Suzano | 9 | 0.0 | . 2020-04-06 PR | Campo Largo | 9 | 0.0 | . 2020-04-06 SP | Itapecerica da Serra | 9 | 1.0 | . 2020-04-06 MG | Importados/Indefinidos | 9 | 0.0 | . 2020-04-06 RS | Bento Gonçalves | 9 | 0.0 | . 2020-04-06 RS | Torres | 9 | 0.0 | . 2020-04-06 AC | Acrelândia | 9 | 0.0 | . 2020-04-06 BA | Camaçari | 9 | 0.0 | . 2020-04-06 SP | Franco da Rocha | 8 | 1.0 | . 2020-04-06 SC | Antônio Carlos | 8 | 1.0 | . 2020-04-06 RJ | Maricá | 8 | 1.0 | . 2020-04-06 SP | Piracicaba | 8 | 0.0 | . 2020-04-06 ES | Linhares | 8 | 0.0 | . 2020-04-06 PR | Importados/Indefinidos | 8 | 0.0 | . 2020-04-06 GO | Rio Verde | 8 | 0.0 | . 2020-04-06 SP | Araçatuba | 8 | 0.0 | . 2020-04-06 SP | Francisco Morato | 8 | 1.0 | . 2020-04-06 MA | São José de Ribamar | 8 | 0.0 | . 2020-04-06 AM | Itacoatiara | 8 | 0.0 | . 2020-04-06 BA | Itabuna | 8 | 0.0 | . 2020-04-06 GO | Anápolis | 8 | 0.0 | . 2020-04-06 RS | São Leopoldo | 8 | 0.0 | . 2020-04-06 RS | Lajeado | 8 | 0.0 | . 2020-04-06 PE | São Lourenço da Mata | 7 | 3.0 | . 2020-04-06 SP | Botucatu | 7 | 0.0 | . 2020-04-06 PE | Fernando de Noronha | 7 | 0.0 | . 2020-04-06 PR | Pinhais | 7 | 0.0 | . 2020-04-06 SP | Jundiaí | 7 | 0.0 | . 2020-04-06 PR | São José dos Pinhais | 7 | 0.0 | . 2020-04-06 PE | Camaragibe | 7 | 1.0 | . 2020-04-06 PR | Arapongas | 7 | 0.0 | . 2020-04-06 SP | Atibaia | 7 | 0.0 | . 2020-04-06 RS | Sant&#39;Ana do Livramento | 7 | 0.0 | . 2020-04-06 AM | Santo Antônio do Içá | 7 | 0.0 | . 2020-04-06 RS | Marau | 7 | 0.0 | . 2020-04-06 RJ | Teresópolis | 7 | 0.0 | . 2020-04-06 SC | Camboriú | 7 | 0.0 | . 2020-04-06 RS | Viamão | 7 | 0.0 | . 2020-04-06 RJ | Macaé | 6 | 0.0 | . 2020-04-06 SP | Bauru | 6 | 1.0 | . 2020-04-06 MT | Rondonópolis | 6 | 0.0 | . 2020-04-06 PE | Importados/Indefinidos | 6 | 1.0 | . 2020-04-06 MS | Dourados | 6 | 0.0 | . 2020-04-06 BA | Ipiaú | 6 | 0.0 | . 2020-04-06 GO | Luziânia | 6 | 1.0 | . 2020-04-06 SP | Mairiporã | 6 | 2.0 | . 2020-04-06 SP | Arujá | 6 | 1.0 | . 2020-04-06 MG | Betim | 6 | 0.0 | . 2020-04-06 SC | Chapecó | 6 | 0.0 | . 2020-04-06 SC | Imbituba | 6 | 0.0 | . 2020-04-06 SP | São Vicente | 6 | 0.0 | . 2020-04-06 GO | Valparaíso de Goiás | 6 | 0.0 | . 2020-04-06 RJ | Mesquita | 6 | 1.0 | . 2020-04-06 PR | Telêmaco Borba | 6 | 0.0 | . 2020-04-06 SC | Jaraguá do Sul | 6 | 0.0 | . 2020-04-06 MS | Batayporã | 5 | 1.0 | . 2020-04-06 MT | Várzea Grande | 5 | 0.0 | . 2020-04-06 SC | Siderópolis | 5 | 0.0 | . 2020-04-06 PA | Santarém | 5 | 1.0 | . 2020-04-06 BA | Alagoinhas | 5 | 0.0 | . 2020-04-06 PE | Cabo de Santo Agostinho | 5 | 1.0 | . 2020-04-06 PE | Paulista | 5 | 0.0 | . 2020-04-06 BA | Brumado | 5 | 0.0 | . 2020-04-06 MG | Patrocínio | 5 | 0.0 | . 2020-04-06 PR | Ponta Grossa | 5 | 0.0 | . 2020-04-06 RJ | Magé | 5 | 0.0 | . 2020-04-06 SC | Gaspar | 5 | 1.0 | . 2020-04-06 RS | Pelotas | 5 | 0.0 | . 2020-04-06 MG | Pouso Alegre | 5 | 0.0 | . 2020-04-06 PR | Paranaguá | 5 | 0.0 | . 2020-04-06 AL | Importados/Indefinidos | 5 | 0.0 | . 2020-04-06 MG | Lagoa da Prata | 5 | 0.0 | . 2020-04-06 SC | Gravatal | 4 | 0.0 | . 2020-04-06 RS | Tabaí | 4 | 0.0 | . 2020-04-06 SP | Poá | 4 | 0.0 | . 2020-04-06 RS | Ivoti | 4 | 1.0 | . 2020-04-06 MA | Paço do Lumiar | 4 | 0.0 | . 2020-04-06 SC | Lages | 4 | 0.0 | . 2020-04-06 SP | Praia Grande | 4 | 0.0 | . 2020-04-06 MT | Sinop | 4 | 0.0 | . 2020-04-06 MT | Tangará da Serra | 4 | 0.0 | . 2020-04-06 RS | Farroupilha | 4 | 0.0 | . 2020-04-06 SC | Navegantes | 4 | 0.0 | . 2020-04-06 SP | Ribeirão Pires | 4 | 0.0 | . 2020-04-06 BA | Itororó | 4 | 0.0 | . 2020-04-06 SC | Porto Belo | 4 | 0.0 | . 2020-04-06 MG | Varginha | 4 | 0.0 | . 2020-04-06 PR | Medianeira | 4 | 0.0 | . 2020-04-06 BA | Santa Cruz Cabrália | 4 | 0.0 | . 2020-04-06 SP | Vargem Grande Paulista | 4 | 1.0 | . 2020-04-06 ES | São Mateus | 4 | 1.0 | . 2020-04-06 ES | Aracruz | 4 | 0.0 | . 2020-04-06 RJ | Queimados | 4 | 0.0 | . 2020-04-06 RS | Campo Bom | 4 | 0.0 | . 2020-04-06 BA | Vitória da Conquista | 4 | 0.0 | . 2020-04-06 RS | Cachoeirinha | 4 | 0.0 | . 2020-04-06 SC | Araranguá | 4 | 0.0 | . 2020-04-06 SP | Araraquara | 4 | 0.0 | . 2020-04-06 RS | Alvorada | 4 | 0.0 | . 2020-04-06 BA | Prado | 4 | 0.0 | . 2020-04-06 PR | Colombo | 4 | 0.0 | . 2020-04-06 RJ | Nilópolis | 4 | 0.0 | . 2020-04-06 MG | Patos de Minas | 4 | 0.0 | . 2020-04-06 RJ | Nova Friburgo | 4 | 0.0 | . casos_mar5.columns . Index([&#39;regiao&#39;, &#39;estado&#39;, &#39;data&#39;, &#39;casosNovos&#39;, &#39;casosAcumulados&#39;, &#39;obitosNovos&#39;, &#39;obitosAcumulados&#39;, &#39;população&#39;, &#39;Relativa&#39;], dtype=&#39;object&#39;) .",
            "url": "https://covid19graficos.github.io/relatorio/coronavirus/2020/04/07/corona-brasil-interativo.html",
            "relUrl": "/coronavirus/2020/04/07/corona-brasil-interativo.html",
            "date": " • Apr 7, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Projeção do Covid-19 no Brasil",
            "content": "Gr&#225;ficos . Proje&#231;&#227;o do n&#250;mero de casos no Brasil para a pr&#243;xima semana . Proje&#231;&#227;o do n&#250;mero de &#243;bitos no Brasil para a pr&#243;xima semana . N&#250;mero de Casos Novos Confirmados . N&#250;meros de &#211;bitos Novos . Agradecimentos e Contribui&#231;&#245;es . Ívi M. de Carvalho, D. Sc. | . (Para Programadores) C&#243;digo para gera&#231;&#227;o dos gr&#225;ficos . NOTA: O resto desse relatório está focado no desenvolvimento dos gráficos mostrados acima. Somente é relevante caso tenha interesse em Python e Data Analysis . Neste relatório vamos desenvolver em Python uma projeção que pode ser atualizada em tempo real do número de casos de Covid-19 no Brasil. Devido à sua natureza com crescimento exponencial, podemos fazer projeções de curto/médio prazo de acordo com tal tendência. É importante salientar que não existe nenhuma exponencial pura. Em algum momento haverá um ponto de inflexão (quando o número de casos começa a diminuir) e esta exponencial se tornará um sigmóide (como já é o caso da China). Portanto, como não há como prever quando ocorrerá essa inflexão, as projeções somente são úteis para curto e médio prazo. Sem mais delongas, vamos começar! Primeiramente, todas as importações que serão utilizadas: . # Todas as importações vem aqui import numpy as np import pandas as pd; import matplotlib.pyplot as plt import seaborn as sns; from sklearn.linear_model import LinearRegression from datetime import date . /usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead. import pandas.util.testing as tm . E também parâmetros: . FIGSIZE = (8,4) . Em seguida, vamos importar a base de dados disponibilizada pelo repositório da John Hopkins University. Há duas bases relevantes para nosso caso, uma com o histórico do número de casos e outro com o histório do número de mortes (ambos obtido a partir dos relatórios diários da OMS). . CASOS_URL = &#39;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv&#39; MORTES_URL = &#39;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv&#39; . Ambos são urls diretas para arquivos .CSV, portanto podemos importá-los diretamente para a biblioteca Pandas do Python, sem precisar baixá-los: . casos = pd.read_csv(CASOS_URL) mortes = pd.read_csv(MORTES_URL) . Vamos visualizar o cabeçalho de cada um: . casos.head() . Province/State Country/Region Lat Long 1/22/20 1/23/20 1/24/20 1/25/20 1/26/20 1/27/20 1/28/20 1/29/20 1/30/20 1/31/20 2/1/20 2/2/20 2/3/20 2/4/20 2/5/20 2/6/20 2/7/20 2/8/20 2/9/20 2/10/20 2/11/20 2/12/20 2/13/20 2/14/20 2/15/20 2/16/20 2/17/20 2/18/20 2/19/20 2/20/20 2/21/20 2/22/20 2/23/20 2/24/20 2/25/20 2/26/20 2/27/20 2/28/20 2/29/20 3/1/20 3/2/20 3/3/20 3/4/20 3/5/20 3/6/20 3/7/20 3/8/20 3/9/20 3/10/20 3/11/20 3/12/20 3/13/20 3/14/20 3/15/20 3/16/20 3/17/20 3/18/20 3/19/20 3/20/20 3/21/20 3/22/20 3/23/20 3/24/20 3/25/20 3/26/20 3/27/20 3/28/20 3/29/20 3/30/20 3/31/20 4/1/20 4/2/20 4/3/20 4/4/20 4/5/20 4/6/20 . 0 NaN | Afghanistan | 33.0000 | 65.0000 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 4 | 4 | 5 | 7 | 7 | 7 | 11 | 16 | 21 | 22 | 22 | 22 | 24 | 24 | 40 | 40 | 74 | 84 | 94 | 110 | 110 | 120 | 170 | 174 | 237 | 273 | 281 | 299 | 349 | 367 | . 1 NaN | Albania | 41.1533 | 20.1683 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 10 | 12 | 23 | 33 | 38 | 42 | 51 | 55 | 59 | 64 | 70 | 76 | 89 | 104 | 123 | 146 | 174 | 186 | 197 | 212 | 223 | 243 | 259 | 277 | 304 | 333 | 361 | 377 | . 2 NaN | Algeria | 28.0339 | 1.6596 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 3 | 5 | 12 | 12 | 17 | 17 | 19 | 20 | 20 | 20 | 24 | 26 | 37 | 48 | 54 | 60 | 74 | 87 | 90 | 139 | 201 | 230 | 264 | 302 | 367 | 409 | 454 | 511 | 584 | 716 | 847 | 986 | 1171 | 1251 | 1320 | 1423 | . 3 NaN | Andorra | 42.5063 | 1.5218 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 2 | 39 | 39 | 53 | 75 | 88 | 113 | 133 | 164 | 188 | 224 | 267 | 308 | 334 | 370 | 376 | 390 | 428 | 439 | 466 | 501 | 525 | . 4 NaN | Angola | -11.2027 | 17.8739 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 2 | 2 | 3 | 3 | 3 | 4 | 4 | 5 | 7 | 7 | 7 | 8 | 8 | 8 | 10 | 14 | 16 | . mortes.head() . Province/State Country/Region Lat Long 1/22/20 1/23/20 1/24/20 1/25/20 1/26/20 1/27/20 1/28/20 1/29/20 1/30/20 1/31/20 2/1/20 2/2/20 2/3/20 2/4/20 2/5/20 2/6/20 2/7/20 2/8/20 2/9/20 2/10/20 2/11/20 2/12/20 2/13/20 2/14/20 2/15/20 2/16/20 2/17/20 2/18/20 2/19/20 2/20/20 2/21/20 2/22/20 2/23/20 2/24/20 2/25/20 2/26/20 2/27/20 2/28/20 2/29/20 3/1/20 3/2/20 3/3/20 3/4/20 3/5/20 3/6/20 3/7/20 3/8/20 3/9/20 3/10/20 3/11/20 3/12/20 3/13/20 3/14/20 3/15/20 3/16/20 3/17/20 3/18/20 3/19/20 3/20/20 3/21/20 3/22/20 3/23/20 3/24/20 3/25/20 3/26/20 3/27/20 3/28/20 3/29/20 3/30/20 3/31/20 4/1/20 4/2/20 4/3/20 4/4/20 4/5/20 4/6/20 . 0 NaN | Afghanistan | 33.0000 | 65.0000 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 2 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | 6 | 6 | 7 | 7 | 11 | . 1 NaN | Albania | 41.1533 | 20.1683 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 2 | 2 | 2 | 2 | 2 | 4 | 5 | 5 | 6 | 8 | 10 | 10 | 11 | 15 | 15 | 16 | 17 | 20 | 20 | 21 | . 2 NaN | Algeria | 28.0339 | 1.6596 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 2 | 3 | 4 | 4 | 4 | 7 | 9 | 11 | 15 | 17 | 17 | 19 | 21 | 25 | 26 | 29 | 31 | 35 | 44 | 58 | 86 | 105 | 130 | 152 | 173 | . 3 NaN | Andorra | 42.5063 | 1.5218 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 3 | 3 | 3 | 6 | 8 | 12 | 14 | 15 | 16 | 17 | 18 | 21 | . 4 NaN | Angola | -11.2027 | 17.8739 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | . Como para este relatório temos interesse em apenas dados do Brasil, vamos atribuir duas novas variáveis à ambos: . def filter_country(df, country): # Filtrar pais df = df[df[&#39;Country/Region&#39;]==country] # Remover colunas iniciais, manter somente as datas df = df.iloc[:, 4:] # Transpor df = df.T # Redefinir coluna df.columns = [country] # Definir index para Datetime df.index = pd.to_datetime(df.index) return df casos_brasil = filter_country(casos, &#39;Brazil&#39;) mortes_brasil = filter_country(mortes, &#39;Brazil&#39;) . Vamos ver como ficaram os novos dataframes: . casos_brasil.tail() . Brazil . 2020-04-02 8044 | . 2020-04-03 9056 | . 2020-04-04 10360 | . 2020-04-05 11130 | . 2020-04-06 12161 | . mortes_brasil.tail() . Brazil . 2020-04-02 324 | . 2020-04-03 359 | . 2020-04-04 445 | . 2020-04-05 486 | . 2020-04-06 564 | . Podemos facilmente também plotar tais dados para ver como estão: . casos_brasil.plot(title=&#39;Número de casos&#39;); . mortes_brasil.plot(title=&#39;Número de mortes&#39;); . Podemos conferir se o número de casos está se acelerando ou não plotando um gráfico de barras do número de casos por dia. Isso será importante para identificar a inflexão! . casos_novos_brasil = casos_brasil[1:]-casos_brasil[:-1].values casos_novos_brasil.tail() . Brazil . 2020-04-02 1208 | . 2020-04-03 1012 | . 2020-04-04 1304 | . 2020-04-05 770 | . 2020-04-06 1031 | . mortes_novas_brasil = mortes_brasil[1:]-mortes_brasil[:-1].values mortes_novas_brasil.tail() . Brazil . 2020-04-02 84 | . 2020-04-03 35 | . 2020-04-04 86 | . 2020-04-05 41 | . 2020-04-06 78 | . Em seguida vamos visualizar ambos em um gráfico de barras: . # Funcao personalizada def plot_bar_novos(df, title): df.index = df.index.strftime(&#39;%d/%m&#39;)#astype(&#39;str&#39;) ax = df.plot.bar( title=title, figsize=FIGSIZE ) _=plt.xticks(rotation=50) return ax . primeiro_caso_filtro = casos_novos_brasil.values&gt;0 ax=plot_bar_novos(casos_novos_brasil[primeiro_caso_filtro], title=&#39;Casos novos (sem acumular, a partir do primeiro caso)&#39;, ) . # Filtrar a partir do primeiro obito primeiro_obito_filtro = mortes_novas_brasil.values&gt;0 # Criar plot ax=plot_bar_novos(mortes_novas_brasil[primeiro_obito_filtro], title=&#39;Óbitos novos (sem acumular, a partir do primeiro óbito)&#39; ) . ax.figure.savefig(&#39;obitos_novos.png&#39;, dpi=300) . Vamos agora dar início à modelagem das projeções. Primeiramente, vamos fazer alguns plots em cima do log dos dados: . casos_brasil[&#39;Brazil&#39;].apply(np.log).plot(marker=&#39;o&#39;, linestyle=&#39;&#39;, title=&#39;Log do Número de casos&#39;); . mortes_brasil[&#39;Brazil&#39;].apply(np.log).plot(marker=&#39;o&#39;, linestyle=&#39;&#39;, title=&#39;Log do Número de Mortes&#39;); . casos_novos_brasil.apply(np.log).plot(marker=&#39;o&#39;, linestyle=&#39;&#39;, title=&#39;Log do número de casos novos&#39;); . mortes_novas_brasil.apply(np.log).plot(marker=&#39;o&#39;, linestyle=&#39;&#39;, title=&#39;Log de novas mortes&#39;); . Todas as curvas acima não representam uma reta perfeita, o que são ótimas notícias: Significa que talvez não esteja mais seguindo uma tendência exponencial. De qualquer forma, vou usar como ponto de partida uma regressão linear, apesar de haverem ressalvas sobre o uso dela. Por simplificação, vou começar com uma projeção do número total de casos e de mortes. Primeiramente, vou juntar todos os dados em um único dataframe: . brasil = pd.DataFrame({ &#39;Confirmados Cumulativo&#39;: casos_brasil[&#39;Brazil&#39;].values[1:], &#39;Confirmados Novos&#39;: casos_novos_brasil[&#39;Brazil&#39;].values, &#39;Mortes Cumulativa&#39;: mortes_brasil[&#39;Brazil&#39;].values[1:], &#39;Mortes Novas&#39;: mortes_novas_brasil[&#39;Brazil&#39;].values }) brasil.index = casos_novos_brasil.index brasil.tail() . Confirmados Cumulativo Confirmados Novos Mortes Cumulativa Mortes Novas . 2020-04-02 8044 | 1208 | 324 | 84 | . 2020-04-03 9056 | 1012 | 359 | 35 | . 2020-04-04 10360 | 1304 | 445 | 86 | . 2020-04-05 11130 | 770 | 486 | 41 | . 2020-04-06 12161 | 1031 | 564 | 78 | . Também podemos criar um dataframe com o log de todos os dados: . brasil_log = brasil.apply(np.log1p) brasil_log.tail() . Confirmados Cumulativo Confirmados Novos Mortes Cumulativa Mortes Novas . 2020-04-02 8.992806 | 7.097549 | 5.783825 | 4.442651 | . 2020-04-03 9.111293 | 6.920672 | 5.886104 | 3.583519 | . 2020-04-04 9.245804 | 7.173958 | 6.100319 | 4.465908 | . 2020-04-05 9.317489 | 6.647688 | 6.188264 | 3.737670 | . 2020-04-06 9.406072 | 6.939254 | 6.336826 | 4.369448 | . Vamos visualizar a distribuição de cada um e também scatter plots de cada um versus o outro: . pd.plotting.scatter_matrix(brasil_log, figsize = (14,8), diagonal = &#39;kde&#39;); . O plot acima fica um pouco enviesado pois há um grande acúmulo de zeros. Vamos filtrar as datas a partir do promeiro óbito: . primeiro_obito = brasil_log.index[brasil_log[&#39;Mortes Cumulativa&#39;]&gt;0][0] primeiro_obito_filtro = brasil_log.index&gt;=primeiro_obito primeiro_obito . Timestamp(&#39;2020-03-17 00:00:00&#39;) . Como é uma base bastante recente, vamos também pegar o primeiro caso: . primeiro_caso = brasil_log.index[brasil_log[&#39;Confirmados Cumulativo&#39;]&gt;0][0] primeiro_caso_filtro = brasil_log.index&gt;=primeiro_caso primeiro_caso . Timestamp(&#39;2020-02-26 00:00:00&#39;) . Vamos repetir o scatter matrix acima a partir dos filtros que definimos: . g = sns.pairplot(brasil[primeiro_obito_filtro], kind=&quot;reg&quot;) g.fig.tight_layout() g.fig.subplots_adjust(top=0.88) g.fig.suptitle(&#39;Grade de gráficos, dados a partir do primeiro óbito&#39;, y=0.92); . g = sns.pairplot(brasil[primeiro_caso_filtro], kind=&quot;reg&quot;) g.fig.suptitle(&#39;Scatter Matrix com filtro a partir do primeiro caso&#39;, y=1.08); . g = sns.pairplot(brasil_log[primeiro_obito_filtro], kind=&quot;reg&quot;) g.fig.suptitle(&#39;Scatter Matrix do Log dos dados com filtro a partir do primeiro óbito&#39;, y=1.08); . g = sns.pairplot(brasil_log[primeiro_obito_filtro], kind=&quot;reg&quot;) g.fig.suptitle(&#39;Scatter Matrix do Log dos dados com filtro a partir do primeiro óbito&#39;, y=1.08); . Os plots acima, talvez pareçam informação irrelevante, mas o fiz para ter uma ideia sobre a distribuição dos dados e se há alguma distribuição normal em algum caso, que justificaria o uso do desvio padrão (uma vez que o mesmo é em relação à distribuição normal). De qualquer forma, para manter as coisas simples inicialmente, vou manter meu plano inicial de criar uma projeção do número de casos incluindo o intervalo do desvio padrão. Então vamos começar pegando o as estatísticas filtrando a partir do primeiro caso: . std = brasil_log[primeiro_caso_filtro].std() . Visualizar um plot da tendência que vamos modelar: . brasil_log[primeiro_caso_filtro][&#39;Confirmados Cumulativo&#39;].plot() . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fc594259940&gt; . Em seguida ajustar uma regressão linear em cima do log: . def fitar(x, y): lr = LinearRegression() lr.fit(x,y) return lr x = np.arange(sum(primeiro_caso_filtro)).reshape(-1,1) y = brasil_log[primeiro_caso_filtro][&#39;Confirmados Cumulativo&#39;].values lr_casos = fitar(x, y) . def projetar(lr, x, y, plot=True): y_pred = lr.predict(x) if plot: plt.scatter(x, y) plt.plot(y_pred, &#39;r&#39;) plt.title(&quot;Projeção logarítmica&quot;) plt.show() plt.scatter(x, np.expm1(y)) plt.plot(np.expm1(y_pred), &#39;r&#39;) plt.title(&quot;Projeção exponencial&quot;) plt.show() return y_pred y_pred = projetar(lr_casos, x, y) . A projeção acima não ficou boa, vamos testar suavizar com um exponential moving average: . def generate_moving_average(data, mom=0.7): MOM = 0.7 rolling_mean = [data[0]] for d in data[1:]: rolling_mean.append(rolling_mean[-1]*MOM + (1-MOM)*d) return np.array(rolling_mean) def fitar_projetar(x, y, mom=None): if mom is not None: y_old = y y = generate_moving_average(y) lr = fitar(x, y) y_pred = projetar(lr, x, y, plot=not mom) # Plota se mom for nulo if mom is not None: y_pred_exp = np.expm1(y_pred) reversed_mv = [(rm-rm_*mom)/(1-mom) for rm, rm_ in zip(y_pred_exp[1:], y_pred_exp[:-1])] plt.scatter(x, np.expm1(y_old), label=&quot;Original&quot;) plt.scatter(x, np.expm1(y), label=&quot;Exp. Moving Average&quot;) plt.plot(y_pred_exp, &#39;r&#39;, label=&quot;Projeção do EMA&quot;) plt.plot(reversed_mv, label=&quot;EMA reverso para projeção real&quot;) plt.legend() plt.title(f&quot;Projeção com Exp. Moving Average (momentum = {mom})&quot;) plt.show() return y_pred y_pred = fitar_projetar(x, y, mom=0.5) . Também não ficou muito boa. Um dos motivos de estas funções não estarem se saindo bem é que o erro está sendo inferido na escala logarítmica, ou seja, enquanto estamos na escala logarítmica, o erro em termos absolutos é pequeno, no entanto, quando passamos à escala normal, o erro aumenta consideravelmente. Parra corrigir isso, precisamos ajustar uma função exponencial diretamente sem realizar a transformação logarítmica. Precisamos de uma função de custo que infira o erro diretamente da exponencial. Podemos fazer isso com o auxílio de otimizadores de redes neurais. Vamos também aproveitar para ajustar uma sigmóide. E aqui um detalhe: para quem é de machine learning, as boas práticas de seleção de modelos não se aplicam aqui (por exemplo, divisão treinamento e teste). Como os modelos a serem ajustados são bastante simples, não há a necessidade de reservar um conjunto de validação/teste. . # Creating a model from keras.models import Sequential; from keras.layers import Dense from keras import backend as K from keras.optimizers import Adam from keras.activations import sigmoid, elu def get_keras_model(lr=0.001, activation=&#39;exp&#39;): if activation==&#39;exp&#39;: def activ_func(x): return K.exp(x) - 1 elif activation==&#39;sigm&#39;: activ_func = sigmoid elif activation==&#39;elu&#39;: activ_func = elu # Usage model = Sequential(); model.add(Dense(1, input_dim=1, activation=activ_func)) model.compile(optimizer=Adam(lr=lr), loss=&#39;mean_squared_error&#39;) return model . Using TensorFlow backend. . # Definir entrada e saida x = np.arange(sum(primeiro_caso_filtro)).reshape(-1,1) y = brasil[primeiro_caso_filtro][&#39;Confirmados Cumulativo&#39;].values . # Preparar dados def preparar_dados(x, y): x_mean = x.mean() x_std = x.std() y_mean = y.mean() y_std = y.std() x_prep = (x-x_mean)/x_std y_prep = (y-y_mean)/y_std return x_prep, y_prep x_prep, y_prep = preparar_dados(x, y) . #hide_output model = get_keras_model(lr=0.1) model.fit(x_prep, y_prep, epochs=100, verbose=0); . from sklearn.metrics import r2_score . def projetar_keras(model, x, y, days_ahead=0, plot=True, model_func=&quot;exponencial&quot;, tipo=&#39;caso&#39;, exibir_pontos=False, anotar_dados_reais=True, dados_reais_step=2): title = f&#39;Projeção {model_func} de {tipo}s de Covid-19 no Brasil&#39; + f&#39; para os próximos {days_ahead} dias&#39; hoje = date.today() hoje = hoje.strftime(&quot;%d/%m&quot;) x_mean = x.mean() x_std = x.std() y_mean = y.mean() y_std = y.std() n_days = len(x) x_proj = np.arange(n_days+days_ahead).reshape(-1,1) x_prep = (x_proj-x_mean)/x_std y_prep = (y-y_mean)/y_std y_pred = model.predict(x_prep) y_pred = y_pred*y_std + y_mean #Reverse y_pred back y_pred = y_pred.astype(int) y_pred = np.clip(y_pred, 0, None) y_pred = y_pred.squeeze() #print(y) #print(y_pred) r2 = r2_score(y, y_pred[:-days_ahead]) if plot: fig = plt.figure(figsize=FIGSIZE) # Plotar projeção plt.plot(x_proj[-days_ahead-1:], y_pred[-days_ahead-1:], &#39;-&#39;, color=&#39;red&#39;, label=&#39;Projeção&#39;) # Plotar função if exibir_pontos: plt.plot(x_proj[:-days_ahead], y_pred[:-days_ahead], &#39;-&#39;, color=&#39;red&#39;, label=f&#39;Ajuste {model_func} (R²={r2:.2f})&#39;, alpha=0.4) #plt.scatter(x, y, label=&#39;Dados reais&#39;, color=&#39;orange&#39;) plt.plot(y, &#39;.&#39;, label=&#39;Dados reais&#39;) plt.title(title) for x_anot, y_anot in zip(x_proj[-days_ahead:], y_pred[-days_ahead:]): plt.annotate(y_anot, (x_anot, y_anot), ha=&#39;right&#39;, color=&#39;red&#39;) plt.annotate(f&#39;({hoje}): {y[-1]}&#39;, (x[-1], y[-1]), ha=&#39;right&#39;, color=&#39;black&#39;, textcoords=&quot;offset points&quot;, xytext=(-5,0)) if anotar_dados_reais: for x_anot, y_anot in zip(x[:-1:dados_reais_step], y[:-1:dados_reais_step]): plt.annotate(y_anot, (x_anot, y_anot), ha=&#39;right&#39;, color=&#39;midnightblue&#39;, textcoords=&quot;offset points&quot;, xytext=(-5,3) ) plt.grid(color=&#39;black&#39;, linestyle=&#39;--&#39;, linewidth=0.17) plt.legend() plt.xlabel(f&quot;Dias desde o primeiro {tipo} no Brasil&quot;) plt.ylabel(f&#39;{tipo.capitalize()}s confirmados acumulados&#39;) plt.xticks(x_proj[::2]) plt.show() return y_pred, fig . y_pred, fig = projetar_keras(model, x, y, days_ahead=7, exibir_pontos=True, anotar_dados_reais=False, dados_reais_step=3) . Por curiosidade, vamos testar ajustar um sigmóide: . #hide_output model = get_keras_model(lr=1, activation=&#39;sigm&#39;) model.fit(x_prep, y_prep, epochs=100, verbose=0); . y_pred, fig = projetar_keras(model, x, y, days_ahead=5, model_func=&#39;sigmóide&#39;, exibir_pontos=True) . Bem distante do esperado :) Vamos testar também o ELU: . #hide_output model = get_keras_model(lr=0.1, activation=&#39;elu&#39;) model.fit(x_prep, y_prep, epochs=100, verbose=0); . y_pred, fig = projetar_keras(model, x, y, days_ahead=7, model_func=&quot;ELU (Exp. Linear Unit)&quot;, exibir_pontos=True) . Um pouco melhor, mas neste caso com tendência linear. Vamos também replicar estes dois últimos para o número de óbitos. . # Definir entrada e saida x = np.arange(sum(primeiro_obito_filtro)).reshape(-1,1) y = brasil[primeiro_obito_filtro][&#39;Mortes Cumulativa&#39;].values x_prep, y_prep = preparar_dados(x, y) . #hide_output model = get_keras_model(lr=0.1, activation=&#39;exp&#39;) model.fit(x_prep, y_prep, epochs=100, verbose=0); . y_pred, fig = projetar_keras(model, x, y, days_ahead=7, model_func=&quot;exponencial&quot;, tipo=&#39;obito&#39;, exibir_pontos=True, anotar_dados_reais=False, dados_reais_step=3) . #hide_output model = get_keras_model(lr=0.1, activation=&#39;elu&#39;) model.fit(x_prep, y_prep, epochs=100, verbose=0); . y_pred, fig = projetar_keras(model, x, y, days_ahead=7, model_func=&quot;ELU (Exp. Linear Unit)&quot;, tipo=&#39;obito&#39;, exibir_pontos=True) .",
            "url": "https://covid19graficos.github.io/relatorio/coronavirus/2020/04/06/projecao-brasil.html",
            "relUrl": "/coronavirus/2020/04/06/projecao-brasil.html",
            "date": " • Apr 6, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Sobre este website . Este website foi criado utilizando fastpages no qual permite a conversão automática de arquivos do Jupyter notebook em páginas da web. Temos o objetivo de tornar análises comparativas do Brasil com o resto do mundo de maneira à melhor informar a população. Sugestões de relatórios podem ser submetidas em nosso repositório. . Desenvolvedores . Vinicius Bastos Gomes Linkedin: https://www.linkedin.com/in/vinicius-gomes-phd-490557163/ | Github: https://github.com/ViniciusBG | . | Fernando Marcos Wittmann LinkedIn: https://www.linkedin.com/in/fernandowittmann/ | GitHub: https://github.com/WittmannF | . | . Fontes . John Hopkins University: https://github.com/CSSEGISandData/COVID-19 | Brasil.io: https://brasil.io/dataset/covid19/boletim | Ministério da Saúde: https://covid.saude.gov.br/ | . As fontes de cada relatório podem também ser conferidas em nossos notebooks. .",
          "url": "https://covid19graficos.github.io/relatorio/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}