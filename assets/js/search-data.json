{
  
    
        "post0": {
            "title": "Coronavirus Brasil vs Mundo - Gráficos Interativos",
            "content": "Fonte: https://opendata.ecdc.europa.eu/covid19/casedistribution/csv . Gráficos de contaminação . . . . . Contaminação Relativa . . . . . Mortes . . . . . . . Letalidade . . . O gráfico abaixo representa uma estimativa simples da quantidade de casos atualmente no Brasil. Uma vez que a baixa quantidade de testes tem levado os números a uma subnotificação, o cálculo foi realizado com base no número de óbitos registrados por COVID-19 no Brasil e na taxa de letalidade de países como a Alemanha e a Coréia do Sul, países que tem testado massivamente sua população. Desse modo os números são os seguintes: . Número atual de casos registrados no Brasil hoje: 11130 Estimativa de casos no Brasil hoje caso a letalidade seja próxima à da Alemanha: 48600 Estimativa de casos no Brasil hoje caso a letalidade seja próxima à da Coréia do Sul: 80967 . . .",
            "url": "https://covid19graficos.github.io/relatorio/coronavirus/2020/04/06/corona-mundo-interativo.html",
            "relUrl": "/coronavirus/2020/04/06/corona-mundo-interativo.html",
            "date": " • Apr 6, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Coronavirus Brasil vs Mundo - Gráficos Estáticos",
            "content": "Fonte: https://opendata.ecdc.europa.eu/covid19/casedistribution/csv . Gráficos de contaminação . Contaminação Relativa . Óbitos . Letalidade .",
            "url": "https://covid19graficos.github.io/relatorio/coronavirus/2020/04/06/corona-mundo-estatico.html",
            "relUrl": "/coronavirus/2020/04/06/corona-mundo-estatico.html",
            "date": " • Apr 6, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Coronavirus Brasil - Gráficos interativos",
            "content": "Gráficos de contaminação . . . . . . . . . regioes = casos_mar5.groupby([&#39;data&#39;,&#39;regiao&#39;]).sum()[[&#39;casosAcumulados&#39;,&#39;obitosAcumulados&#39;]] regioes.reset_index(level=[0,1],inplace=True) regioes . data regiao casosAcumulados obitosAcumulados . 0 2020-03-12 | Centro-Oeste | 2 | 0 | . 1 2020-03-12 | Nordeste | 5 | 0 | . 2 2020-03-12 | Norte | 0 | 0 | . 3 2020-03-12 | Sudeste | 60 | 0 | . 4 2020-03-12 | Sul | 10 | 0 | . 5 2020-03-13 | Centro-Oeste | 5 | 0 | . 6 2020-03-13 | Nordeste | 6 | 0 | . 7 2020-03-13 | Norte | 0 | 0 | . 8 2020-03-13 | Sudeste | 75 | 0 | . 9 2020-03-13 | Sul | 12 | 0 | . 10 2020-03-14 | Centro-Oeste | 9 | 0 | . 11 2020-03-14 | Nordeste | 6 | 0 | . 12 2020-03-14 | Norte | 0 | 0 | . 13 2020-03-14 | Sudeste | 90 | 0 | . 14 2020-03-14 | Sul | 16 | 0 | . 15 2020-03-15 | Centro-Oeste | 11 | 0 | . 16 2020-03-15 | Nordeste | 7 | 0 | . 17 2020-03-15 | Norte | 1 | 0 | . 18 2020-03-15 | Sudeste | 163 | 0 | . 19 2020-03-15 | Sul | 18 | 0 | . 20 2020-03-16 | Centro-Oeste | 18 | 0 | . 21 2020-03-16 | Nordeste | 7 | 0 | . 22 2020-03-16 | Norte | 1 | 0 | . 23 2020-03-16 | Sudeste | 189 | 0 | . 24 2020-03-16 | Sul | 19 | 0 | . 25 2020-03-17 | Centro-Oeste | 32 | 0 | . 26 2020-03-17 | Nordeste | 30 | 0 | . 27 2020-03-17 | Norte | 1 | 0 | . 28 2020-03-17 | Sudeste | 205 | 1 | . 29 2020-03-17 | Sul | 23 | 0 | . 30 2020-03-18 | Centro-Oeste | 41 | 0 | . 31 2020-03-18 | Nordeste | 35 | 0 | . 32 2020-03-18 | Norte | 1 | 0 | . 33 2020-03-18 | Sudeste | 309 | 4 | . 34 2020-03-18 | Sul | 42 | 0 | . 35 2020-03-19 | Centro-Oeste | 61 | 0 | . 36 2020-03-19 | Nordeste | 90 | 0 | . 37 2020-03-19 | Norte | 8 | 0 | . 38 2020-03-19 | Sudeste | 391 | 6 | . 39 2020-03-19 | Sul | 71 | 0 | . 40 2020-03-20 | Centro-Oeste | 112 | 0 | . 41 2020-03-20 | Nordeste | 134 | 0 | . 42 2020-03-20 | Norte | 15 | 0 | . 43 2020-03-20 | Sudeste | 553 | 11 | . 44 2020-03-20 | Sul | 90 | 0 | . 45 2020-03-21 | Centro-Oeste | 138 | 0 | . 46 2020-03-21 | Nordeste | 168 | 0 | . 47 2020-03-21 | Norte | 26 | 0 | . 48 2020-03-21 | Sudeste | 642 | 18 | . 49 2020-03-21 | Sul | 154 | 0 | . 50 2020-03-22 | Centro-Oeste | 161 | 0 | . 51 2020-03-22 | Nordeste | 231 | 0 | . 52 2020-03-22 | Norte | 49 | 0 | . 53 2020-03-22 | Sudeste | 926 | 25 | . 54 2020-03-22 | Sul | 179 | 0 | . 55 2020-03-23 | Centro-Oeste | 179 | 0 | . 56 2020-03-23 | Nordeste | 308 | 0 | . 57 2020-03-23 | Norte | 59 | 0 | . 58 2020-03-23 | Sudeste | 1135 | 34 | . 59 2020-03-23 | Sul | 210 | 0 | . 60 2020-03-24 | Centro-Oeste | 217 | 0 | . 61 2020-03-24 | Nordeste | 354 | 0 | . 62 2020-03-24 | Norte | 82 | 0 | . 63 2020-03-24 | Sudeste | 1278 | 46 | . 64 2020-03-24 | Sul | 270 | 0 | . 65 2020-03-25 | Centro-Oeste | 221 | 0 | . 66 2020-03-25 | Nordeste | 390 | 1 | . 67 2020-03-25 | Norte | 105 | 1 | . 68 2020-03-25 | Sudeste | 1404 | 54 | . 69 2020-03-25 | Sul | 313 | 1 | . 70 2020-03-26 | Centro-Oeste | 275 | 1 | . 71 2020-03-26 | Nordeste | 457 | 6 | . 72 2020-03-26 | Norte | 126 | 1 | . 73 2020-03-26 | Sudeste | 1665 | 67 | . 74 2020-03-26 | Sul | 392 | 2 | . 75 2020-03-27 | Centro-Oeste | 318 | 1 | . 76 2020-03-27 | Nordeste | 539 | 7 | . 77 2020-03-27 | Norte | 145 | 1 | . 78 2020-03-27 | Sudeste | 1952 | 78 | . 79 2020-03-27 | Sul | 463 | 5 | . 80 2020-03-28 | Centro-Oeste | 360 | 1 | . 81 2020-03-28 | Nordeste | 623 | 10 | . 82 2020-03-28 | Norte | 184 | 1 | . 83 2020-03-28 | Sudeste | 2222 | 97 | . 84 2020-03-28 | Sul | 514 | 5 | . 85 2020-03-29 | Centro-Oeste | 399 | 2 | . 86 2020-03-29 | Nordeste | 720 | 13 | . 87 2020-03-29 | Norte | 227 | 1 | . 88 2020-03-29 | Sudeste | 2342 | 115 | . 89 2020-03-29 | Sul | 568 | 5 | . 90 2020-03-30 | Centro-Oeste | 435 | 2 | . 91 2020-03-30 | Nordeste | 790 | 17 | . 92 2020-03-30 | Norte | 254 | 1 | . 93 2020-03-30 | Sudeste | 2507 | 132 | . 94 2020-03-30 | Sul | 593 | 7 | . 95 2020-03-31 | Centro-Oeste | 470 | 5 | . 96 2020-03-31 | Nordeste | 875 | 22 | . 97 2020-03-31 | Norte | 294 | 4 | . 98 2020-03-31 | Sudeste | 3406 | 161 | . 99 2020-03-31 | Sul | 672 | 9 | . 100 2020-04-01 | Centro-Oeste | 504 | 5 | . 101 2020-04-01 | Nordeste | 1005 | 27 | . 102 2020-04-01 | Norte | 337 | 5 | . 103 2020-04-01 | Sudeste | 4223 | 195 | . 104 2020-04-01 | Sul | 765 | 9 | . 105 2020-04-02 | Centro-Oeste | 532 | 6 | . 106 2020-04-02 | Nordeste | 1180 | 43 | . 107 2020-04-02 | Norte | 377 | 5 | . 108 2020-04-02 | Sudeste | 4988 | 234 | . 109 2020-04-02 | Sul | 833 | 11 | . 110 2020-04-03 | Centro-Oeste | 594 | 9 | . 111 2020-04-03 | Nordeste | 1399 | 51 | . 112 2020-04-03 | Norte | 427 | 9 | . 113 2020-04-03 | Sudeste | 5658 | 276 | . 114 2020-04-03 | Sul | 978 | 14 | . 115 2020-04-04 | Centro-Oeste | 675 | 11 | . 116 2020-04-04 | Nordeste | 1642 | 59 | . 117 2020-04-04 | Norte | 527 | 16 | . 118 2020-04-04 | Sudeste | 6295 | 329 | . 119 2020-04-04 | Sul | 1139 | 17 | . 120 2020-04-05 | Centro-Oeste | 708 | 12 | . 121 2020-04-05 | Nordeste | 1880 | 78 | . 122 2020-04-05 | Norte | 651 | 19 | . 123 2020-04-05 | Sudeste | 6678 | 351 | . 124 2020-04-05 | Sul | 1213 | 26 | . Curvas de contaminação por regiões . . . . . . . . . . . . . . . . . . . . . . . Óbitos . . . Óbitos por regiões . . . . . . . . . . . Capitais brasileiras . . . Estado Cidade Casos Mortes . date . 2020-04-05 SP | São Paulo | 3612 | 220.0 | . 2020-04-05 RJ | Rio de Janeiro | 1068 | 42.0 | . 2020-04-05 DF | Brasília | 468 | 7.0 | . 2020-04-05 AM | Manaus | 379 | 11.0 | . 2020-04-05 MG | Belo Horizonte | 262 | 3.0 | . 2020-04-05 RS | Porto Alegre | 254 | 5.0 | . 2020-04-05 BA | Salvador | 244 | 7.0 | . 2020-04-05 PR | Curitiba | 172 | 0.0 | . 2020-04-05 PE | Recife | 139 | 14.0 | . 2020-04-05 MA | São Luís | 121 | 2.0 | . 2020-04-05 SC | Florianópolis | 94 | 2.0 | . 2020-04-05 RJ | Niterói | 87 | 2.0 | . 2020-04-05 SP | São Bernardo do Campo | 81 | 5.0 | . 2020-04-05 SP | Importados/Indefinidos | 73 | 0.0 | . 2020-04-05 GO | Goiânia | 73 | 2.0 | . 2020-04-05 SP | Santo André | 72 | 3.0 | . 2020-04-05 SP | Santos | 72 | 2.0 | . 2020-04-05 SP | Osasco | 69 | 3.0 | . 2020-04-05 ES | Vitória | 62 | 2.0 | . 2020-04-05 SP | Guarulhos | 62 | 5.0 | . 2020-04-05 ES | Vila Velha | 53 | 2.0 | . 2020-04-05 PA | Belém | 49 | 0.0 | . 2020-04-05 RJ | Volta Redonda | 45 | 2.0 | . 2020-04-05 MS | Campo Grande | 43 | 0.0 | . 2020-04-05 SP | Taboão da Serra | 41 | 3.0 | . 2020-04-05 SP | São Caetano do Sul | 38 | 1.0 | . 2020-04-05 MT | Cuiabá | 38 | 0.0 | . 2020-04-05 AC | Rio Branco | 38 | 0.0 | . 2020-04-05 PR | Londrina | 38 | 1.0 | . 2020-04-05 MG | Juiz de Fora | 37 | 0.0 | . 2020-04-05 MG | Nova Lima | 37 | 0.0 | . 2020-04-05 RR | Boa Vista | 36 | 1.0 | . 2020-04-05 PR | Cascavel | 35 | 1.0 | . 2020-04-05 MG | Uberlândia | 34 | 2.0 | . 2020-04-05 ES | Serra | 31 | 1.0 | . 2020-04-05 BA | Feira de Santana | 30 | 0.0 | . 2020-04-05 SP | São José dos Campos | 30 | 0.0 | . 2020-04-05 SP | Barueri | 30 | 1.0 | . 2020-04-05 AP | Macapá | 29 | 1.0 | . 2020-04-05 RJ | Nova Iguaçu | 29 | 2.0 | . 2020-04-05 SP | Cotia | 29 | 3.0 | . 2020-04-05 SC | Criciúma | 27 | 1.0 | . 2020-04-05 PB | João Pessoa | 26 | 2.0 | . 2020-04-05 SP | Campinas | 26 | 4.0 | . 2020-04-05 SC | Blumenau | 26 | 0.0 | . 2020-04-05 SP | Ribeirão Preto | 25 | 1.0 | . 2020-04-05 SC | Joinville | 25 | 1.0 | . 2020-04-05 PR | Foz do Iguaçu | 24 | 0.0 | . 2020-04-05 SP | Santana de Parnaíba | 24 | 0.0 | . 2020-04-05 RS | Bagé | 24 | 0.0 | . 2020-04-05 SP | Diadema | 24 | 1.0 | . 2020-04-05 PR | Maringá | 21 | 2.0 | . 2020-04-05 PI | Teresina | 21 | 2.0 | . 2020-04-05 SC | Itajaí | 20 | 1.0 | . 2020-04-05 SP | Embu das Artes | 20 | 1.0 | . 2020-04-05 RJ | Duque de Caxias | 20 | 3.0 | . 2020-04-05 AL | Maceió | 20 | 2.0 | . 2020-04-05 SP | Caieiras | 20 | 1.0 | . 2020-04-05 RS | Novo Hamburgo | 19 | 1.0 | . 2020-04-05 SC | Tubarão | 19 | 0.0 | . 2020-04-05 SC | São José | 17 | 1.0 | . 2020-04-05 BA | Lauro de Freitas | 17 | 0.0 | . 2020-04-05 SP | Mogi das Cruzes | 17 | 1.0 | . 2020-04-05 SC | Braço do Norte | 16 | 0.0 | . 2020-04-05 ES | Cariacica | 16 | 0.0 | . 2020-04-05 AM | Manacapuru | 16 | 3.0 | . 2020-04-05 SP | Mauá | 16 | 0.0 | . 2020-04-05 RJ | Belford Roxo | 15 | 2.0 | . 2020-04-05 SP | Ferraz de Vasconcelos | 15 | 0.0 | . 2020-04-05 MG | Divinópolis | 15 | 0.0 | . 2020-04-05 RS | Caxias do Sul | 15 | 0.0 | . 2020-04-05 RJ | Itaboraí | 14 | 1.0 | . 2020-04-05 SP | Carapicuíba | 14 | 1.0 | . 2020-04-05 MG | Contagem | 13 | 0.0 | . 2020-04-05 RJ | São Gonçalo | 13 | 1.0 | . 2020-04-05 PR | Campo Mourão | 13 | 3.0 | . 2020-04-05 RJ | Petrópolis | 13 | 1.0 | . 2020-04-05 PE | Jaboatão dos Guararapes | 12 | 0.0 | . 2020-04-05 TO | Palmas | 12 | 0.0 | . 2020-04-05 SC | Balneário Camboriú | 12 | 0.0 | . 2020-04-05 BA | Ilhéus | 12 | 0.0 | . 2020-04-05 PR | Cianorte | 11 | 1.0 | . 2020-04-05 MG | Uberaba | 11 | 0.0 | . 2020-04-05 RJ | São João de Meriti | 10 | 1.0 | . 2020-04-05 SP | São José do Rio Preto | 10 | 0.0 | . 2020-04-05 BA | Porto Seguro | 10 | 0.0 | . 2020-04-05 RO | Porto Velho | 10 | 1.0 | . 2020-04-05 RS | Canoas | 10 | 0.0 | . 2020-04-05 PA | Ananindeua | 10 | 0.0 | . 2020-04-05 SP | Itaquaquecetuba | 10 | 0.0 | . 2020-04-05 PR | Campo Largo | 9 | 0.0 | . 2020-04-05 SP | Itapecerica da Serra | 9 | 1.0 | . 2020-04-05 SP | Suzano | 9 | 0.0 | . 2020-04-05 SP | Sorocaba | 9 | 2.0 | . 2020-04-05 RS | Torres | 9 | 0.0 | . 2020-04-05 SC | Importados/Indefinidos | 9 | 0.0 | . 2020-04-05 RS | Passo Fundo | 9 | 0.0 | . 2020-04-05 RS | Bento Gonçalves | 9 | 0.0 | . 2020-04-05 PE | Olinda | 9 | 3.0 | . 2020-04-05 RS | Gravataí | 9 | 0.0 | . 2020-04-05 AC | Acrelândia | 9 | 0.0 | . 2020-04-05 GO | Anápolis | 8 | 0.0 | . 2020-04-05 RJ | Maricá | 8 | 1.0 | . 2020-04-05 RS | Lajeado | 8 | 0.0 | . 2020-04-05 SP | Itapevi | 8 | 1.0 | . 2020-04-05 ES | Linhares | 8 | 0.0 | . 2020-04-05 RS | São Leopoldo | 8 | 0.0 | . 2020-04-05 SP | Franco da Rocha | 8 | 1.0 | . 2020-04-05 SC | Antônio Carlos | 8 | 1.0 | . 2020-04-05 SP | Francisco Morato | 8 | 1.0 | . 2020-04-05 GO | Rio Verde | 8 | 0.0 | . 2020-04-05 MG | Importados/Indefinidos | 7 | 0.0 | . 2020-04-05 PR | São José dos Pinhais | 7 | 0.0 | . 2020-04-05 PE | Fernando de Noronha | 7 | 0.0 | . 2020-04-05 PR | Pinhais | 7 | 0.0 | . 2020-04-05 PR | Arapongas | 7 | 0.0 | . 2020-04-05 RJ | Teresópolis | 7 | 0.0 | . 2020-04-05 BA | Camaçari | 7 | 0.0 | . 2020-04-05 SP | Botucatu | 7 | 0.0 | . 2020-04-05 SC | Camboriú | 7 | 0.0 | . 2020-04-05 BA | Itabuna | 7 | 0.0 | . 2020-04-05 SC | Jaraguá do Sul | 6 | 0.0 | . 2020-04-05 SC | Brusque | 6 | 0.0 | . 2020-04-05 BA | Ipiaú | 6 | 0.0 | . 2020-04-05 PE | Importados/Indefinidos | 6 | 1.0 | . 2020-04-05 SC | Chapecó | 6 | 0.0 | . 2020-04-05 RJ | Macaé | 6 | 0.0 | . 2020-04-05 PR | Telêmaco Borba | 6 | 0.0 | . 2020-04-05 SP | Jundiaí | 6 | 0.0 | . 2020-04-05 PE | Camaragibe | 6 | 0.0 | . 2020-04-05 PR | Importados/Indefinidos | 6 | 0.0 | . 2020-04-05 SP | Piracicaba | 6 | 0.0 | . 2020-04-05 SC | Imbituba | 6 | 0.0 | . 2020-04-05 RS | Sant&#39;Ana do Livramento | 6 | 0.0 | . 2020-04-05 MS | Dourados | 6 | 0.0 | . 2020-04-05 RS | Viamão | 6 | 0.0 | . 2020-04-05 SP | Arujá | 6 | 1.0 | . 2020-04-05 MT | Rondonópolis | 6 | 0.0 | . 2020-04-05 PA | Santarém | 5 | 1.0 | . 2020-04-05 PE | Cabo de Santo Agostinho | 5 | 1.0 | . 2020-04-05 BA | Brumado | 5 | 0.0 | . 2020-04-05 MG | Lagoa da Prata | 5 | 0.0 | . 2020-04-05 PR | Ponta Grossa | 5 | 0.0 | . 2020-04-05 MA | São José de Ribamar | 5 | 0.0 | . 2020-04-05 MG | Betim | 5 | 0.0 | . 2020-04-05 GO | Valparaíso de Goiás | 5 | 0.0 | . 2020-04-05 RJ | Magé | 5 | 0.0 | . 2020-04-05 AM | Itacoatiara | 5 | 0.0 | . 2020-04-05 MS | Batayporã | 5 | 1.0 | . 2020-04-05 AM | Santo Antônio do Içá | 5 | 0.0 | . 2020-04-05 RJ | Mesquita | 5 | 1.0 | . 2020-04-05 AL | Importados/Indefinidos | 5 | 0.0 | . 2020-04-05 SP | Mairiporã | 5 | 2.0 | . 2020-04-05 PR | Paranaguá | 5 | 0.0 | . 2020-04-05 PE | Paulista | 5 | 0.0 | . 2020-04-05 BA | Alagoinhas | 5 | 0.0 | . 2020-04-05 SP | São Vicente | 5 | 0.0 | . 2020-04-05 PR | Medianeira | 4 | 0.0 | . 2020-04-05 ES | São Mateus | 4 | 1.0 | . 2020-04-05 MT | Tangará da Serra | 4 | 0.0 | . 2020-04-05 MT | Várzea Grande | 4 | 0.0 | . 2020-04-05 SC | Lages | 4 | 0.0 | . 2020-04-05 SC | Navegantes | 4 | 0.0 | . 2020-04-05 RS | Marau | 4 | 0.0 | . 2020-04-05 BA | Vitória da Conquista | 4 | 0.0 | . 2020-04-05 RJ | Nilópolis | 4 | 0.0 | . 2020-04-05 ES | Aracruz | 4 | 0.0 | . 2020-04-05 BA | Santa Cruz Cabrália | 4 | 0.0 | . 2020-04-05 PR | Colombo | 4 | 0.0 | . 2020-04-05 BA | Prado | 4 | 0.0 | . 2020-04-05 RS | Alvorada | 4 | 0.0 | . 2020-04-05 BA | Itororó | 4 | 0.0 | . 2020-04-05 RS | Ivoti | 4 | 1.0 | . 2020-04-05 SC | Gravatal | 4 | 0.0 | . 2020-04-05 SC | Porto Belo | 4 | 0.0 | . 2020-04-05 SP | Ribeirão Pires | 4 | 0.0 | . 2020-04-05 MG | Muriaé | 4 | 0.0 | . 2020-04-05 MG | Pouso Alegre | 4 | 0.0 | . 2020-04-05 SP | Araçatuba | 4 | 0.0 | . 2020-04-05 MG | Sabará | 4 | 0.0 | . 2020-04-05 SP | Praia Grande | 4 | 0.0 | . 2020-04-05 SP | Atibaia | 4 | 0.0 | . 2020-04-05 TO | Araguaína | 4 | 0.0 | . 2020-04-05 SP | Vargem Grande Paulista | 4 | 1.0 | . 2020-04-05 SC | Siderópolis | 4 | 0.0 | . 2020-04-05 RS | Erechim | 3 | 0.0 | . 2020-04-05 MG | Varginha | 3 | 0.0 | . 2020-04-05 PR | Paranavaí | 3 | 0.0 | . 2020-04-05 PR | Pato Branco | 3 | 0.0 | . 2020-04-05 RS | Farroupilha | 3 | 0.0 | . 2020-04-05 SP | Jaboticabal | 3 | 1.0 | . 2020-04-05 RJ | Angra dos Reis | 3 | 0.0 | . 2020-04-05 BA | Juazeiro | 3 | 0.0 | . 2020-04-05 SP | Guarujá | 3 | 0.0 | . 2020-04-05 MG | Mariana | 3 | 1.0 | . 2020-04-05 GO | Jataí | 3 | 0.0 | . 2020-04-05 RS | Pelotas | 3 | 0.0 | . 2020-04-05 SP | Bauru | 3 | 1.0 | . 2020-04-05 PE | São Lourenço da Mata | 3 | 0.0 | . 2020-04-05 RS | Campo Bom | 3 | 0.0 | .",
            "url": "https://covid19graficos.github.io/relatorio/coronavirus/2020/04/06/corona-brasil-interativo.html",
            "relUrl": "/coronavirus/2020/04/06/corona-brasil-interativo.html",
            "date": " • Apr 6, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Projeção do Covid-19 no Brasil",
            "content": "Gr&#225;ficos . Proje&#231;&#227;o do n&#250;mero de casos no Brasil para a pr&#243;xima semana . Proje&#231;&#227;o do n&#250;mero de &#243;bitos no Brasil para a pr&#243;xima semana . N&#250;mero de Casos Novos Confirmados . N&#250;meros de &#211;bitos Novos . Agradecimentos e Contribui&#231;&#245;es . Ívi M. de Carvalho, D. Sc. | . (Para Programadores) C&#243;digo para gera&#231;&#227;o dos gr&#225;ficos . NOTA: O resto desse relatório está focado no desenvolvimento dos gráficos mostrados acima. Somente é relevante caso tenha interesse em Python e Data Analysis . Neste relatório vamos desenvolver em Python uma projeção que pode ser atualizada em tempo real do número de casos de Covid-19 no Brasil. Devido à sua natureza com crescimento exponencial, podemos fazer projeções de curto/médio prazo de acordo com tal tendência. É importante salientar que não existe nenhuma exponencial pura. Em algum momento haverá um ponto de inflexão (quando o número de casos começa a diminuir) e esta exponencial se tornará um sigmóide (como já é o caso da China). Portanto, como não há como prever quando ocorrerá essa inflexão, as projeções somente são úteis para curto e médio prazo. Sem mais delongas, vamos começar! Primeiramente, todas as importações que serão utilizadas: . # Todas as importações vem aqui import numpy as np import pandas as pd; import matplotlib.pyplot as plt import seaborn as sns; from sklearn.linear_model import LinearRegression from datetime import date . E também parâmetros: . FIGSIZE = (8,4) . Em seguida, vamos importar a base de dados disponibilizada pelo repositório da John Hopkins University. Há duas bases relevantes para nosso caso, uma com o histórico do número de casos e outro com o histório do número de mortes (ambos obtido a partir dos relatórios diários da OMS). . CASOS_URL = &#39;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv&#39; MORTES_URL = &#39;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv&#39; . Ambos são urls diretas para arquivos .CSV, portanto podemos importá-los diretamente para a biblioteca Pandas do Python, sem precisar baixá-los: . casos = pd.read_csv(CASOS_URL) mortes = pd.read_csv(MORTES_URL) . Vamos visualizar o cabeçalho de cada um: . casos.head() . Province/State Country/Region Lat Long 1/22/20 1/23/20 1/24/20 1/25/20 1/26/20 1/27/20 1/28/20 1/29/20 1/30/20 1/31/20 2/1/20 2/2/20 2/3/20 2/4/20 2/5/20 2/6/20 2/7/20 2/8/20 2/9/20 2/10/20 2/11/20 2/12/20 2/13/20 2/14/20 2/15/20 2/16/20 2/17/20 2/18/20 2/19/20 2/20/20 2/21/20 2/22/20 2/23/20 2/24/20 2/25/20 2/26/20 2/27/20 2/28/20 2/29/20 3/1/20 3/2/20 3/3/20 3/4/20 3/5/20 3/6/20 3/7/20 3/8/20 3/9/20 3/10/20 3/11/20 3/12/20 3/13/20 3/14/20 3/15/20 3/16/20 3/17/20 3/18/20 3/19/20 3/20/20 3/21/20 3/22/20 3/23/20 3/24/20 3/25/20 3/26/20 3/27/20 3/28/20 3/29/20 3/30/20 3/31/20 4/1/20 4/2/20 4/3/20 4/4/20 4/5/20 . 0 NaN | Afghanistan | 33.0000 | 65.0000 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 4 | 4 | 5 | 7 | 7 | 7 | 11 | 16 | 21 | 22 | 22 | 22 | 24 | 24 | 40 | 40 | 74 | 84 | 94 | 110 | 110 | 120 | 170 | 174 | 237 | 273 | 281 | 299 | 349 | . 1 NaN | Albania | 41.1533 | 20.1683 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 10 | 12 | 23 | 33 | 38 | 42 | 51 | 55 | 59 | 64 | 70 | 76 | 89 | 104 | 123 | 146 | 174 | 186 | 197 | 212 | 223 | 243 | 259 | 277 | 304 | 333 | 361 | . 2 NaN | Algeria | 28.0339 | 1.6596 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 3 | 5 | 12 | 12 | 17 | 17 | 19 | 20 | 20 | 20 | 24 | 26 | 37 | 48 | 54 | 60 | 74 | 87 | 90 | 139 | 201 | 230 | 264 | 302 | 367 | 409 | 454 | 511 | 584 | 716 | 847 | 986 | 1171 | 1251 | 1320 | . 3 NaN | Andorra | 42.5063 | 1.5218 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 2 | 39 | 39 | 53 | 75 | 88 | 113 | 133 | 164 | 188 | 224 | 267 | 308 | 334 | 370 | 376 | 390 | 428 | 439 | 466 | 501 | . 4 NaN | Angola | -11.2027 | 17.8739 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 2 | 2 | 3 | 3 | 3 | 4 | 4 | 5 | 7 | 7 | 7 | 8 | 8 | 8 | 10 | 14 | . mortes.head() . Province/State Country/Region Lat Long 1/22/20 1/23/20 1/24/20 1/25/20 1/26/20 1/27/20 1/28/20 1/29/20 1/30/20 1/31/20 2/1/20 2/2/20 2/3/20 2/4/20 2/5/20 2/6/20 2/7/20 2/8/20 2/9/20 2/10/20 2/11/20 2/12/20 2/13/20 2/14/20 2/15/20 2/16/20 2/17/20 2/18/20 2/19/20 2/20/20 2/21/20 2/22/20 2/23/20 2/24/20 2/25/20 2/26/20 2/27/20 2/28/20 2/29/20 3/1/20 3/2/20 3/3/20 3/4/20 3/5/20 3/6/20 3/7/20 3/8/20 3/9/20 3/10/20 3/11/20 3/12/20 3/13/20 3/14/20 3/15/20 3/16/20 3/17/20 3/18/20 3/19/20 3/20/20 3/21/20 3/22/20 3/23/20 3/24/20 3/25/20 3/26/20 3/27/20 3/28/20 3/29/20 3/30/20 3/31/20 4/1/20 4/2/20 4/3/20 4/4/20 4/5/20 . 0 NaN | Afghanistan | 33.0000 | 65.0000 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 2 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | 6 | 6 | 7 | 7 | . 1 NaN | Albania | 41.1533 | 20.1683 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 2 | 2 | 2 | 2 | 2 | 4 | 5 | 5 | 6 | 8 | 10 | 10 | 11 | 15 | 15 | 16 | 17 | 20 | 20 | . 2 NaN | Algeria | 28.0339 | 1.6596 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 2 | 3 | 4 | 4 | 4 | 7 | 9 | 11 | 15 | 17 | 17 | 19 | 21 | 25 | 26 | 29 | 31 | 35 | 44 | 58 | 86 | 105 | 130 | 152 | . 3 NaN | Andorra | 42.5063 | 1.5218 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 3 | 3 | 3 | 6 | 8 | 12 | 14 | 15 | 16 | 17 | 18 | . 4 NaN | Angola | -11.2027 | 17.8739 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | . Como para este relatório temos interesse em apenas dados do Brasil, vamos atribuir duas novas variáveis à ambos: . def filter_country(df, country): # Filtrar pais df = df[df[&#39;Country/Region&#39;]==country] # Remover colunas iniciais, manter somente as datas df = df.iloc[:, 4:] # Transpor df = df.T # Redefinir coluna df.columns = [country] # Definir index para Datetime df.index = pd.to_datetime(df.index) return df casos_brasil = filter_country(casos, &#39;Brazil&#39;) mortes_brasil = filter_country(mortes, &#39;Brazil&#39;) . Vamos ver como ficaram os novos dataframes: . casos_brasil.tail() . Brazil . 2020-04-01 6836 | . 2020-04-02 8044 | . 2020-04-03 9056 | . 2020-04-04 10360 | . 2020-04-05 11130 | . mortes_brasil.tail() . Brazil . 2020-04-01 240 | . 2020-04-02 324 | . 2020-04-03 359 | . 2020-04-04 445 | . 2020-04-05 486 | . Podemos facilmente também plotar tais dados para ver como estão: . casos_brasil.plot(title=&#39;Número de casos&#39;); . mortes_brasil.plot(title=&#39;Número de mortes&#39;); . Podemos conferir se o número de casos está se acelerando ou não plotando um gráfico de barras do número de casos por dia. Isso será importante para identificar a inflexão! . casos_novos_brasil = casos_brasil[1:]-casos_brasil[:-1].values casos_novos_brasil.tail() . Brazil . 2020-04-01 1119 | . 2020-04-02 1208 | . 2020-04-03 1012 | . 2020-04-04 1304 | . 2020-04-05 770 | . mortes_novas_brasil = mortes_brasil[1:]-mortes_brasil[:-1].values mortes_novas_brasil.tail() . Brazil . 2020-04-01 39 | . 2020-04-02 84 | . 2020-04-03 35 | . 2020-04-04 86 | . 2020-04-05 41 | . Em seguida vamos visualizar ambos em um gráfico de barras: . # Funcao personalizada def plot_bar_novos(df, title): df.index = df.index.strftime(&#39;%d/%m&#39;)#astype(&#39;str&#39;) ax = df.plot.bar( title=title, figsize=FIGSIZE ) _=plt.xticks(rotation=50) return ax . primeiro_caso_filtro = casos_novos_brasil.values&gt;0 ax=plot_bar_novos(casos_novos_brasil[primeiro_caso_filtro], title=&#39;Casos novos (sem acumular, a partir do primeiro caso)&#39;, ) . # Filtrar a partir do primeiro obito primeiro_obito_filtro = mortes_novas_brasil.values&gt;0 # Criar plot ax=plot_bar_novos(mortes_novas_brasil[primeiro_obito_filtro], title=&#39;Óbitos novos (sem acumular, a partir do primeiro óbito)&#39; ) . ax.figure.savefig(&#39;obitos_novos.png&#39;, dpi=300) . Vamos agora dar início à modelagem das projeções. Primeiramente, vamos fazer alguns plots em cima do log dos dados: . casos_brasil[&#39;Brazil&#39;].apply(np.log).plot(marker=&#39;o&#39;, linestyle=&#39;&#39;, title=&#39;Log do Número de casos&#39;); . mortes_brasil[&#39;Brazil&#39;].apply(np.log).plot(marker=&#39;o&#39;, linestyle=&#39;&#39;, title=&#39;Log do Número de Mortes&#39;); . casos_novos_brasil.apply(np.log).plot(marker=&#39;o&#39;, linestyle=&#39;&#39;, title=&#39;Log do número de casos novos&#39;); . mortes_novas_brasil.apply(np.log).plot(marker=&#39;o&#39;, linestyle=&#39;&#39;, title=&#39;Log de novas mortes&#39;); . Todas as curvas acima não representam uma reta perfeita, o que são ótimas notícias: Significa que talvez não esteja mais seguindo uma tendência exponencial. De qualquer forma, vou usar como ponto de partida uma regressão linear, apesar de haverem ressalvas sobre o uso dela. Por simplificação, vou começar com uma projeção do número total de casos e de mortes. Primeiramente, vou juntar todos os dados em um único dataframe: . brasil = pd.DataFrame({ &#39;Confirmados Cumulativo&#39;: casos_brasil[&#39;Brazil&#39;].values[1:], &#39;Confirmados Novos&#39;: casos_novos_brasil[&#39;Brazil&#39;].values, &#39;Mortes Cumulativa&#39;: mortes_brasil[&#39;Brazil&#39;].values[1:], &#39;Mortes Novas&#39;: mortes_novas_brasil[&#39;Brazil&#39;].values }) brasil.index = casos_novos_brasil.index brasil.tail() . Confirmados Cumulativo Confirmados Novos Mortes Cumulativa Mortes Novas . 2020-04-01 6836 | 1119 | 240 | 39 | . 2020-04-02 8044 | 1208 | 324 | 84 | . 2020-04-03 9056 | 1012 | 359 | 35 | . 2020-04-04 10360 | 1304 | 445 | 86 | . 2020-04-05 11130 | 770 | 486 | 41 | . Também podemos criar um dataframe com o log de todos os dados: . brasil_log = brasil.apply(np.log1p) brasil_log.tail() . Confirmados Cumulativo Confirmados Novos Mortes Cumulativa Mortes Novas . 2020-04-01 8.830104 | 7.021084 | 5.484797 | 3.688879 | . 2020-04-02 8.992806 | 7.097549 | 5.783825 | 4.442651 | . 2020-04-03 9.111293 | 6.920672 | 5.886104 | 3.583519 | . 2020-04-04 9.245804 | 7.173958 | 6.100319 | 4.465908 | . 2020-04-05 9.317489 | 6.647688 | 6.188264 | 3.737670 | . Vamos visualizar a distribuição de cada um e também scatter plots de cada um versus o outro: . pd.plotting.scatter_matrix(brasil_log, figsize = (14,8), diagonal = &#39;kde&#39;); . O plot acima fica um pouco enviesado pois há um grande acúmulo de zeros. Vamos filtrar as datas a partir do promeiro óbito: . primeiro_obito = brasil_log.index[brasil_log[&#39;Mortes Cumulativa&#39;]&gt;0][0] primeiro_obito_filtro = brasil_log.index&gt;=primeiro_obito primeiro_obito . Timestamp(&#39;2020-03-17 00:00:00&#39;) . Como é uma base bastante recente, vamos também pegar o primeiro caso: . primeiro_caso = brasil_log.index[brasil_log[&#39;Confirmados Cumulativo&#39;]&gt;0][0] primeiro_caso_filtro = brasil_log.index&gt;=primeiro_caso primeiro_caso . Timestamp(&#39;2020-02-26 00:00:00&#39;) . Vamos repetir o scatter matrix acima a partir dos filtros que definimos: . g = sns.pairplot(brasil[primeiro_obito_filtro], kind=&quot;reg&quot;) g.fig.tight_layout() g.fig.subplots_adjust(top=0.88) g.fig.suptitle(&#39;Grade de gráficos, dados a partir do primeiro óbito&#39;, y=0.92); . g = sns.pairplot(brasil[primeiro_caso_filtro], kind=&quot;reg&quot;) g.fig.suptitle(&#39;Scatter Matrix com filtro a partir do primeiro caso&#39;, y=1.08); . g = sns.pairplot(brasil_log[primeiro_obito_filtro], kind=&quot;reg&quot;) g.fig.suptitle(&#39;Scatter Matrix do Log dos dados com filtro a partir do primeiro óbito&#39;, y=1.08); . g = sns.pairplot(brasil_log[primeiro_obito_filtro], kind=&quot;reg&quot;) g.fig.suptitle(&#39;Scatter Matrix do Log dos dados com filtro a partir do primeiro óbito&#39;, y=1.08); . Os plots acima, talvez pareçam informação irrelevante, mas o fiz para ter uma ideia sobre a distribuição dos dados e se há alguma distribuição normal em algum caso, que justificaria o uso do desvio padrão (uma vez que o mesmo é em relação à distribuição normal). De qualquer forma, para manter as coisas simples inicialmente, vou manter meu plano inicial de criar uma projeção do número de casos incluindo o intervalo do desvio padrão. Então vamos começar pegando o as estatísticas filtrando a partir do primeiro caso: . std = brasil_log[primeiro_caso_filtro].std() . Visualizar um plot da tendência que vamos modelar: . brasil_log[primeiro_caso_filtro][&#39;Confirmados Cumulativo&#39;].plot() . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7feafcb942b0&gt; . Em seguida ajustar uma regressão linear em cima do log: . def fitar(x, y): lr = LinearRegression() lr.fit(x,y) return lr x = np.arange(sum(primeiro_caso_filtro)).reshape(-1,1) y = brasil_log[primeiro_caso_filtro][&#39;Confirmados Cumulativo&#39;].values lr_casos = fitar(x, y) . def projetar(lr, x, y, plot=True): y_pred = lr.predict(x) if plot: plt.scatter(x, y) plt.plot(y_pred, &#39;r&#39;) plt.title(&quot;Projeção logarítmica&quot;) plt.show() plt.scatter(x, np.expm1(y)) plt.plot(np.expm1(y_pred), &#39;r&#39;) plt.title(&quot;Projeção exponencial&quot;) plt.show() return y_pred y_pred = projetar(lr_casos, x, y) . A projeção acima não ficou boa, vamos testar suavizar com um exponential moving average: . def generate_moving_average(data, mom=0.7): MOM = 0.7 rolling_mean = [data[0]] for d in data[1:]: rolling_mean.append(rolling_mean[-1]*MOM + (1-MOM)*d) return np.array(rolling_mean) def fitar_projetar(x, y, mom=None): if mom is not None: y_old = y y = generate_moving_average(y) lr = fitar(x, y) y_pred = projetar(lr, x, y, plot=not mom) # Plota se mom for nulo if mom is not None: y_pred_exp = np.expm1(y_pred) reversed_mv = [(rm-rm_*mom)/(1-mom) for rm, rm_ in zip(y_pred_exp[1:], y_pred_exp[:-1])] plt.scatter(x, np.expm1(y_old), label=&quot;Original&quot;) plt.scatter(x, np.expm1(y), label=&quot;Exp. Moving Average&quot;) plt.plot(y_pred_exp, &#39;r&#39;, label=&quot;Projeção do EMA&quot;) plt.plot(reversed_mv, label=&quot;EMA reverso para projeção real&quot;) plt.legend() plt.title(f&quot;Projeção com Exp. Moving Average (momentum = {mom})&quot;) plt.show() return y_pred y_pred = fitar_projetar(x, y, mom=0.5) . Também não ficou muito boa. Um dos motivos de estas funções não estarem se saindo bem é que o erro está sendo inferido na escala logarítmica, ou seja, enquanto estamos na escala logarítmica, o erro em termos absolutos é pequeno, no entanto, quando passamos à escala normal, o erro aumenta consideravelmente. Parra corrigir isso, precisamos ajustar uma função exponencial diretamente sem realizar a transformação logarítmica. Precisamos de uma função de custo que infira o erro diretamente da exponencial. Podemos fazer isso com o auxílio de otimizadores de redes neurais. Vamos também aproveitar para ajustar uma sigmóide. E aqui um detalhe: para quem é de machine learning, as boas práticas de seleção de modelos não se aplicam aqui (por exemplo, divisão treinamento e teste). Como os modelos a serem ajustados são bastante simples, não há a necessidade de reservar um conjunto de validação/teste. . # Creating a model from keras.models import Sequential; from keras.layers import Dense from keras import backend as K from keras.optimizers import Adam from keras.activations import sigmoid, elu def get_keras_model(lr=0.001, activation=&#39;exp&#39;): if activation==&#39;exp&#39;: def activ_func(x): return K.exp(x) - 1 elif activation==&#39;sigm&#39;: activ_func = sigmoid elif activation==&#39;elu&#39;: activ_func = elu # Usage model = Sequential(); model.add(Dense(1, input_dim=1, activation=activ_func)) model.compile(optimizer=Adam(lr=lr), loss=&#39;mean_squared_error&#39;) return model . # Definir entrada e saida x = np.arange(sum(primeiro_caso_filtro)).reshape(-1,1) y = brasil[primeiro_caso_filtro][&#39;Confirmados Cumulativo&#39;].values . # Preparar dados def preparar_dados(x, y): x_mean = x.mean() x_std = x.std() y_mean = y.mean() y_std = y.std() x_prep = (x-x_mean)/x_std y_prep = (y-y_mean)/y_std return x_prep, y_prep x_prep, y_prep = preparar_dados(x, y) . #hide_output model = get_keras_model(lr=0.1) model.fit(x_prep, y_prep, epochs=100, verbose=0); . from sklearn.metrics import r2_score . def projetar_keras(model, x, y, days_ahead=0, plot=True, model_func=&quot;exponencial&quot;, tipo=&#39;caso&#39;, exibir_pontos=False, anotar_dados_reais=True, dados_reais_step=2): title = f&#39;Projeção {model_func} de {tipo}s de Covid-19 no Brasil&#39; + f&#39; para os próximos {days_ahead} dias&#39; hoje = date.today() hoje = hoje.strftime(&quot;%d/%m&quot;) x_mean = x.mean() x_std = x.std() y_mean = y.mean() y_std = y.std() n_days = len(x) x_proj = np.arange(n_days+days_ahead).reshape(-1,1) x_prep = (x_proj-x_mean)/x_std y_prep = (y-y_mean)/y_std y_pred = model.predict(x_prep) y_pred = y_pred*y_std + y_mean #Reverse y_pred back y_pred = y_pred.astype(int) y_pred = np.clip(y_pred, 0, None) y_pred = y_pred.squeeze() #print(y) #print(y_pred) r2 = r2_score(y, y_pred[:-days_ahead]) if plot: fig = plt.figure(figsize=FIGSIZE) # Plotar projeção plt.plot(x_proj[-days_ahead-1:], y_pred[-days_ahead-1:], &#39;-&#39;, color=&#39;red&#39;, label=&#39;Projeção&#39;) # Plotar função if exibir_pontos: plt.plot(x_proj[:-days_ahead], y_pred[:-days_ahead], &#39;-&#39;, color=&#39;red&#39;, label=f&#39;Ajuste {model_func} (R²={r2:.2f})&#39;, alpha=0.4) #plt.scatter(x, y, label=&#39;Dados reais&#39;, color=&#39;orange&#39;) plt.plot(y, &#39;.&#39;, label=&#39;Dados reais&#39;) plt.title(title) for x_anot, y_anot in zip(x_proj[-days_ahead:], y_pred[-days_ahead:]): plt.annotate(y_anot, (x_anot, y_anot), ha=&#39;right&#39;, color=&#39;red&#39;) plt.annotate(f&#39;({hoje}): {y[-1]}&#39;, (x[-1], y[-1]), ha=&#39;right&#39;, color=&#39;black&#39;, textcoords=&quot;offset points&quot;, xytext=(-5,0)) if anotar_dados_reais: for x_anot, y_anot in zip(x[:-1:dados_reais_step], y[:-1:dados_reais_step]): plt.annotate(y_anot, (x_anot, y_anot), ha=&#39;right&#39;, color=&#39;midnightblue&#39;, textcoords=&quot;offset points&quot;, xytext=(-5,3) ) plt.grid(color=&#39;black&#39;, linestyle=&#39;--&#39;, linewidth=0.17) plt.legend() plt.xlabel(f&quot;Dias desde o primeiro {tipo} no Brasil&quot;) plt.ylabel(f&#39;{tipo.capitalize()}s confirmados acumulados&#39;) plt.xticks(x_proj[::2]) plt.show() return y_pred, fig . y_pred, fig = projetar_keras(model, x, y, days_ahead=7, exibir_pontos=True, anotar_dados_reais=False, dados_reais_step=3) . Por curiosidade, vamos testar ajustar um sigmóide: . #hide_output model = get_keras_model(lr=1, activation=&#39;sigm&#39;) model.fit(x_prep, y_prep, epochs=100, verbose=0); . y_pred, fig = projetar_keras(model, x, y, days_ahead=5, model_func=&#39;sigmóide&#39;, exibir_pontos=True) . Bem distante do esperado :) Vamos testar também o ELU: . #hide_output model = get_keras_model(lr=0.1, activation=&#39;elu&#39;) model.fit(x_prep, y_prep, epochs=100, verbose=0); . y_pred, fig = projetar_keras(model, x, y, days_ahead=7, model_func=&quot;ELU (Exp. Linear Unit)&quot;, exibir_pontos=True) . Um pouco melhor, mas neste caso com tendência linear. Vamos também replicar estes dois últimos para o número de óbitos. . # Definir entrada e saida x = np.arange(sum(primeiro_obito_filtro)).reshape(-1,1) y = brasil[primeiro_obito_filtro][&#39;Mortes Cumulativa&#39;].values x_prep, y_prep = preparar_dados(x, y) . #hide_output model = get_keras_model(lr=0.1, activation=&#39;exp&#39;) model.fit(x_prep, y_prep, epochs=100, verbose=0); . y_pred, fig = projetar_keras(model, x, y, days_ahead=7, model_func=&quot;exponencial&quot;, tipo=&#39;obito&#39;, exibir_pontos=True, anotar_dados_reais=False, dados_reais_step=3) . #hide_output model = get_keras_model(lr=0.1, activation=&#39;elu&#39;) model.fit(x_prep, y_prep, epochs=100, verbose=0); . y_pred, fig = projetar_keras(model, x, y, days_ahead=7, model_func=&quot;ELU (Exp. Linear Unit)&quot;, tipo=&#39;obito&#39;, exibir_pontos=True) . &quot;&quot;&quot; ### Extrapolação do Número de Casos O gráfico abaixo representa uma estimativa simples da quantidade de casos atualmente no Brasil. Uma vez que a baixa quantidade de testes tem levado os números a uma subnotificação, o cálculo foi realizado com base no número de óbitos registrados por COVID-19 no Brasil e na taxa de letalidade de países como a Alemanha e a Coréia do Sul, países que tem testado massivamente sua população. Desse modo os números são os seguintes: &quot;&quot;&quot; . &#39; n### Extrapolação do Número de Casos nO gráfico abaixo representa uma estimativa simples da quantidade de casos natualmente no Brasil. Uma vez que a baixa quantidade de testes tem levado os nnúmeros a uma subnotificação, o cálculo foi realizado com base no número de nóbitos registrados por COVID-19 no Brasil e na taxa de letalidade de países como na Alemanha e a Coréia do Sul, países que tem testado massivamente sua população. nDesse modo os números são os seguintes: n&#39; . x = np.arange(sum(primeiro_caso_filtro)).reshape(-1,1) y = brasil[primeiro_caso_filtro][&#39;Confirmados Cumulativo&#39;].values x_casos, y_casos = preparar_dados(x, y) . model_casos = get_keras_model(lr=0.1) model_casos.fit(x_casos, y_casos, epochs=100, verbose=0); .",
            "url": "https://covid19graficos.github.io/relatorio/coronavirus/2020/04/05/projecao-brasil.html",
            "relUrl": "/coronavirus/2020/04/05/projecao-brasil.html",
            "date": " • Apr 5, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Sobre este website . Este website foi criado utilizando fastpages no qual permite a conversão automática de arquivos do Jupyter notebook em páginas da web. Temos o objetivo de tornar análises comparativas do Brasil com o resto do mundo de maneira à melhor informar a população. Sugestões de relatórios podem ser submetidas em nosso repositório. . Desenvolvedores . Vinicius Bastos Gomes Linkedin: https://www.linkedin.com/in/vinicius-gomes-phd-490557163/ | Github: https://github.com/ViniciusBG | . | Fernando Marcos Wittmann LinkedIn: https://www.linkedin.com/in/fernandowittmann/ | GitHub: https://github.com/WittmannF | . | . Fontes . John Hopkins University: https://github.com/CSSEGISandData/COVID-19 | Brasil.io: https://brasil.io/dataset/covid19/boletim | Ministério da Saúde: https://covid.saude.gov.br/ | . As fontes de cada relatório podem também ser conferidas em nossos notebooks. .",
          "url": "https://covid19graficos.github.io/relatorio/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}