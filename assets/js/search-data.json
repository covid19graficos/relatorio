{
  
    
        "post0": {
            "title": "Mundo - comparações entre países",
            "content": "Fonte: https://opendata.ecdc.europa.eu/covid19/casedistribution/csv . Gráficos de contaminação . Os gráficos a seguir apresentam curvas de contaminação de diversos países. Foram criados com o intuito de comparar estratégias de combate à disseminação do vírus. É importante notar que as curvas de contaminação estão amplamente relacionadas à quantidade de testes que os países tem realizado. . . . . . Contaminação Relativa . Essa seção conta com gráficos em que o número de casos é dívidido pela população dos países para que se tenha uma ideia da proporção de infectados por país. . . . . . Óbitos . Os gráficos a seguir apresentam os óbitos contabilizados por COVID-19, nas escalas aritmética e logarítmica. . . . . . Letalidade . O gráfco a seguir aponta o número de mortes dividido pelo número de casos confirmados. É importantíssimo notar a grande dependência desses números da quantidade de testes disponíveis. Quanto mais testes realizados, mais confiáveis os dados. . . . O gráfico a seguir apresenta a curva de letalidade dos países. Novamente reiteramos que: mais do que de fato apresentar uma flutuação da letalidade do vírus, que muito provavelmente não varia tão abruptamente, esses gráficos demonstram, por exemplo, um aumento na quantidade de testes (quando a taxa de letalidade cai), uma mudança na forma de contabilizar os óbitos, entre outros. . . . O gráfico abaixo representa uma estimativa simples da quantidade de casos atualmente no Brasil. Uma vez que a baixa quantidade de testes tem levado os números a uma subnotificação, o cálculo foi realizado com base no número de óbitos registrados por COVID-19 no Brasil e na taxa da Alemanha, país que tem testado massivamente sua população. Desse modo os números são os seguintes: . Número atual de casos registrados no Brasil hoje: 30425 Estimativa de casos no Brasil hoje caso a letalidade seja próxima à da Alemanha: 66574 . . .",
            "url": "https://covid19graficos.github.io/relatorio/coronavirus/2020/04/17/corona-mundo-interativo.html",
            "relUrl": "/coronavirus/2020/04/17/corona-mundo-interativo.html",
            "date": " • Apr 17, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Brasil - comparações entre estados, regiões e cidades",
            "content": "Fonte (estados):https://covid.saude.gov.br/ (cidades) https://data.brasil.io/dataset/covid19/caso.csv.gz . Gráficos de contaminação . Casos novos no país. . . . Os gráficos a seguir apresentam curvas de contaminação dos estados brasileiros. É importante notar que as curvas de contaminação estão amplamente relacionadas à quantidade de testes que os países tem realizado. Até o momento estarão apenas na escala aritmética. . . . Essa seção conta com gráficos em que o número de casos é dívidido pela população dos estados para que se tenha uma ideia da proporção de infectados por país. . . . O gráfico a seguir é um comparativo de casos totais por estado no Brasil. . . . O gráfico a seguir é um comparativo a proporção de habitantes infectados por estado no Brasil. . . . Curvas de contaminação por regiões . Comparações entre as regiões do Brasil. Primeiramente uma soma dos casos por regiões e, posteriormente, uma comparação entre os estados das regiões. . . . . . . . . . . . . . . . . . . . . . . . Óbitos . . . Comparações entre as regiões do Brasil. Primeiramente uma soma dos casos por regiões e, posteriormente, uma comparação entre os estados das regiões. . . . Óbitos por regiões . . . . . . . . . . . . . Letalidade por estado brasileiro . O gráfco a seguir aponta o número de mortes dividido pelo número de casos confirmados. É importantíssimo notar a grande dependência desses números da quantidade de testes disponíveis. Quanto mais testes realizados, mais confiáveis os dados. . . . O gráfico a seguir apresenta a curva de letalidade dos estados. Novamente reiteramos que: mais do que de fato apresentar uma flutuação da letalidade do vírus, que muito provavelmente não varia tão abruptamente, esses gráficos demonstram, por exemplo, um aumento na quantidade de testes (quando a taxa de letalidade cai), uma mudança na forma de contabilizar os óbitos, entre outros. . . . Capitais brasileiras . Comparações entre as capitais de estados do Brasil . . . . . Linhas de todas as cidades . A seguir as linhas de casos e óbitos de todas as cidades do Brasil das quais temos acesso aos dados. Para melhor utilização, encontre a cidade e clique duas vezes sobre sua legenda, isolando-a. Caso queira compará-la com outra cidade, adicione a linha da segunda cidade desejada clicando uma vez sobre sua legenda. . . . . . 200 cidades com maiores números de casos . Abaixo uma tabela com a lista das 200 cidades com mais casos no país. . cidade_last.columns . Index([&#39;state&#39;, &#39;city&#39;, &#39;confirmed&#39;, &#39;deaths&#39;, &#39;data&#39;], dtype=&#39;object&#39;) . Estado Cidade Casos Mortes . date . 2020-04-16 SP | São Paulo | 7908 | 603 | . 2020-04-16 RJ | Rio de Janeiro | 2659 | 195 | . 2020-04-16 CE | Fortaleza | 2041 | 95 | . 2020-04-16 AM | Manaus | 1459 | 107 | . 2020-04-16 PE | Recife | 958 | 70 | . 2020-04-16 DF | Brasília | 727 | 20 | . 2020-04-16 MA | São Luís | 664 | 35 | . 2020-04-16 BA | Salvador | 571 | 18 | . 2020-04-16 MG | Belo Horizonte | 390 | 7 | . 2020-04-16 RS | Porto Alegre | 361 | 8 | . 2020-04-16 PR | Curitiba | 320 | 8 | . 2020-04-16 AP | Macapá | 303 | 8 | . 2020-04-16 SP | Guarulhos | 269 | 25 | . 2020-04-16 SP | São Bernardo do Campo | 255 | 16 | . 2020-04-16 SP | Santos | 247 | 15 | . 2020-04-16 SC | Florianópolis | 219 | 3 | . 2020-04-16 SP | Santo André | 205 | 7 | . 2020-04-16 SP | Osasco | 203 | 18 | . 2020-04-16 GO | Goiânia | 182 | 8 | . 2020-04-16 RJ | Niterói | 167 | 11 | . 2020-04-16 RJ | Nova Iguaçu | 150 | 12 | . 2020-04-16 SP | Campinas | 149 | 7 | . 2020-04-16 AM | Manacapuru | 149 | 6 | . 2020-04-16 RR | Boa Vista | 147 | 2 | . 2020-04-16 PE | Olinda | 147 | 12 | . 2020-04-16 PB | João Pessoa | 142 | 16 | . 2020-04-16 RJ | Duque de Caxias | 125 | 21 | . 2020-04-16 RJ | Volta Redonda | 121 | 6 | . 2020-04-16 PE | Jaboatão dos Guararapes | 121 | 11 | . 2020-04-16 SP | São José dos Campos | 116 | 3 | . 2020-04-16 SP | Taboão da Serra | 100 | 5 | . 2020-04-16 SP | Diadema | 100 | 3 | . 2020-04-16 PE | Paulista | 98 | 4 | . 2020-04-16 SP | Barueri | 97 | 5 | . 2020-04-16 RJ | São Gonçalo | 95 | 5 | . 2020-04-16 SP | São Caetano do Sul | 90 | 3 | . 2020-04-16 SP | Mogi das Cruzes | 86 | 6 | . 2020-04-16 PI | Teresina | 86 | 5 | . 2020-04-16 AC | Rio Branco | 86 | 4 | . 2020-04-16 MT | Cuiabá | 83 | 1 | . 2020-04-16 MG | Juiz de Fora | 82 | 2 | . 2020-04-16 PR | Londrina | 74 | 4 | . 2020-04-16 SC | Joinville | 73 | 2 | . 2020-04-16 SP | Cotia | 72 | 4 | . 2020-04-16 SC | Blumenau | 71 | 0 | . 2020-04-16 SP | Mauá | 71 | 2 | . 2020-04-16 AL | Maceió | 70 | 3 | . 2020-04-16 MS | Campo Grande | 68 | 2 | . 2020-04-16 SP | Ribeirão Preto | 68 | 5 | . 2020-04-16 RJ | São João de Meriti | 68 | 5 | . 2020-04-16 RJ | Petrópolis | 66 | 1 | . 2020-04-16 SP | São José do Rio Preto | 65 | 3 | . 2020-04-16 MG | Uberlândia | 64 | 4 | . 2020-04-16 PE | Camaragibe | 63 | 6 | . 2020-04-16 SP | Importados/Indefinidos | 63 | 0 | . 2020-04-16 PR | Cascavel | 59 | 2 | . 2020-04-16 RO | Porto Velho | 58 | 2 | . 2020-04-16 SP | Suzano | 57 | 6 | . 2020-04-16 SC | Balneário Camboriú | 57 | 0 | . 2020-04-16 CE | Caucaia | 56 | 4 | . 2020-04-16 BA | Feira de Santana | 56 | 0 | . 2020-04-16 BA | Ilhéus | 55 | 2 | . 2020-04-16 MA | São José de Ribamar | 55 | 2 | . 2020-04-16 RJ | Belford Roxo | 54 | 3 | . 2020-04-16 SC | Camboriú | 54 | 2 | . 2020-04-16 SP | Carapicuíba | 52 | 2 | . 2020-04-16 PE | São Lourenço da Mata | 52 | 12 | . 2020-04-16 CE | Maracanaú | 51 | 4 | . 2020-04-16 RJ | Mesquita | 51 | 1 | . 2020-04-16 SP | Embu das Artes | 50 | 2 | . 2020-04-16 SP | Santana de Parnaíba | 50 | 0 | . 2020-04-16 AP | Santana | 48 | 2 | . 2020-04-16 SP | Franco da Rocha | 47 | 2 | . 2020-04-16 SP | Caieiras | 47 | 6 | . 2020-04-16 SP | Ferraz de Vasconcelos | 47 | 2 | . 2020-04-16 MG | Nova Lima | 46 | 0 | . 2020-04-16 SC | Criciúma | 44 | 4 | . 2020-04-16 SP | Itaquaquecetuba | 42 | 0 | . 2020-04-16 RS | Caxias do Sul | 41 | 0 | . 2020-04-16 SC | Itajaí | 41 | 2 | . 2020-04-16 SE | Aracaju | 40 | 4 | . 2020-04-16 SP | Itapecerica da Serra | 38 | 1 | . 2020-04-16 PR | Foz do Iguaçu | 36 | 0 | . 2020-04-16 CE | Aquiraz | 36 | 0 | . 2020-04-16 SP | São Vicente | 36 | 0 | . 2020-04-16 SP | Sorocaba | 36 | 5 | . 2020-04-16 RJ | Maricá | 35 | 4 | . 2020-04-16 MG | Divinópolis | 35 | 1 | . 2020-04-16 SP | Araçatuba | 33 | 0 | . 2020-04-16 SP | Bragança Paulista | 33 | 6 | . 2020-04-16 SC | São José | 33 | 1 | . 2020-04-16 SP | Praia Grande | 33 | 6 | . 2020-04-16 BA | Itabuna | 32 | 0 | . 2020-04-16 SC | Tubarão | 32 | 2 | . 2020-04-16 SP | Araraquara | 32 | 2 | . 2020-04-16 PR | Maringá | 32 | 5 | . 2020-04-16 RJ | Itaboraí | 31 | 4 | . 2020-04-16 BA | Lauro de Freitas | 29 | 3 | . 2020-04-16 RS | Passo Fundo | 29 | 2 | . 2020-04-16 RS | Bagé | 28 | 0 | . 2020-04-16 SP | Itapevi | 28 | 5 | . 2020-04-16 RJ | Magé | 28 | 3 | . 2020-04-16 SP | Jundiaí | 27 | 3 | . 2020-04-16 RS | Novo Hamburgo | 26 | 2 | . 2020-04-16 MA | Paço do Lumiar | 26 | 2 | . 2020-04-16 SP | Ribeirão Pires | 26 | 0 | . 2020-04-16 SP | Guarujá | 26 | 1 | . 2020-04-16 SC | Braço do Norte | 25 | 1 | . 2020-04-16 CE | Importados/Indefinidos | 25 | 10 | . 2020-04-16 SP | Botucatu | 24 | 2 | . 2020-04-16 GO | Anápolis | 24 | 0 | . 2020-04-16 PE | Fernando de Noronha | 24 | 0 | . 2020-04-16 RJ | Nilópolis | 24 | 0 | . 2020-04-16 RJ | Nova Friburgo | 23 | 1 | . 2020-04-16 SP | Bauru | 23 | 3 | . 2020-04-16 MT | Rondonópolis | 23 | 1 | . 2020-04-16 MG | Contagem | 22 | 0 | . 2020-04-16 TO | Palmas | 21 | 1 | . 2020-04-16 PR | Campo Mourão | 21 | 4 | . 2020-04-16 CE | Sobral | 21 | 0 | . 2020-04-16 MG | Uberaba | 21 | 2 | . 2020-04-16 SC | Brusque | 20 | 0 | . 2020-04-16 RJ | Macaé | 20 | 2 | . 2020-04-16 PE | Cabo de Santo Agostinho | 19 | 9 | . 2020-04-16 SP | Francisco Morato | 19 | 1 | . 2020-04-16 RS | Lajeado | 19 | 0 | . 2020-04-16 SP | Piracicaba | 18 | 1 | . 2020-04-16 RS | São Leopoldo | 18 | 1 | . 2020-04-16 AM | Iranduba | 18 | 3 | . 2020-04-16 BA | Vitória da Conquista | 18 | 1 | . 2020-04-16 PB | Santa Rita | 17 | 1 | . 2020-04-16 PR | São José dos Pinhais | 17 | 0 | . 2020-04-16 SP | Americana | 17 | 3 | . 2020-04-16 PE | Abreu e Lima | 17 | 0 | . 2020-04-16 MG | Pouso Alegre | 17 | 2 | . 2020-04-16 SP | Arujá | 17 | 1 | . 2020-04-16 GO | Goianésia | 17 | 0 | . 2020-04-16 SP | Atibaia | 17 | 1 | . 2020-04-16 MA | Imperatriz | 17 | 1 | . 2020-04-16 RO | Ariquemes | 16 | 0 | . 2020-04-16 RS | Canoas | 16 | 1 | . 2020-04-16 SP | Poá | 15 | 2 | . 2020-04-16 BA | Camaçari | 15 | 0 | . 2020-04-16 CE | Eusébio | 15 | 2 | . 2020-04-16 RJ | Queimados | 15 | 1 | . 2020-04-16 AM | Itacoatiara | 15 | 0 | . 2020-04-16 MG | Lagoa da Prata | 14 | 0 | . 2020-04-16 RJ | Teresópolis | 14 | 0 | . 2020-04-16 PR | Cianorte | 14 | 1 | . 2020-04-16 RS | Gravataí | 14 | 0 | . 2020-04-16 PE | Igarassu | 13 | 2 | . 2020-04-16 AC | Plácido de Castro | 13 | 1 | . 2020-04-16 SC | Imbituba | 13 | 0 | . 2020-04-16 PR | Campo Largo | 13 | 2 | . 2020-04-16 SC | Palhoça | 13 | 1 | . 2020-04-16 PR | Importados/Indefinidos | 13 | 2 | . 2020-04-16 PR | Pinhais | 13 | 1 | . 2020-04-16 RJ | Barra Mansa | 13 | 1 | . 2020-04-16 SC | Importados/Indefinidos | 13 | 0 | . 2020-04-16 BA | Ipiaú | 13 | 0 | . 2020-04-16 RS | Viamão | 13 | 0 | . 2020-04-16 GO | Rio Verde | 13 | 1 | . 2020-04-16 RS | Santa Maria | 13 | 0 | . 2020-04-16 PR | Arapongas | 12 | 1 | . 2020-04-16 MT | Sinop | 12 | 0 | . 2020-04-16 RS | Pelotas | 12 | 0 | . 2020-04-16 RS | Marau | 12 | 1 | . 2020-04-16 AC | Acrelândia | 12 | 0 | . 2020-04-16 SP | Rio Claro | 12 | 3 | . 2020-04-16 BA | Uruçuca | 12 | 2 | . 2020-04-16 AM | Tonantins | 12 | 0 | . 2020-04-16 BA | Porto Seguro | 12 | 0 | . 2020-04-16 MS | Três Lagoas | 11 | 1 | . 2020-04-16 SC | Antônio Carlos | 11 | 3 | . 2020-04-16 PR | Ibema | 11 | 0 | . 2020-04-16 MG | Importados/Indefinidos | 11 | 0 | . 2020-04-16 PE | Vitória de Santo Antão | 11 | 2 | . 2020-04-16 SC | Lages | 11 | 0 | . 2020-04-16 RJ | Barra do Piraí | 11 | 2 | . 2020-04-16 AM | Parintins | 11 | 3 | . 2020-04-16 CE | Quixadá | 11 | 0 | . 2020-04-16 SP | Jandira | 11 | 1 | . 2020-04-16 RS | Bento Gonçalves | 11 | 0 | . 2020-04-16 RJ | Rio das Ostras | 11 | 3 | . 2020-04-16 CE | Maranguape | 10 | 2 | . 2020-04-16 RJ | Araruama | 10 | 1 | . 2020-04-16 PR | Paranaguá | 10 | 2 | . 2020-04-16 SP | Vinhedo | 10 | 0 | . 2020-04-16 AM | São Paulo de Olivença | 10 | 0 | . 2020-04-16 MS | Dourados | 10 | 0 | . 2020-04-16 PE | Caruaru | 10 | 1 | . 2020-04-16 CE | Horizonte | 10 | 1 | . 2020-04-16 MG | Varginha | 10 | 1 | . 2020-04-16 SC | Navegantes | 10 | 0 | . 2020-04-16 PR | Paranavaí | 10 | 1 | . 2020-04-16 MS | Nova Andradina | 10 | 0 | . 2020-04-16 SC | Gravatal | 10 | 0 | . 2020-04-16 MG | Extrema | 10 | 0 | . 2020-04-16 AM | Santo Antônio do Içá | 10 | 0 | . 2020-04-16 MG | Betim | 9 | 0 | .",
            "url": "https://covid19graficos.github.io/relatorio/coronavirus/2020/04/17/corona-brasil-interativo.html",
            "relUrl": "/coronavirus/2020/04/17/corona-brasil-interativo.html",
            "date": " • Apr 17, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Projeção do Covid-19 no Brasil",
            "content": "Gr&#225;ficos . Proje&#231;&#227;o do n&#250;mero de casos no Brasil para a pr&#243;xima semana . Proje&#231;&#227;o do n&#250;mero de &#243;bitos no Brasil para a pr&#243;xima semana . N&#250;mero de Casos Novos Confirmados . N&#250;meros de &#211;bitos Novos . Agradecimentos e Contribui&#231;&#245;es . Ívi M. de Carvalho, D. Sc. | . (Para Programadores) C&#243;digo para gera&#231;&#227;o dos gr&#225;ficos . NOTA: O resto desse relatório está focado no desenvolvimento dos gráficos mostrados acima. Somente é relevante caso tenha interesse em Python e Data Analysis . Neste relatório vamos desenvolver em Python uma projeção que pode ser atualizada em tempo real do número de casos de Covid-19 no Brasil. Devido à sua natureza com crescimento exponencial, podemos fazer projeções de curto/médio prazo de acordo com tal tendência. É importante salientar que não existe nenhuma exponencial pura. Em algum momento haverá um ponto de inflexão (quando o número de casos começa a diminuir) e esta exponencial se tornará um sigmóide (como já é o caso da China). Portanto, como não há como prever quando ocorrerá essa inflexão, as projeções somente são úteis para curto e médio prazo. Sem mais delongas, vamos começar! Primeiramente, todas as importações que serão utilizadas: . # Todas as importações vem aqui import numpy as np import pandas as pd; import matplotlib.pyplot as plt import seaborn as sns; from sklearn.linear_model import LinearRegression from datetime import date . E também parâmetros: . FIGSIZE = (8,4) . Em seguida, vamos importar a base de dados disponibilizada pelo repositório da John Hopkins University. Há duas bases relevantes para nosso caso, uma com o histórico do número de casos e outro com o histório do número de mortes (ambos obtido a partir dos relatórios diários da OMS). . CASOS_URL = &#39;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv&#39; MORTES_URL = &#39;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv&#39; . Ambos são urls diretas para arquivos .CSV, portanto podemos importá-los diretamente para a biblioteca Pandas do Python, sem precisar baixá-los: . casos = pd.read_csv(CASOS_URL) mortes = pd.read_csv(MORTES_URL) . Vamos visualizar o cabeçalho de cada um: . casos.head() . Province/State Country/Region Lat Long 1/22/20 1/23/20 1/24/20 1/25/20 1/26/20 1/27/20 1/28/20 1/29/20 1/30/20 1/31/20 2/1/20 2/2/20 2/3/20 2/4/20 2/5/20 2/6/20 2/7/20 2/8/20 2/9/20 2/10/20 2/11/20 2/12/20 2/13/20 2/14/20 2/15/20 2/16/20 2/17/20 2/18/20 2/19/20 2/20/20 2/21/20 2/22/20 2/23/20 2/24/20 2/25/20 2/26/20 ... 3/7/20 3/8/20 3/9/20 3/10/20 3/11/20 3/12/20 3/13/20 3/14/20 3/15/20 3/16/20 3/17/20 3/18/20 3/19/20 3/20/20 3/21/20 3/22/20 3/23/20 3/24/20 3/25/20 3/26/20 3/27/20 3/28/20 3/29/20 3/30/20 3/31/20 4/1/20 4/2/20 4/3/20 4/4/20 4/5/20 4/6/20 4/7/20 4/8/20 4/9/20 4/10/20 4/11/20 4/12/20 4/13/20 4/14/20 4/15/20 . 0 NaN | Afghanistan | 33.0000 | 65.0000 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | ... | 1 | 4 | 4 | 5 | 7 | 7 | 7 | 11 | 16 | 21 | 22 | 22 | 22 | 24 | 24 | 40 | 40 | 74 | 84 | 94 | 110 | 110 | 120 | 170 | 174 | 237 | 273 | 281 | 299 | 349 | 367 | 423 | 444 | 484 | 521 | 555 | 607 | 665 | 714 | 784 | . 1 NaN | Albania | 41.1533 | 20.1683 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 2 | 10 | 12 | 23 | 33 | 38 | 42 | 51 | 55 | 59 | 64 | 70 | 76 | 89 | 104 | 123 | 146 | 174 | 186 | 197 | 212 | 223 | 243 | 259 | 277 | 304 | 333 | 361 | 377 | 383 | 400 | 409 | 416 | 433 | 446 | 467 | 475 | 494 | . 2 NaN | Algeria | 28.0339 | 1.6596 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | ... | 17 | 19 | 20 | 20 | 20 | 24 | 26 | 37 | 48 | 54 | 60 | 74 | 87 | 90 | 139 | 201 | 230 | 264 | 302 | 367 | 409 | 454 | 511 | 584 | 716 | 847 | 986 | 1171 | 1251 | 1320 | 1423 | 1468 | 1572 | 1666 | 1761 | 1825 | 1914 | 1983 | 2070 | 2160 | . 3 NaN | Andorra | 42.5063 | 1.5218 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 2 | 39 | 39 | 53 | 75 | 88 | 113 | 133 | 164 | 188 | 224 | 267 | 308 | 334 | 370 | 376 | 390 | 428 | 439 | 466 | 501 | 525 | 545 | 564 | 583 | 601 | 601 | 638 | 646 | 659 | 673 | . 4 NaN | Angola | -11.2027 | 17.8739 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 2 | 2 | 3 | 3 | 3 | 4 | 4 | 5 | 7 | 7 | 7 | 8 | 8 | 8 | 10 | 14 | 16 | 17 | 19 | 19 | 19 | 19 | 19 | 19 | 19 | 19 | . 5 rows × 89 columns . mortes.head() . Province/State Country/Region Lat Long 1/22/20 1/23/20 1/24/20 1/25/20 1/26/20 1/27/20 1/28/20 1/29/20 1/30/20 1/31/20 2/1/20 2/2/20 2/3/20 2/4/20 2/5/20 2/6/20 2/7/20 2/8/20 2/9/20 2/10/20 2/11/20 2/12/20 2/13/20 2/14/20 2/15/20 2/16/20 2/17/20 2/18/20 2/19/20 2/20/20 2/21/20 2/22/20 2/23/20 2/24/20 2/25/20 2/26/20 ... 3/7/20 3/8/20 3/9/20 3/10/20 3/11/20 3/12/20 3/13/20 3/14/20 3/15/20 3/16/20 3/17/20 3/18/20 3/19/20 3/20/20 3/21/20 3/22/20 3/23/20 3/24/20 3/25/20 3/26/20 3/27/20 3/28/20 3/29/20 3/30/20 3/31/20 4/1/20 4/2/20 4/3/20 4/4/20 4/5/20 4/6/20 4/7/20 4/8/20 4/9/20 4/10/20 4/11/20 4/12/20 4/13/20 4/14/20 4/15/20 . 0 NaN | Afghanistan | 33.0000 | 65.0000 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 2 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | 6 | 6 | 7 | 7 | 11 | 14 | 14 | 15 | 15 | 18 | 18 | 21 | 23 | 25 | . 1 NaN | Albania | 41.1533 | 20.1683 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 2 | 2 | 2 | 2 | 2 | 4 | 5 | 5 | 6 | 8 | 10 | 10 | 11 | 15 | 15 | 16 | 17 | 20 | 20 | 21 | 22 | 22 | 23 | 23 | 23 | 23 | 23 | 24 | 25 | . 2 NaN | Algeria | 28.0339 | 1.6596 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 1 | 2 | 3 | 4 | 4 | 4 | 7 | 9 | 11 | 15 | 17 | 17 | 19 | 21 | 25 | 26 | 29 | 31 | 35 | 44 | 58 | 86 | 105 | 130 | 152 | 173 | 193 | 205 | 235 | 256 | 275 | 293 | 313 | 326 | 336 | . 3 NaN | Andorra | 42.5063 | 1.5218 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 3 | 3 | 3 | 6 | 8 | 12 | 14 | 15 | 16 | 17 | 18 | 21 | 22 | 23 | 25 | 26 | 26 | 29 | 29 | 31 | 33 | . 4 NaN | Angola | -11.2027 | 17.8739 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | . 5 rows × 89 columns . Como para este relatório temos interesse em apenas dados do Brasil, vamos atribuir duas novas variáveis à ambos: . def filter_country(df, country): # Filtrar pais df = df[df[&#39;Country/Region&#39;]==country] # Remover colunas iniciais, manter somente as datas df = df.iloc[:, 4:] # Transpor df = df.T # Redefinir coluna df.columns = [country] # Definir index para Datetime df.index = pd.to_datetime(df.index) return df casos_brasil = filter_country(casos, &#39;Brazil&#39;) mortes_brasil = filter_country(mortes, &#39;Brazil&#39;) . Vamos ver como ficaram os novos dataframes: . casos_brasil.tail() . Brazil . 2020-04-11 20727 | . 2020-04-12 22192 | . 2020-04-13 23430 | . 2020-04-14 25262 | . 2020-04-15 28320 | . mortes_brasil.tail() . Brazil . 2020-04-11 1124 | . 2020-04-12 1223 | . 2020-04-13 1328 | . 2020-04-14 1532 | . 2020-04-15 1736 | . Podemos facilmente também plotar tais dados para ver como estão: . casos_brasil.plot(title=&#39;Número de casos&#39;); . mortes_brasil.plot(title=&#39;Número de mortes&#39;); . Podemos conferir se o número de casos está se acelerando ou não plotando um gráfico de barras do número de casos por dia. Isso será importante para identificar a inflexão! . casos_novos_brasil = casos_brasil[1:]-casos_brasil[:-1].values casos_novos_brasil.tail() . Brazil . 2020-04-11 1089 | . 2020-04-12 1465 | . 2020-04-13 1238 | . 2020-04-14 1832 | . 2020-04-15 3058 | . mortes_novas_brasil = mortes_brasil[1:]-mortes_brasil[:-1].values mortes_novas_brasil.tail() . Brazil . 2020-04-11 67 | . 2020-04-12 99 | . 2020-04-13 105 | . 2020-04-14 204 | . 2020-04-15 204 | . Em seguida vamos visualizar ambos em um gráfico de barras: . # Funcao personalizada def plot_bar_novos(df, title): df.index = df.index.strftime(&#39;%d/%m&#39;)#astype(&#39;str&#39;) ax = df.plot.bar( title=title, figsize=FIGSIZE ) _=plt.xticks(rotation=50) return ax . primeiro_caso_filtro = casos_novos_brasil.values&gt;0 ax=plot_bar_novos(casos_novos_brasil[primeiro_caso_filtro], title=&#39;Casos novos (sem acumular, a partir do primeiro caso)&#39;, ) . # Filtrar a partir do primeiro obito primeiro_obito_filtro = mortes_novas_brasil.values&gt;0 # Criar plot ax=plot_bar_novos(mortes_novas_brasil[primeiro_obito_filtro], title=&#39;Óbitos novos (sem acumular, a partir do primeiro óbito)&#39; ) . ax.figure.savefig(&#39;obitos_novos.png&#39;, dpi=300) . Vamos agora dar início à modelagem das projeções. Primeiramente, vamos fazer alguns plots em cima do log dos dados: . casos_brasil[&#39;Brazil&#39;].apply(np.log).plot(marker=&#39;o&#39;, linestyle=&#39;&#39;, title=&#39;Log do Número de casos&#39;); . mortes_brasil[&#39;Brazil&#39;].apply(np.log).plot(marker=&#39;o&#39;, linestyle=&#39;&#39;, title=&#39;Log do Número de Mortes&#39;); . casos_novos_brasil.apply(np.log).plot(marker=&#39;o&#39;, linestyle=&#39;&#39;, title=&#39;Log do número de casos novos&#39;); . mortes_novas_brasil.apply(np.log).plot(marker=&#39;o&#39;, linestyle=&#39;&#39;, title=&#39;Log de novas mortes&#39;); . Todas as curvas acima não representam uma reta perfeita, o que são ótimas notícias: Significa que talvez não esteja mais seguindo uma tendência exponencial. De qualquer forma, vou usar como ponto de partida uma regressão linear, apesar de haverem ressalvas sobre o uso dela. Por simplificação, vou começar com uma projeção do número total de casos e de mortes. Primeiramente, vou juntar todos os dados em um único dataframe: . brasil = pd.DataFrame({ &#39;Confirmados Cumulativo&#39;: casos_brasil[&#39;Brazil&#39;].values[1:], &#39;Confirmados Novos&#39;: casos_novos_brasil[&#39;Brazil&#39;].values, &#39;Mortes Cumulativa&#39;: mortes_brasil[&#39;Brazil&#39;].values[1:], &#39;Mortes Novas&#39;: mortes_novas_brasil[&#39;Brazil&#39;].values }) brasil.index = casos_novos_brasil.index brasil.tail() . Confirmados Cumulativo Confirmados Novos Mortes Cumulativa Mortes Novas . 2020-04-11 20727 | 1089 | 1124 | 67 | . 2020-04-12 22192 | 1465 | 1223 | 99 | . 2020-04-13 23430 | 1238 | 1328 | 105 | . 2020-04-14 25262 | 1832 | 1532 | 204 | . 2020-04-15 28320 | 3058 | 1736 | 204 | . Também podemos criar um dataframe com o log de todos os dados: . brasil_log = brasil.apply(np.log1p) brasil_log.tail() . Confirmados Cumulativo Confirmados Novos Mortes Cumulativa Mortes Novas . 2020-04-11 9.939241 | 6.993933 | 7.025538 | 4.219508 | . 2020-04-12 10.007532 | 7.290293 | 7.109879 | 4.605170 | . 2020-04-13 10.061815 | 7.122060 | 7.192182 | 4.663439 | . 2020-04-14 10.137096 | 7.513709 | 7.334982 | 5.323010 | . 2020-04-15 10.251359 | 8.025843 | 7.459915 | 5.323010 | . Vamos visualizar a distribuição de cada um e também scatter plots de cada um versus o outro: . pd.plotting.scatter_matrix(brasil_log, figsize = (14,8), diagonal = &#39;kde&#39;); . O plot acima fica um pouco enviesado pois há um grande acúmulo de zeros. Vamos filtrar as datas a partir do promeiro óbito: . primeiro_obito = brasil_log.index[brasil_log[&#39;Mortes Cumulativa&#39;]&gt;0][0] primeiro_obito_filtro = brasil_log.index&gt;=primeiro_obito primeiro_obito . Timestamp(&#39;2020-03-17 00:00:00&#39;) . Como é uma base bastante recente, vamos também pegar o primeiro caso: . primeiro_caso = brasil_log.index[brasil_log[&#39;Confirmados Cumulativo&#39;]&gt;0][0] primeiro_caso_filtro = brasil_log.index&gt;=primeiro_caso primeiro_caso . Timestamp(&#39;2020-02-26 00:00:00&#39;) . Vamos repetir o scatter matrix acima a partir dos filtros que definimos: . g = sns.pairplot(brasil[primeiro_obito_filtro], kind=&quot;reg&quot;) g.fig.tight_layout() g.fig.subplots_adjust(top=0.88) g.fig.suptitle(&#39;Grade de gráficos, dados a partir do primeiro óbito&#39;, y=0.92); . g = sns.pairplot(brasil[primeiro_caso_filtro], kind=&quot;reg&quot;) g.fig.suptitle(&#39;Scatter Matrix com filtro a partir do primeiro caso&#39;, y=1.08); . g = sns.pairplot(brasil_log[primeiro_obito_filtro], kind=&quot;reg&quot;) g.fig.suptitle(&#39;Scatter Matrix do Log dos dados com filtro a partir do primeiro óbito&#39;, y=1.08); . g = sns.pairplot(brasil_log[primeiro_obito_filtro], kind=&quot;reg&quot;) g.fig.suptitle(&#39;Scatter Matrix do Log dos dados com filtro a partir do primeiro óbito&#39;, y=1.08); . Os plots acima, talvez pareçam informação irrelevante, mas o fiz para ter uma ideia sobre a distribuição dos dados e se há alguma distribuição normal em algum caso, que justificaria o uso do desvio padrão (uma vez que o mesmo é em relação à distribuição normal). De qualquer forma, para manter as coisas simples inicialmente, vou manter meu plano inicial de criar uma projeção do número de casos incluindo o intervalo do desvio padrão. Então vamos começar pegando o as estatísticas filtrando a partir do primeiro caso: . std = brasil_log[primeiro_caso_filtro].std() . Visualizar um plot da tendência que vamos modelar: . brasil_log[primeiro_caso_filtro][&#39;Confirmados Cumulativo&#39;].plot() . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f3da3b140f0&gt; . Em seguida ajustar uma regressão linear em cima do log: . def fitar(x, y): lr = LinearRegression() lr.fit(x,y) return lr x = np.arange(sum(primeiro_caso_filtro)).reshape(-1,1) y = brasil_log[primeiro_caso_filtro][&#39;Confirmados Cumulativo&#39;].values lr_casos = fitar(x, y) . def projetar(lr, x, y, plot=True): y_pred = lr.predict(x) if plot: plt.scatter(x, y) plt.plot(y_pred, &#39;r&#39;) plt.title(&quot;Projeção logarítmica&quot;) plt.show() plt.scatter(x, np.expm1(y)) plt.plot(np.expm1(y_pred), &#39;r&#39;) plt.title(&quot;Projeção exponencial&quot;) plt.show() return y_pred y_pred = projetar(lr_casos, x, y) . A projeção acima não ficou boa, vamos testar suavizar com um exponential moving average: . def generate_moving_average(data, mom=0.7): MOM = 0.7 rolling_mean = [data[0]] for d in data[1:]: rolling_mean.append(rolling_mean[-1]*MOM + (1-MOM)*d) return np.array(rolling_mean) def fitar_projetar(x, y, mom=None): if mom is not None: y_old = y y = generate_moving_average(y) lr = fitar(x, y) y_pred = projetar(lr, x, y, plot=not mom) # Plota se mom for nulo if mom is not None: y_pred_exp = np.expm1(y_pred) reversed_mv = [(rm-rm_*mom)/(1-mom) for rm, rm_ in zip(y_pred_exp[1:], y_pred_exp[:-1])] plt.scatter(x, np.expm1(y_old), label=&quot;Original&quot;) plt.scatter(x, np.expm1(y), label=&quot;Exp. Moving Average&quot;) plt.plot(y_pred_exp, &#39;r&#39;, label=&quot;Projeção do EMA&quot;) plt.plot(reversed_mv, label=&quot;EMA reverso para projeção real&quot;) plt.legend() plt.title(f&quot;Projeção com Exp. Moving Average (momentum = {mom})&quot;) plt.show() return y_pred y_pred = fitar_projetar(x, y, mom=0.5) . Também não ficou muito boa. Um dos motivos de estas funções não estarem se saindo bem é que o erro está sendo inferido na escala logarítmica, ou seja, enquanto estamos na escala logarítmica, o erro em termos absolutos é pequeno, no entanto, quando passamos à escala normal, o erro aumenta consideravelmente. Parra corrigir isso, precisamos ajustar uma função exponencial diretamente sem realizar a transformação logarítmica. Precisamos de uma função de custo que infira o erro diretamente da exponencial. Podemos fazer isso com o auxílio de otimizadores de redes neurais. Vamos também aproveitar para ajustar uma sigmóide. E aqui um detalhe: para quem é de machine learning, as boas práticas de seleção de modelos não se aplicam aqui (por exemplo, divisão treinamento e teste). Como os modelos a serem ajustados são bastante simples, não há a necessidade de reservar um conjunto de validação/teste. . # Creating a model from keras.models import Sequential; from keras.layers import Dense from keras import backend as K from keras.optimizers import Adam from keras.activations import sigmoid, elu def get_keras_model(lr=0.001, activation=&#39;exp&#39;): if activation==&#39;exp&#39;: def activ_func(x): return K.exp(x) - 1 elif activation==&#39;sigm&#39;: activ_func = sigmoid elif activation==&#39;elu&#39;: activ_func = elu # Usage model = Sequential(); model.add(Dense(1, input_dim=1, activation=activ_func)) model.compile(optimizer=Adam(lr=lr), loss=&#39;mean_squared_error&#39;) return model . # Definir entrada e saida x = np.arange(sum(primeiro_caso_filtro)).reshape(-1,1) y = brasil[primeiro_caso_filtro][&#39;Confirmados Cumulativo&#39;].values . # Preparar dados def preparar_dados(x, y): x_mean = x.mean() x_std = x.std() y_mean = y.mean() y_std = y.std() x_prep = (x-x_mean)/x_std y_prep = (y-y_mean)/y_std return x_prep, y_prep x_prep, y_prep = preparar_dados(x, y) . #hide_output model = get_keras_model(lr=0.1) model.fit(x_prep, y_prep, epochs=100, verbose=0); . from sklearn.metrics import r2_score . def projetar_keras(model, x, y, days_ahead=0, plot=True, model_func=&quot;exponencial&quot;, tipo=&#39;caso&#39;, exibir_pontos=False, anotar_dados_reais=True, dados_reais_step=2): title = f&#39;Projeção {model_func} de {tipo}s de Covid-19 no Brasil&#39; + f&#39; para os próximos {days_ahead} dias&#39; hoje = date.today() hoje = hoje.strftime(&quot;%d/%m&quot;) x_mean = x.mean() x_std = x.std() y_mean = y.mean() y_std = y.std() n_days = len(x) x_proj = np.arange(n_days+days_ahead).reshape(-1,1) x_prep = (x_proj-x_mean)/x_std y_prep = (y-y_mean)/y_std y_pred = model.predict(x_prep) y_pred = y_pred*y_std + y_mean #Reverse y_pred back y_pred = y_pred.astype(int) y_pred = np.clip(y_pred, 0, None) y_pred = y_pred.squeeze() #print(y) #print(y_pred) r2 = r2_score(y, y_pred[:-days_ahead]) if plot: fig = plt.figure(figsize=FIGSIZE) # Plotar projeção plt.plot(x_proj[-days_ahead-1:], y_pred[-days_ahead-1:], &#39;-&#39;, color=&#39;red&#39;, label=&#39;Projeção&#39;) # Plotar função if exibir_pontos: plt.plot(x_proj[:-days_ahead], y_pred[:-days_ahead], &#39;-&#39;, color=&#39;red&#39;, label=f&#39;Ajuste {model_func} (R²={r2:.2f})&#39;, alpha=0.4) #plt.scatter(x, y, label=&#39;Dados reais&#39;, color=&#39;orange&#39;) plt.plot(y, &#39;.&#39;, label=&#39;Dados reais&#39;) plt.title(title) for x_anot, y_anot in zip(x_proj[-days_ahead:], y_pred[-days_ahead:]): plt.annotate(y_anot, (x_anot, y_anot), ha=&#39;right&#39;, color=&#39;red&#39;) plt.annotate(f&#39;({hoje}): {y[-1]}&#39;, (x[-1], y[-1]), ha=&#39;right&#39;, color=&#39;black&#39;, textcoords=&quot;offset points&quot;, xytext=(-5,0)) if anotar_dados_reais: for x_anot, y_anot in zip(x[:-1:dados_reais_step], y[:-1:dados_reais_step]): plt.annotate(y_anot, (x_anot, y_anot), ha=&#39;right&#39;, color=&#39;midnightblue&#39;, textcoords=&quot;offset points&quot;, xytext=(-5,3) ) plt.grid(color=&#39;black&#39;, linestyle=&#39;--&#39;, linewidth=0.17) plt.legend() plt.xlabel(f&quot;Dias desde o primeiro {tipo} no Brasil&quot;) plt.ylabel(f&#39;{tipo.capitalize()}s confirmados acumulados&#39;) plt.xticks(x_proj[::2]) plt.show() return y_pred, fig . y_pred, fig = projetar_keras(model, x, y, days_ahead=7, exibir_pontos=True, anotar_dados_reais=False, dados_reais_step=3) . Por curiosidade, vamos testar ajustar um sigmóide: . #hide_output model = get_keras_model(lr=1, activation=&#39;sigm&#39;) model.fit(x_prep, y_prep, epochs=100, verbose=0); . y_pred, fig = projetar_keras(model, x, y, days_ahead=5, model_func=&#39;sigmóide&#39;, exibir_pontos=True) . Bem distante do esperado :) Vamos testar também o ELU: . #hide_output model = get_keras_model(lr=0.1, activation=&#39;elu&#39;) model.fit(x_prep, y_prep, epochs=100, verbose=0); . y_pred, fig = projetar_keras(model, x, y, days_ahead=7, model_func=&quot;ELU (Exp. Linear Unit)&quot;, exibir_pontos=True) . Um pouco melhor, mas neste caso com tendência linear. Vamos também replicar estes dois últimos para o número de óbitos. . # Definir entrada e saida x = np.arange(sum(primeiro_obito_filtro)).reshape(-1,1) y = brasil[primeiro_obito_filtro][&#39;Mortes Cumulativa&#39;].values x_prep, y_prep = preparar_dados(x, y) . #hide_output model = get_keras_model(lr=0.1, activation=&#39;exp&#39;) model.fit(x_prep, y_prep, epochs=100, verbose=0); . y_pred, fig = projetar_keras(model, x, y, days_ahead=7, model_func=&quot;exponencial&quot;, tipo=&#39;obito&#39;, exibir_pontos=True, anotar_dados_reais=False, dados_reais_step=3) . #hide_output model = get_keras_model(lr=0.1, activation=&#39;elu&#39;) model.fit(x_prep, y_prep, epochs=100, verbose=0); . y_pred, fig = projetar_keras(model, x, y, days_ahead=7, model_func=&quot;ELU (Exp. Linear Unit)&quot;, tipo=&#39;obito&#39;, exibir_pontos=True) .",
            "url": "https://covid19graficos.github.io/relatorio/coronavirus/2020/04/15/projecao-brasil.html",
            "relUrl": "/coronavirus/2020/04/15/projecao-brasil.html",
            "date": " • Apr 15, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Sobre este website . Este website foi criado utilizando fastpages no qual permite a conversão automática de arquivos do Jupyter notebook em páginas da web. Temos o objetivo de tornar análises comparativas do Brasil com o resto do mundo de maneira à melhor informar a população. Sugestões de relatórios podem ser submetidas em nosso repositório. . Desenvolvedores . Vinicius Bastos Gomes Linkedin: https://www.linkedin.com/in/vinicius-gomes-phd-490557163/ | Github: https://github.com/ViniciusBG | . | Fernando Marcos Wittmann LinkedIn: https://www.linkedin.com/in/fernandowittmann/ | GitHub: https://github.com/WittmannF | . | . Fontes . John Hopkins University: https://github.com/CSSEGISandData/COVID-19 | Brasil.io: https://brasil.io/dataset/covid19/boletim | Ministério da Saúde: https://covid.saude.gov.br/ | . As fontes de cada relatório podem também ser conferidas em nossos notebooks. .",
          "url": "https://covid19graficos.github.io/relatorio/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}