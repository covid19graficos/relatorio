{
  
    
        "post0": {
            "title": "Mundo - comparações entre países",
            "content": "Fonte: https://opendata.ecdc.europa.eu/covid19/casedistribution/csv . Gráficos de contaminação . Os gráficos a seguir apresentam curvas de contaminação de diversos países. Foram criados com o intuito de comparar estratégias de combate à disseminação do vírus. É importante notar que as curvas de contaminação estão amplamente relacionadas à quantidade de testes que os países tem realizado. A seção contem duas aproximações e duas versões do gáfico completo: nas escalas aritmética e logarítmica. . . . . . Contaminação Relativa . Essa seção conta com gráficos em que o número de casos é dívidido pela população dos países para que se tenha uma ideia da proporção de infectados por país. . . . . . Mortes . . . . . Letalidade . O gráfco a seguir aponta o número de mortes dividido pelo número de casos confirmados. É importantíssimo notar a grande dependência desses números da quantidade de testes disponíveis. Quanto mais testes realizados, mais confiáveis os dados. . . . . . O gráfico abaixo representa uma estimativa simples da quantidade de casos atualmente no Brasil. Uma vez que a baixa quantidade de testes tem levado os números a uma subnotificação, o cálculo foi realizado com base no número de óbitos registrados por COVID-19 no Brasil e na taxa da Alemanha, país que tem testado massivamente sua população. Desse modo os números são os seguintes: . Número atual de casos registrados no Brasil hoje: 20727 Estimativa de casos no Brasil hoje caso a letalidade seja próxima à da Alemanha: 50630 . . .",
            "url": "https://covid19graficos.github.io/relatorio/coronavirus/2020/04/12/corona-mundo-interativo.html",
            "relUrl": "/coronavirus/2020/04/12/corona-mundo-interativo.html",
            "date": " • Apr 12, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Brasil - comparações entre estados, regiões e cidades.",
            "content": "Gráficos de contaminação . Casos novos no país. . . . Os gráficos a seguir apresentam curvas de contaminação dos estados brasileiros. É importante notar que as curvas de contaminação estão amplamente relacionadas à quantidade de testes que os países tem realizado. Até o momento estarão apenas na escala aritmética. . . . Essa seção conta com gráficos em que o número de casos é dívidido pela população dos estados para que se tenha uma ideia da proporção de infectados por país. . . . O gráfico a seguir é um comparativo de casos totais por estado no Brasil. . . . O gráfico a seguir é um comparativo a proporção de habitantes infectados por estado no Brasil. . . . Curvas de contaminação por regiões . Comparações entre as regiões do Brasil. Primeiramente uma soma dos casos por regiões e, posteriormente, uma comparação entre os estados das regiões. . . . . . . . . . . . . . . . . . . . . . . . Óbitos . . . Comparações entre as regiões do Brasil. Primeiramente uma soma dos casos por regiões e, posteriormente, uma comparação entre os estados das regiões. . . . Óbitos por regiões . . . . . . . . . . . . . Letalidade por estado brasileiro . . . . . Capitais brasileiras . Comparações entre as capitais de estados do Brasil . . . . . Linhas de todas as cidades . . . . . 200 cidades com maiores números de casos . cidade_last.columns . Index([&#39;state&#39;, &#39;city&#39;, &#39;confirmed&#39;, &#39;deaths&#39;, &#39;data&#39;], dtype=&#39;object&#39;) . Estado Cidade Casos Mortes . date . 2020-04-11 SP | São Paulo | 6131 | 422.0 | . 2020-04-11 RJ | Rio de Janeiro | 1905 | 98.0 | . 2020-04-11 CE | Fortaleza | 1457 | 58.0 | . 2020-04-11 PE | Recife | 486 | 34.0 | . 2020-04-11 MG | Belo Horizonte | 338 | 6.0 | . 2020-04-11 MA | São Luís | 333 | 22.0 | . 2020-04-11 RS | Porto Alegre | 311 | 6.0 | . 2020-04-11 PR | Curitiba | 279 | 5.0 | . 2020-04-11 SP | Guarulhos | 191 | 16.0 | . 2020-04-11 SC | Florianópolis | 173 | 3.0 | . 2020-04-11 SP | São Bernardo do Campo | 172 | 9.0 | . 2020-04-11 AP | Macapá | 171 | 3.0 | . 2020-04-11 SP | Santos | 146 | 6.0 | . 2020-04-11 SP | Santo André | 142 | 3.0 | . 2020-04-11 SP | Osasco | 127 | 8.0 | . 2020-04-11 RJ | Niterói | 120 | 6.0 | . 2020-04-11 GO | Goiânia | 114 | 5.0 | . 2020-04-11 ES | Vila Velha | 114 | 2.0 | . 2020-04-11 ES | Vitória | 101 | 2.0 | . 2020-04-11 SP | Campinas | 100 | 5.0 | . 2020-04-11 SP | São José dos Campos | 85 | 1.0 | . 2020-04-11 ES | Serra | 80 | 3.0 | . 2020-04-11 SP | Importados/Indefinidos | 79 | 0.0 | . 2020-04-11 RJ | Nova Iguaçu | 73 | 3.0 | . 2020-04-11 RJ | Volta Redonda | 71 | 6.0 | . 2020-04-11 SP | Taboão da Serra | 71 | 5.0 | . 2020-04-11 RR | Boa Vista | 70 | 2.0 | . 2020-04-11 RJ | São Gonçalo | 64 | 4.0 | . 2020-04-11 MT | Cuiabá | 64 | 0.0 | . 2020-04-11 RJ | Duque de Caxias | 62 | 16.0 | . 2020-04-11 PR | Londrina | 62 | 3.0 | . 2020-04-11 SC | Blumenau | 61 | 0.0 | . 2020-04-11 SP | São Caetano do Sul | 61 | 2.0 | . 2020-04-11 SP | Diadema | 60 | 1.0 | . 2020-04-11 SP | Cotia | 59 | 4.0 | . 2020-04-11 MG | Juiz de Fora | 58 | 1.0 | . 2020-04-11 PR | Cascavel | 58 | 2.0 | . 2020-04-11 PE | Jaboatão dos Guararapes | 57 | 3.0 | . 2020-04-11 PE | Olinda | 57 | 6.0 | . 2020-04-11 AC | Rio Branco | 57 | 2.0 | . 2020-04-11 SP | Mogi das Cruzes | 56 | 2.0 | . 2020-04-11 SC | Joinville | 52 | 1.0 | . 2020-04-11 SC | Balneário Camboriú | 52 | 0.0 | . 2020-04-11 MS | Campo Grande | 51 | 0.0 | . 2020-04-11 MG | Uberlândia | 47 | 2.0 | . 2020-04-11 MG | Nova Lima | 44 | 0.0 | . 2020-04-11 SP | Mauá | 43 | 0.0 | . 2020-04-11 SP | Barueri | 43 | 2.0 | . 2020-04-11 PE | Paulista | 40 | 0.0 | . 2020-04-11 SP | São José do Rio Preto | 40 | 1.0 | . 2020-04-11 SC | Criciúma | 38 | 3.0 | . 2020-04-11 AL | Maceió | 37 | 3.0 | . 2020-04-11 SC | Itajaí | 36 | 2.0 | . 2020-04-11 SP | Ribeirão Preto | 36 | 4.0 | . 2020-04-11 RS | Caxias do Sul | 34 | 0.0 | . 2020-04-11 SP | Embu das Artes | 34 | 2.0 | . 2020-04-11 SP | Ferraz de Vasconcelos | 34 | 0.0 | . 2020-04-11 SP | Caieiras | 33 | 4.0 | . 2020-04-11 SP | Santana de Parnaíba | 33 | 0.0 | . 2020-04-11 SP | Suzano | 32 | 3.0 | . 2020-04-11 SP | Carapicuíba | 31 | 2.0 | . 2020-04-11 SC | Tubarão | 30 | 1.0 | . 2020-04-11 ES | Cariacica | 30 | 0.0 | . 2020-04-11 RJ | Belford Roxo | 29 | 3.0 | . 2020-04-11 CE | Aquiraz | 29 | 0.0 | . 2020-04-11 PE | São Lourenço da Mata | 28 | 7.0 | . 2020-04-11 RJ | São João de Meriti | 28 | 2.0 | . 2020-04-11 PE | Camaragibe | 28 | 3.0 | . 2020-04-11 PR | Maringá | 27 | 4.0 | . 2020-04-11 PR | Foz do Iguaçu | 27 | 0.0 | . 2020-04-11 RJ | Petrópolis | 27 | 1.0 | . 2020-04-11 RS | Bagé | 27 | 0.0 | . 2020-04-11 SP | Itapecerica da Serra | 27 | 1.0 | . 2020-04-11 MA | São José de Ribamar | 26 | 0.0 | . 2020-04-11 SP | Bragança Paulista | 26 | 4.0 | . 2020-04-11 CE | Caucaia | 26 | 1.0 | . 2020-04-11 SC | Braço do Norte | 25 | 0.0 | . 2020-04-11 RO | Porto Velho | 25 | 2.0 | . 2020-04-11 SP | Itaquaquecetuba | 25 | 0.0 | . 2020-04-11 SC | Camboriú | 25 | 0.0 | . 2020-04-11 SC | São José | 24 | 0.0 | . 2020-04-11 RS | Novo Hamburgo | 24 | 2.0 | . 2020-04-11 RJ | Mesquita | 23 | 1.0 | . 2020-04-11 CE | Maracanaú | 21 | 1.0 | . 2020-04-11 MG | Divinópolis | 21 | 1.0 | . 2020-04-11 AP | Santana | 21 | 2.0 | . 2020-04-11 SP | Sorocaba | 20 | 2.0 | . 2020-04-11 RJ | Itaboraí | 20 | 2.0 | . 2020-04-11 CE | Importados/Indefinidos | 20 | 0.0 | . 2020-04-11 SP | Franco da Rocha | 19 | 1.0 | . 2020-04-11 RS | Passo Fundo | 18 | 2.0 | . 2020-04-11 PR | Campo Mourão | 18 | 4.0 | . 2020-04-11 MG | Contagem | 17 | 0.0 | . 2020-04-11 SP | Itapevi | 17 | 4.0 | . 2020-04-11 MG | Uberaba | 17 | 0.0 | . 2020-04-11 MT | Rondonópolis | 17 | 0.0 | . 2020-04-11 RS | Lajeado | 16 | 0.0 | . 2020-04-11 SP | Praia Grande | 16 | 2.0 | . 2020-04-11 RS | São Leopoldo | 16 | 1.0 | . 2020-04-11 SP | Ribeirão Pires | 16 | 0.0 | . 2020-04-11 SC | Brusque | 16 | 0.0 | . 2020-04-11 MG | Importados/Indefinidos | 16 | 0.0 | . 2020-04-11 TO | Palmas | 15 | 0.0 | . 2020-04-11 SP | Botucatu | 15 | 1.0 | . 2020-04-11 RJ | Maricá | 15 | 2.0 | . 2020-04-11 GO | Anápolis | 15 | 0.0 | . 2020-04-11 MA | Paço do Lumiar | 14 | 2.0 | . 2020-04-11 CE | Sobral | 14 | 0.0 | . 2020-04-11 RJ | Nilópolis | 14 | 0.0 | . 2020-04-11 PE | Cabo de Santo Agostinho | 14 | 4.0 | . 2020-04-11 PE | Fernando de Noronha | 14 | 0.0 | . 2020-04-11 SP | São Vicente | 14 | 0.0 | . 2020-04-11 SP | Araçatuba | 14 | 0.0 | . 2020-04-11 SP | Francisco Morato | 13 | 1.0 | . 2020-04-11 SP | Atibaia | 13 | 0.0 | . 2020-04-11 RS | Canoas | 13 | 1.0 | . 2020-04-11 RJ | Nova Friburgo | 13 | 0.0 | . 2020-04-11 RS | Gravataí | 13 | 0.0 | . 2020-04-11 PR | Cianorte | 13 | 1.0 | . 2020-04-11 PR | Pinhais | 13 | 0.0 | . 2020-04-11 SP | Jundiaí | 13 | 1.0 | . 2020-04-11 PR | Importados/Indefinidos | 12 | 1.0 | . 2020-04-11 SP | Piracicaba | 12 | 0.0 | . 2020-04-11 PR | Campo Largo | 11 | 0.0 | . 2020-04-11 RS | Bento Gonçalves | 11 | 0.0 | . 2020-04-11 PR | São José dos Pinhais | 11 | 0.0 | . 2020-04-11 MG | Pouso Alegre | 11 | 1.0 | . 2020-04-11 RJ | Barra Mansa | 11 | 0.0 | . 2020-04-11 MG | Lagoa da Prata | 11 | 0.0 | . 2020-04-11 RJ | Magé | 11 | 0.0 | . 2020-04-11 SC | Antônio Carlos | 11 | 3.0 | . 2020-04-11 MT | Sinop | 11 | 0.0 | . 2020-04-11 SP | Arujá | 11 | 1.0 | . 2020-04-11 GO | Rio Verde | 11 | 1.0 | . 2020-04-11 SC | Importados/Indefinidos | 11 | 0.0 | . 2020-04-11 SP | Bauru | 10 | 1.0 | . 2020-04-11 RJ | Queimados | 10 | 0.0 | . 2020-04-11 SP | Araraquara | 10 | 1.0 | . 2020-04-11 MA | Imperatriz | 10 | 0.0 | . 2020-04-11 MS | Nova Andradina | 10 | 0.0 | . 2020-04-11 GO | Goianésia | 10 | 0.0 | . 2020-04-11 SC | Jaraguá do Sul | 10 | 0.0 | . 2020-04-11 SC | Imbituba | 9 | 0.0 | . 2020-04-11 ES | Linhares | 9 | 1.0 | . 2020-04-11 MS | Três Lagoas | 9 | 0.0 | . 2020-04-11 SP | Ilha Comprida | 9 | 0.0 | . 2020-04-11 SP | Vinhedo | 9 | 0.0 | . 2020-04-11 RS | Marau | 9 | 1.0 | . 2020-04-11 AC | Acrelândia | 9 | 0.0 | . 2020-04-11 SP | Poá | 9 | 1.0 | . 2020-04-11 RS | Torres | 9 | 0.0 | . 2020-04-11 PR | Arapongas | 9 | 0.0 | . 2020-04-11 SC | Gravatal | 8 | 0.0 | . 2020-04-11 GO | Luziânia | 8 | 2.0 | . 2020-04-11 RJ | Teresópolis | 8 | 0.0 | . 2020-04-11 MG | Betim | 8 | 0.0 | . 2020-04-11 PE | Importados/Indefinidos | 8 | 1.0 | . 2020-04-11 RS | Santa Maria | 8 | 0.0 | . 2020-04-11 SC | Lages | 8 | 0.0 | . 2020-04-11 RS | Viamão | 8 | 0.0 | . 2020-04-11 SP | Guarujá | 7 | 0.0 | . 2020-04-11 CE | Iguatu | 7 | 3.0 | . 2020-04-11 SC | Sombrio | 7 | 1.0 | . 2020-04-11 MG | Varginha | 7 | 1.0 | . 2020-04-11 MS | Dourados | 7 | 0.0 | . 2020-04-11 PR | Araruna | 7 | 0.0 | . 2020-04-11 CE | Horizonte | 7 | 1.0 | . 2020-04-11 MG | Timóteo | 7 | 0.0 | . 2020-04-11 MG | Sabará | 7 | 0.0 | . 2020-04-11 CE | Quixadá | 7 | 0.0 | . 2020-04-11 SP | Mairiporã | 7 | 2.0 | . 2020-04-11 PR | Colombo | 7 | 0.0 | . 2020-04-11 AL | Importados/Indefinidos | 7 | 0.0 | . 2020-04-11 RS | Sant&#39;Ana do Livramento | 7 | 0.0 | . 2020-04-11 SC | Itapema | 7 | 0.0 | . 2020-04-11 SC | Içara | 7 | 0.0 | . 2020-04-11 PR | Telêmaco Borba | 6 | 0.0 | . 2020-04-11 PR | Santa Fé | 6 | 1.0 | . 2020-04-11 SP | Taubaté | 6 | 0.0 | . 2020-04-11 MS | Batayporã | 6 | 2.0 | . 2020-04-11 PE | Paudalho | 6 | 1.0 | . 2020-04-11 RJ | Macaé | 6 | 1.0 | . 2020-04-11 MG | Patos de Minas | 6 | 1.0 | . 2020-04-11 MG | Patrocínio | 6 | 0.0 | . 2020-04-11 SP | Mogi Guaçu | 6 | 1.0 | . 2020-04-11 MS | Sonora | 6 | 0.0 | . 2020-04-11 PE | Caruaru | 6 | 1.0 | . 2020-04-11 SC | Chapecó | 6 | 0.0 | . 2020-04-11 SC | Palhoça | 6 | 1.0 | . 2020-04-11 TO | Araguaína | 6 | 0.0 | . 2020-04-11 SC | São Ludgero | 6 | 1.0 | . 2020-04-11 RS | Cachoeirinha | 6 | 0.0 | . 2020-04-11 GO | Valparaíso de Goiás | 6 | 0.0 | . 2020-04-11 MT | Várzea Grande | 6 | 0.0 | . 2020-04-11 RJ | Resende | 6 | 0.0 | . 2020-04-11 SP | São Carlos | 5 | 2.0 | . 2020-04-11 SP | Paulínia | 5 | 0.0 | . 2020-04-11 RS | Farroupilha | 5 | 0.0 | . 2020-04-11 GO | Itumbiara | 5 | 0.0 | . 2020-04-11 PE | Abreu e Lima | 5 | 0.0 | .",
            "url": "https://covid19graficos.github.io/relatorio/coronavirus/2020/04/12/corona-brasil-interativo.html",
            "relUrl": "/coronavirus/2020/04/12/corona-brasil-interativo.html",
            "date": " • Apr 12, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Projeção do Covid-19 no Brasil",
            "content": "Gr&#225;ficos . Proje&#231;&#227;o do n&#250;mero de casos no Brasil para a pr&#243;xima semana . Proje&#231;&#227;o do n&#250;mero de &#243;bitos no Brasil para a pr&#243;xima semana . N&#250;mero de Casos Novos Confirmados . N&#250;meros de &#211;bitos Novos . Agradecimentos e Contribui&#231;&#245;es . Ívi M. de Carvalho, D. Sc. | . (Para Programadores) C&#243;digo para gera&#231;&#227;o dos gr&#225;ficos . NOTA: O resto desse relatório está focado no desenvolvimento dos gráficos mostrados acima. Somente é relevante caso tenha interesse em Python e Data Analysis . Neste relatório vamos desenvolver em Python uma projeção que pode ser atualizada em tempo real do número de casos de Covid-19 no Brasil. Devido à sua natureza com crescimento exponencial, podemos fazer projeções de curto/médio prazo de acordo com tal tendência. É importante salientar que não existe nenhuma exponencial pura. Em algum momento haverá um ponto de inflexão (quando o número de casos começa a diminuir) e esta exponencial se tornará um sigmóide (como já é o caso da China). Portanto, como não há como prever quando ocorrerá essa inflexão, as projeções somente são úteis para curto e médio prazo. Sem mais delongas, vamos começar! Primeiramente, todas as importações que serão utilizadas: . # Todas as importações vem aqui import numpy as np import pandas as pd; import matplotlib.pyplot as plt import seaborn as sns; from sklearn.linear_model import LinearRegression from datetime import date . E também parâmetros: . FIGSIZE = (8,4) . Em seguida, vamos importar a base de dados disponibilizada pelo repositório da John Hopkins University. Há duas bases relevantes para nosso caso, uma com o histórico do número de casos e outro com o histório do número de mortes (ambos obtido a partir dos relatórios diários da OMS). . CASOS_URL = &#39;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv&#39; MORTES_URL = &#39;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv&#39; . Ambos são urls diretas para arquivos .CSV, portanto podemos importá-los diretamente para a biblioteca Pandas do Python, sem precisar baixá-los: . casos = pd.read_csv(CASOS_URL) mortes = pd.read_csv(MORTES_URL) . Vamos visualizar o cabeçalho de cada um: . casos.head() . Province/State Country/Region Lat Long 1/22/20 1/23/20 1/24/20 1/25/20 1/26/20 1/27/20 1/28/20 1/29/20 1/30/20 1/31/20 2/1/20 2/2/20 2/3/20 2/4/20 2/5/20 2/6/20 2/7/20 2/8/20 2/9/20 2/10/20 2/11/20 2/12/20 2/13/20 2/14/20 2/15/20 2/16/20 2/17/20 2/18/20 2/19/20 2/20/20 2/21/20 2/22/20 2/23/20 2/24/20 2/25/20 2/26/20 ... 3/3/20 3/4/20 3/5/20 3/6/20 3/7/20 3/8/20 3/9/20 3/10/20 3/11/20 3/12/20 3/13/20 3/14/20 3/15/20 3/16/20 3/17/20 3/18/20 3/19/20 3/20/20 3/21/20 3/22/20 3/23/20 3/24/20 3/25/20 3/26/20 3/27/20 3/28/20 3/29/20 3/30/20 3/31/20 4/1/20 4/2/20 4/3/20 4/4/20 4/5/20 4/6/20 4/7/20 4/8/20 4/9/20 4/10/20 4/11/20 . 0 NaN | Afghanistan | 33.0000 | 65.0000 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | ... | 1 | 1 | 1 | 1 | 1 | 4 | 4 | 5 | 7 | 7 | 7 | 11 | 16 | 21 | 22 | 22 | 22 | 24 | 24 | 40 | 40 | 74 | 84 | 94 | 110 | 110 | 120 | 170 | 174 | 237 | 273 | 281 | 299 | 349 | 367 | 423 | 444 | 484 | 521 | 555 | . 1 NaN | Albania | 41.1533 | 20.1683 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 10 | 12 | 23 | 33 | 38 | 42 | 51 | 55 | 59 | 64 | 70 | 76 | 89 | 104 | 123 | 146 | 174 | 186 | 197 | 212 | 223 | 243 | 259 | 277 | 304 | 333 | 361 | 377 | 383 | 400 | 409 | 416 | 433 | . 2 NaN | Algeria | 28.0339 | 1.6596 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | ... | 5 | 12 | 12 | 17 | 17 | 19 | 20 | 20 | 20 | 24 | 26 | 37 | 48 | 54 | 60 | 74 | 87 | 90 | 139 | 201 | 230 | 264 | 302 | 367 | 409 | 454 | 511 | 584 | 716 | 847 | 986 | 1171 | 1251 | 1320 | 1423 | 1468 | 1572 | 1666 | 1761 | 1825 | . 3 NaN | Andorra | 42.5063 | 1.5218 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 2 | 39 | 39 | 53 | 75 | 88 | 113 | 133 | 164 | 188 | 224 | 267 | 308 | 334 | 370 | 376 | 390 | 428 | 439 | 466 | 501 | 525 | 545 | 564 | 583 | 601 | 601 | . 4 NaN | Angola | -11.2027 | 17.8739 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 2 | 2 | 3 | 3 | 3 | 4 | 4 | 5 | 7 | 7 | 7 | 8 | 8 | 8 | 10 | 14 | 16 | 17 | 19 | 19 | 19 | 19 | . 5 rows × 85 columns . mortes.head() . Province/State Country/Region Lat Long 1/22/20 1/23/20 1/24/20 1/25/20 1/26/20 1/27/20 1/28/20 1/29/20 1/30/20 1/31/20 2/1/20 2/2/20 2/3/20 2/4/20 2/5/20 2/6/20 2/7/20 2/8/20 2/9/20 2/10/20 2/11/20 2/12/20 2/13/20 2/14/20 2/15/20 2/16/20 2/17/20 2/18/20 2/19/20 2/20/20 2/21/20 2/22/20 2/23/20 2/24/20 2/25/20 2/26/20 ... 3/3/20 3/4/20 3/5/20 3/6/20 3/7/20 3/8/20 3/9/20 3/10/20 3/11/20 3/12/20 3/13/20 3/14/20 3/15/20 3/16/20 3/17/20 3/18/20 3/19/20 3/20/20 3/21/20 3/22/20 3/23/20 3/24/20 3/25/20 3/26/20 3/27/20 3/28/20 3/29/20 3/30/20 3/31/20 4/1/20 4/2/20 4/3/20 4/4/20 4/5/20 4/6/20 4/7/20 4/8/20 4/9/20 4/10/20 4/11/20 . 0 NaN | Afghanistan | 33.0000 | 65.0000 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 2 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | 6 | 6 | 7 | 7 | 11 | 14 | 14 | 15 | 15 | 18 | . 1 NaN | Albania | 41.1533 | 20.1683 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 2 | 2 | 2 | 2 | 2 | 4 | 5 | 5 | 6 | 8 | 10 | 10 | 11 | 15 | 15 | 16 | 17 | 20 | 20 | 21 | 22 | 22 | 23 | 23 | 23 | . 2 NaN | Algeria | 28.0339 | 1.6596 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 2 | 3 | 4 | 4 | 4 | 7 | 9 | 11 | 15 | 17 | 17 | 19 | 21 | 25 | 26 | 29 | 31 | 35 | 44 | 58 | 86 | 105 | 130 | 152 | 173 | 193 | 205 | 235 | 256 | 275 | . 3 NaN | Andorra | 42.5063 | 1.5218 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 3 | 3 | 3 | 6 | 8 | 12 | 14 | 15 | 16 | 17 | 18 | 21 | 22 | 23 | 25 | 26 | 26 | . 4 NaN | Angola | -11.2027 | 17.8739 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | . 5 rows × 85 columns . Como para este relatório temos interesse em apenas dados do Brasil, vamos atribuir duas novas variáveis à ambos: . def filter_country(df, country): # Filtrar pais df = df[df[&#39;Country/Region&#39;]==country] # Remover colunas iniciais, manter somente as datas df = df.iloc[:, 4:] # Transpor df = df.T # Redefinir coluna df.columns = [country] # Definir index para Datetime df.index = pd.to_datetime(df.index) return df casos_brasil = filter_country(casos, &#39;Brazil&#39;) mortes_brasil = filter_country(mortes, &#39;Brazil&#39;) . Vamos ver como ficaram os novos dataframes: . casos_brasil.tail() . Brazil . 2020-04-07 14034 | . 2020-04-08 16170 | . 2020-04-09 18092 | . 2020-04-10 19638 | . 2020-04-11 20727 | . mortes_brasil.tail() . Brazil . 2020-04-07 686 | . 2020-04-08 819 | . 2020-04-09 950 | . 2020-04-10 1057 | . 2020-04-11 1124 | . Podemos facilmente também plotar tais dados para ver como estão: . casos_brasil.plot(title=&#39;Número de casos&#39;); . mortes_brasil.plot(title=&#39;Número de mortes&#39;); . Podemos conferir se o número de casos está se acelerando ou não plotando um gráfico de barras do número de casos por dia. Isso será importante para identificar a inflexão! . casos_novos_brasil = casos_brasil[1:]-casos_brasil[:-1].values casos_novos_brasil.tail() . Brazil . 2020-04-07 1873 | . 2020-04-08 2136 | . 2020-04-09 1922 | . 2020-04-10 1546 | . 2020-04-11 1089 | . mortes_novas_brasil = mortes_brasil[1:]-mortes_brasil[:-1].values mortes_novas_brasil.tail() . Brazil . 2020-04-07 122 | . 2020-04-08 133 | . 2020-04-09 131 | . 2020-04-10 107 | . 2020-04-11 67 | . Em seguida vamos visualizar ambos em um gráfico de barras: . # Funcao personalizada def plot_bar_novos(df, title): df.index = df.index.strftime(&#39;%d/%m&#39;)#astype(&#39;str&#39;) ax = df.plot.bar( title=title, figsize=FIGSIZE ) _=plt.xticks(rotation=50) return ax . primeiro_caso_filtro = casos_novos_brasil.values&gt;0 ax=plot_bar_novos(casos_novos_brasil[primeiro_caso_filtro], title=&#39;Casos novos (sem acumular, a partir do primeiro caso)&#39;, ) . # Filtrar a partir do primeiro obito primeiro_obito_filtro = mortes_novas_brasil.values&gt;0 # Criar plot ax=plot_bar_novos(mortes_novas_brasil[primeiro_obito_filtro], title=&#39;Óbitos novos (sem acumular, a partir do primeiro óbito)&#39; ) . ax.figure.savefig(&#39;obitos_novos.png&#39;, dpi=300) . Vamos agora dar início à modelagem das projeções. Primeiramente, vamos fazer alguns plots em cima do log dos dados: . casos_brasil[&#39;Brazil&#39;].apply(np.log).plot(marker=&#39;o&#39;, linestyle=&#39;&#39;, title=&#39;Log do Número de casos&#39;); . mortes_brasil[&#39;Brazil&#39;].apply(np.log).plot(marker=&#39;o&#39;, linestyle=&#39;&#39;, title=&#39;Log do Número de Mortes&#39;); . casos_novos_brasil.apply(np.log).plot(marker=&#39;o&#39;, linestyle=&#39;&#39;, title=&#39;Log do número de casos novos&#39;); . mortes_novas_brasil.apply(np.log).plot(marker=&#39;o&#39;, linestyle=&#39;&#39;, title=&#39;Log de novas mortes&#39;); . Todas as curvas acima não representam uma reta perfeita, o que são ótimas notícias: Significa que talvez não esteja mais seguindo uma tendência exponencial. De qualquer forma, vou usar como ponto de partida uma regressão linear, apesar de haverem ressalvas sobre o uso dela. Por simplificação, vou começar com uma projeção do número total de casos e de mortes. Primeiramente, vou juntar todos os dados em um único dataframe: . brasil = pd.DataFrame({ &#39;Confirmados Cumulativo&#39;: casos_brasil[&#39;Brazil&#39;].values[1:], &#39;Confirmados Novos&#39;: casos_novos_brasil[&#39;Brazil&#39;].values, &#39;Mortes Cumulativa&#39;: mortes_brasil[&#39;Brazil&#39;].values[1:], &#39;Mortes Novas&#39;: mortes_novas_brasil[&#39;Brazil&#39;].values }) brasil.index = casos_novos_brasil.index brasil.tail() . Confirmados Cumulativo Confirmados Novos Mortes Cumulativa Mortes Novas . 2020-04-07 14034 | 1873 | 686 | 122 | . 2020-04-08 16170 | 2136 | 819 | 133 | . 2020-04-09 18092 | 1922 | 950 | 131 | . 2020-04-10 19638 | 1546 | 1057 | 107 | . 2020-04-11 20727 | 1089 | 1124 | 67 | . Também podemos criar um dataframe com o log de todos os dados: . brasil_log = brasil.apply(np.log1p) brasil_log.tail() . Confirmados Cumulativo Confirmados Novos Mortes Cumulativa Mortes Novas . 2020-04-07 9.549309 | 7.535830 | 6.532334 | 4.812184 | . 2020-04-08 9.690975 | 7.667158 | 6.709304 | 4.897840 | . 2020-04-09 9.803280 | 7.561642 | 6.857514 | 4.882802 | . 2020-04-10 9.885273 | 7.344073 | 6.964136 | 4.682131 | . 2020-04-11 9.939241 | 6.993933 | 7.025538 | 4.219508 | . Vamos visualizar a distribuição de cada um e também scatter plots de cada um versus o outro: . pd.plotting.scatter_matrix(brasil_log, figsize = (14,8), diagonal = &#39;kde&#39;); . O plot acima fica um pouco enviesado pois há um grande acúmulo de zeros. Vamos filtrar as datas a partir do promeiro óbito: . primeiro_obito = brasil_log.index[brasil_log[&#39;Mortes Cumulativa&#39;]&gt;0][0] primeiro_obito_filtro = brasil_log.index&gt;=primeiro_obito primeiro_obito . Timestamp(&#39;2020-03-17 00:00:00&#39;) . Como é uma base bastante recente, vamos também pegar o primeiro caso: . primeiro_caso = brasil_log.index[brasil_log[&#39;Confirmados Cumulativo&#39;]&gt;0][0] primeiro_caso_filtro = brasil_log.index&gt;=primeiro_caso primeiro_caso . Timestamp(&#39;2020-02-26 00:00:00&#39;) . Vamos repetir o scatter matrix acima a partir dos filtros que definimos: . g = sns.pairplot(brasil[primeiro_obito_filtro], kind=&quot;reg&quot;) g.fig.tight_layout() g.fig.subplots_adjust(top=0.88) g.fig.suptitle(&#39;Grade de gráficos, dados a partir do primeiro óbito&#39;, y=0.92); . g = sns.pairplot(brasil[primeiro_caso_filtro], kind=&quot;reg&quot;) g.fig.suptitle(&#39;Scatter Matrix com filtro a partir do primeiro caso&#39;, y=1.08); . g = sns.pairplot(brasil_log[primeiro_obito_filtro], kind=&quot;reg&quot;) g.fig.suptitle(&#39;Scatter Matrix do Log dos dados com filtro a partir do primeiro óbito&#39;, y=1.08); . g = sns.pairplot(brasil_log[primeiro_obito_filtro], kind=&quot;reg&quot;) g.fig.suptitle(&#39;Scatter Matrix do Log dos dados com filtro a partir do primeiro óbito&#39;, y=1.08); . Os plots acima, talvez pareçam informação irrelevante, mas o fiz para ter uma ideia sobre a distribuição dos dados e se há alguma distribuição normal em algum caso, que justificaria o uso do desvio padrão (uma vez que o mesmo é em relação à distribuição normal). De qualquer forma, para manter as coisas simples inicialmente, vou manter meu plano inicial de criar uma projeção do número de casos incluindo o intervalo do desvio padrão. Então vamos começar pegando o as estatísticas filtrando a partir do primeiro caso: . std = brasil_log[primeiro_caso_filtro].std() . Visualizar um plot da tendência que vamos modelar: . brasil_log[primeiro_caso_filtro][&#39;Confirmados Cumulativo&#39;].plot() . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f5b562c4b38&gt; . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f5acde5cf28&gt; . Em seguida ajustar uma regressão linear em cima do log: . def fitar(x, y): lr = LinearRegression() lr.fit(x,y) return lr x = np.arange(sum(primeiro_caso_filtro)).reshape(-1,1) y = brasil_log[primeiro_caso_filtro][&#39;Confirmados Cumulativo&#39;].values lr_casos = fitar(x, y) . def projetar(lr, x, y, plot=True): y_pred = lr.predict(x) if plot: plt.scatter(x, y) plt.plot(y_pred, &#39;r&#39;) plt.title(&quot;Projeção logarítmica&quot;) plt.show() plt.scatter(x, np.expm1(y)) plt.plot(np.expm1(y_pred), &#39;r&#39;) plt.title(&quot;Projeção exponencial&quot;) plt.show() return y_pred y_pred = projetar(lr_casos, x, y) . A projeção acima não ficou boa, vamos testar suavizar com um exponential moving average: . def generate_moving_average(data, mom=0.7): MOM = 0.7 rolling_mean = [data[0]] for d in data[1:]: rolling_mean.append(rolling_mean[-1]*MOM + (1-MOM)*d) return np.array(rolling_mean) def fitar_projetar(x, y, mom=None): if mom is not None: y_old = y y = generate_moving_average(y) lr = fitar(x, y) y_pred = projetar(lr, x, y, plot=not mom) # Plota se mom for nulo if mom is not None: y_pred_exp = np.expm1(y_pred) reversed_mv = [(rm-rm_*mom)/(1-mom) for rm, rm_ in zip(y_pred_exp[1:], y_pred_exp[:-1])] plt.scatter(x, np.expm1(y_old), label=&quot;Original&quot;) plt.scatter(x, np.expm1(y), label=&quot;Exp. Moving Average&quot;) plt.plot(y_pred_exp, &#39;r&#39;, label=&quot;Projeção do EMA&quot;) plt.plot(reversed_mv, label=&quot;EMA reverso para projeção real&quot;) plt.legend() plt.title(f&quot;Projeção com Exp. Moving Average (momentum = {mom})&quot;) plt.show() return y_pred y_pred = fitar_projetar(x, y, mom=0.5) . Também não ficou muito boa. Um dos motivos de estas funções não estarem se saindo bem é que o erro está sendo inferido na escala logarítmica, ou seja, enquanto estamos na escala logarítmica, o erro em termos absolutos é pequeno, no entanto, quando passamos à escala normal, o erro aumenta consideravelmente. Parra corrigir isso, precisamos ajustar uma função exponencial diretamente sem realizar a transformação logarítmica. Precisamos de uma função de custo que infira o erro diretamente da exponencial. Podemos fazer isso com o auxílio de otimizadores de redes neurais. Vamos também aproveitar para ajustar uma sigmóide. E aqui um detalhe: para quem é de machine learning, as boas práticas de seleção de modelos não se aplicam aqui (por exemplo, divisão treinamento e teste). Como os modelos a serem ajustados são bastante simples, não há a necessidade de reservar um conjunto de validação/teste. . # Creating a model from keras.models import Sequential; from keras.layers import Dense from keras import backend as K from keras.optimizers import Adam from keras.activations import sigmoid, elu def get_keras_model(lr=0.001, activation=&#39;exp&#39;): if activation==&#39;exp&#39;: def activ_func(x): return K.exp(x) - 1 elif activation==&#39;sigm&#39;: activ_func = sigmoid elif activation==&#39;elu&#39;: activ_func = elu # Usage model = Sequential(); model.add(Dense(1, input_dim=1, activation=activ_func)) model.compile(optimizer=Adam(lr=lr), loss=&#39;mean_squared_error&#39;) return model . Using TensorFlow backend. . # Definir entrada e saida x = np.arange(sum(primeiro_caso_filtro)).reshape(-1,1) y = brasil[primeiro_caso_filtro][&#39;Confirmados Cumulativo&#39;].values . # Preparar dados def preparar_dados(x, y): x_mean = x.mean() x_std = x.std() y_mean = y.mean() y_std = y.std() x_prep = (x-x_mean)/x_std y_prep = (y-y_mean)/y_std return x_prep, y_prep x_prep, y_prep = preparar_dados(x, y) . #hide_output model = get_keras_model(lr=0.1) model.fit(x_prep, y_prep, epochs=100, verbose=0); . from sklearn.metrics import r2_score . def projetar_keras(model, x, y, days_ahead=0, plot=True, model_func=&quot;exponencial&quot;, tipo=&#39;caso&#39;, exibir_pontos=False, anotar_dados_reais=True, dados_reais_step=2): title = f&#39;Projeção {model_func} de {tipo}s de Covid-19 no Brasil&#39; + f&#39; para os próximos {days_ahead} dias&#39; hoje = date.today() hoje = hoje.strftime(&quot;%d/%m&quot;) x_mean = x.mean() x_std = x.std() y_mean = y.mean() y_std = y.std() n_days = len(x) x_proj = np.arange(n_days+days_ahead).reshape(-1,1) x_prep = (x_proj-x_mean)/x_std y_prep = (y-y_mean)/y_std y_pred = model.predict(x_prep) y_pred = y_pred*y_std + y_mean #Reverse y_pred back y_pred = y_pred.astype(int) y_pred = np.clip(y_pred, 0, None) y_pred = y_pred.squeeze() #print(y) #print(y_pred) r2 = r2_score(y, y_pred[:-days_ahead]) if plot: fig = plt.figure(figsize=FIGSIZE) # Plotar projeção plt.plot(x_proj[-days_ahead-1:], y_pred[-days_ahead-1:], &#39;-&#39;, color=&#39;red&#39;, label=&#39;Projeção&#39;) # Plotar função if exibir_pontos: plt.plot(x_proj[:-days_ahead], y_pred[:-days_ahead], &#39;-&#39;, color=&#39;red&#39;, label=f&#39;Ajuste {model_func} (R²={r2:.2f})&#39;, alpha=0.4) #plt.scatter(x, y, label=&#39;Dados reais&#39;, color=&#39;orange&#39;) plt.plot(y, &#39;.&#39;, label=&#39;Dados reais&#39;) plt.title(title) for x_anot, y_anot in zip(x_proj[-days_ahead:], y_pred[-days_ahead:]): plt.annotate(y_anot, (x_anot, y_anot), ha=&#39;right&#39;, color=&#39;red&#39;) plt.annotate(f&#39;({hoje}): {y[-1]}&#39;, (x[-1], y[-1]), ha=&#39;right&#39;, color=&#39;black&#39;, textcoords=&quot;offset points&quot;, xytext=(-5,0)) if anotar_dados_reais: for x_anot, y_anot in zip(x[:-1:dados_reais_step], y[:-1:dados_reais_step]): plt.annotate(y_anot, (x_anot, y_anot), ha=&#39;right&#39;, color=&#39;midnightblue&#39;, textcoords=&quot;offset points&quot;, xytext=(-5,3) ) plt.grid(color=&#39;black&#39;, linestyle=&#39;--&#39;, linewidth=0.17) plt.legend() plt.xlabel(f&quot;Dias desde o primeiro {tipo} no Brasil&quot;) plt.ylabel(f&#39;{tipo.capitalize()}s confirmados acumulados&#39;) plt.xticks(x_proj[::2]) plt.show() return y_pred, fig . y_pred, fig = projetar_keras(model, x, y, days_ahead=7, exibir_pontos=True, anotar_dados_reais=False, dados_reais_step=3) . Por curiosidade, vamos testar ajustar um sigmóide: . #hide_output model = get_keras_model(lr=1, activation=&#39;sigm&#39;) model.fit(x_prep, y_prep, epochs=100, verbose=0); . y_pred, fig = projetar_keras(model, x, y, days_ahead=5, model_func=&#39;sigmóide&#39;, exibir_pontos=True) . Bem distante do esperado :) Vamos testar também o ELU: . #hide_output model = get_keras_model(lr=0.1, activation=&#39;elu&#39;) model.fit(x_prep, y_prep, epochs=100, verbose=0); . y_pred, fig = projetar_keras(model, x, y, days_ahead=7, model_func=&quot;ELU (Exp. Linear Unit)&quot;, exibir_pontos=True) . Um pouco melhor, mas neste caso com tendência linear. Vamos também replicar estes dois últimos para o número de óbitos. . # Definir entrada e saida x = np.arange(sum(primeiro_obito_filtro)).reshape(-1,1) y = brasil[primeiro_obito_filtro][&#39;Mortes Cumulativa&#39;].values x_prep, y_prep = preparar_dados(x, y) . #hide_output model = get_keras_model(lr=0.1, activation=&#39;exp&#39;) model.fit(x_prep, y_prep, epochs=100, verbose=0); . y_pred, fig = projetar_keras(model, x, y, days_ahead=7, model_func=&quot;exponencial&quot;, tipo=&#39;obito&#39;, exibir_pontos=True, anotar_dados_reais=False, dados_reais_step=3) . #hide_output model = get_keras_model(lr=0.1, activation=&#39;elu&#39;) model.fit(x_prep, y_prep, epochs=100, verbose=0); . y_pred, fig = projetar_keras(model, x, y, days_ahead=7, model_func=&quot;ELU (Exp. Linear Unit)&quot;, tipo=&#39;obito&#39;, exibir_pontos=True) .",
            "url": "https://covid19graficos.github.io/relatorio/coronavirus/2020/04/11/projecao-brasil.html",
            "relUrl": "/coronavirus/2020/04/11/projecao-brasil.html",
            "date": " • Apr 11, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Sobre este website . Este website foi criado utilizando fastpages no qual permite a conversão automática de arquivos do Jupyter notebook em páginas da web. Temos o objetivo de tornar análises comparativas do Brasil com o resto do mundo de maneira à melhor informar a população. Sugestões de relatórios podem ser submetidas em nosso repositório. . Desenvolvedores . Vinicius Bastos Gomes Linkedin: https://www.linkedin.com/in/vinicius-gomes-phd-490557163/ | Github: https://github.com/ViniciusBG | . | Fernando Marcos Wittmann LinkedIn: https://www.linkedin.com/in/fernandowittmann/ | GitHub: https://github.com/WittmannF | . | . Fontes . John Hopkins University: https://github.com/CSSEGISandData/COVID-19 | Brasil.io: https://brasil.io/dataset/covid19/boletim | Ministério da Saúde: https://covid.saude.gov.br/ | . As fontes de cada relatório podem também ser conferidas em nossos notebooks. .",
          "url": "https://covid19graficos.github.io/relatorio/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}