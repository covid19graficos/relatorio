{
  
    
        "post0": {
            "title": "Mundo - Comparações entre Países",
            "content": "Fonte: https://opendata.ecdc.europa.eu/covid19/casedistribution/csv . Gráficos de contaminação . Os gráficos a seguir apresentam curvas de contaminação de diversos países. Foram criados com o intuito de comparar estratégias de combate à disseminação do vírus. É importante notar que as curvas de contaminação estão amplamente relacionadas à quantidade de testes que os países tem realizado. . . . . . Contaminação Relativa . Essa seção conta com gráficos em que o número de casos é dívidido pela população dos países para que se tenha uma ideia da proporção de infectados por país. . . . . . Óbitos . Os gráficos a seguir apresentam os óbitos contabilizados por COVID-19, nas escalas aritmética e logarítmica. . . . . . Óbitos (relativo) . . . . . Letalidade . O gráfco a seguir aponta o número de mortes dividido pelo número de casos confirmados. É importantíssimo notar a grande dependência desses números da quantidade de testes disponíveis. Quanto mais testes realizados, mais confiáveis os dados. . . . O gráfico a seguir apresenta a curva de letalidade dos países. Novamente reiteramos que: mais do que de fato apresentar uma flutuação da letalidade do vírus, que muito provavelmente não varia tão abruptamente, esses gráficos demonstram, por exemplo, um aumento na quantidade de testes (quando a taxa de letalidade cai), uma mudança na forma de contabilizar os óbitos, entre outros. . . .",
            "url": "https://covid19graficos.github.io/relatorio/coronavirus/2020/05/11/corona-mundo-interativo.html",
            "relUrl": "/coronavirus/2020/05/11/corona-mundo-interativo.html",
            "date": " • May 11, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Brasil - Comparações entre cidades",
            "content": "Fonte (estados):https://covid.saude.gov.br/ (cidades) https://data.brasil.io/dataset/covid19/caso.csv.gz . Capitais brasileiras . Comparações entre as capitais de estados do Brasil . import plotly.express as px . . . . . Linhas de todas as cidades . A seguir as linhas de casos e óbitos de todas as cidades do Brasil das quais temos acesso aos dados. Para melhor utilização, encontre a cidade e clique duas vezes sobre sua legenda, isolando-a. Caso queira compará-la com outra cidade, adicione a linha da segunda cidade desejada clicando uma vez sobre sua legenda. . . . . . 200 cidades com maiores números de casos . Abaixo uma tabela com a lista das 200 cidades com mais casos no país. . Estado Cidade Casos Mortes . date . 2020-05-10 SP | São Paulo | 27307 | 2266 | . 2020-05-10 RJ | Rio de Janeiro | 10520 | 1126 | . 2020-05-10 SP | Osasco | 1257 | 153 | . 2020-05-10 SP | São Bernardo do Campo | 1095 | 92 | . 2020-05-10 SP | Guarulhos | 1075 | 125 | . 2020-05-10 MG | Belo Horizonte | 973 | 26 | . 2020-05-10 SP | Santos | 958 | 66 | . 2020-05-10 SP | Santo André | 925 | 49 | . 2020-05-10 RJ | Niterói | 756 | 43 | . 2020-05-10 RJ | Duque de Caxias | 702 | 105 | . 2020-05-10 SP | Campinas | 609 | 25 | . 2020-05-10 RJ | Nova Iguaçu | 591 | 66 | . 2020-05-10 SP | Barueri | 529 | 58 | . 2020-05-10 RS | Porto Alegre | 508 | 17 | . 2020-05-10 SP | Diadema | 449 | 33 | . 2020-05-10 SP | Mogi das Cruzes | 443 | 31 | . 2020-05-10 RJ | São Gonçalo | 442 | 47 | . 2020-05-10 RJ | Volta Redonda | 399 | 16 | . 2020-05-10 SP | Carapicuíba | 399 | 21 | . 2020-05-10 SC | Florianópolis | 386 | 6 | . 2020-05-10 SP | Mauá | 378 | 30 | . 2020-05-10 SP | São José dos Campos | 355 | 16 | . 2020-05-10 RJ | São João de Meriti | 325 | 36 | . 2020-05-10 MG | Juiz de Fora | 317 | 13 | . 2020-05-10 SP | Ribeirão Preto | 306 | 9 | . 2020-05-10 SC | Chapecó | 298 | 0 | . 2020-05-10 SC | Blumenau | 297 | 2 | . 2020-05-10 SP | São Caetano do Sul | 284 | 19 | . 2020-05-10 RJ | Belford Roxo | 282 | 32 | . 2020-05-10 RJ | Itaboraí | 280 | 23 | . 2020-05-10 SP | Taboão da Serra | 280 | 27 | . 2020-05-10 SP | São Vicente | 279 | 10 | . 2020-05-10 SP | São José do Rio Preto | 275 | 10 | . 2020-05-10 SP | Suzano | 263 | 27 | . 2020-05-10 RS | Passo Fundo | 261 | 17 | . 2020-05-10 SC | Joinville | 261 | 7 | . 2020-05-10 SP | Cotia | 261 | 22 | . 2020-05-10 SP | Guarujá | 252 | 14 | . 2020-05-10 SP | Jundiaí | 251 | 20 | . 2020-05-10 MG | Uberlândia | 246 | 10 | . 2020-05-10 SP | Sorocaba | 239 | 25 | . 2020-05-10 SP | Praia Grande | 236 | 38 | . 2020-05-10 SP | Embu das Artes | 232 | 23 | . 2020-05-10 SP | Itaquaquecetuba | 227 | 30 | . 2020-05-10 SP | Santana de Parnaíba | 219 | 7 | . 2020-05-10 RJ | Mesquita | 218 | 23 | . 2020-05-10 SC | Criciúma | 209 | 4 | . 2020-05-10 SP | Itapevi | 204 | 26 | . 2020-05-10 RJ | Magé | 194 | 12 | . 2020-05-10 SP | Itapecerica da Serra | 191 | 12 | . 2020-05-10 RS | Lajeado | 185 | 8 | . 2020-05-10 MT | Cuiabá | 185 | 2 | . 2020-05-10 SP | Franco da Rocha | 184 | 17 | . 2020-05-10 SP | Bauru | 167 | 10 | . 2020-05-10 RJ | Campos dos Goytacazes | 158 | 4 | . 2020-05-10 SP | Piracicaba | 158 | 13 | . 2020-05-10 SP | Ferraz de Vasconcelos | 157 | 15 | . 2020-05-10 RJ | Petrópolis | 152 | 16 | . 2020-05-10 SP | Caieiras | 149 | 15 | . 2020-05-10 RJ | Nilópolis | 138 | 13 | . 2020-05-10 SP | São Sebastião | 134 | 2 | . 2020-05-10 SC | Concórdia | 132 | 3 | . 2020-05-10 SC | Itajaí | 130 | 3 | . 2020-05-10 SP | Francisco Morato | 128 | 13 | . 2020-05-10 RS | Bento Gonçalves | 128 | 5 | . 2020-05-10 SC | Balneário Camboriú | 124 | 2 | . 2020-05-10 RJ | Angra dos Reis | 120 | 7 | . 2020-05-10 RS | Marau | 119 | 3 | . 2020-05-10 RJ | Maricá | 110 | 13 | . 2020-05-10 SP | Arujá | 110 | 5 | . 2020-05-10 MG | Divinópolis | 108 | 1 | . 2020-05-10 SP | Araraquara | 107 | 4 | . 2020-05-10 SP | Jandira | 106 | 7 | . 2020-05-10 RJ | Macaé | 106 | 14 | . 2020-05-10 RJ | Queimados | 104 | 5 | . 2020-05-10 RJ | Cabo Frio | 103 | 5 | . 2020-05-10 SP | Botucatu | 101 | 5 | . 2020-05-10 SP | Bragança Paulista | 101 | 10 | . 2020-05-10 SC | Braço do Norte | 100 | 2 | . 2020-05-10 SC | Navegantes | 97 | 0 | . 2020-05-10 MG | Nova Lima | 96 | 0 | . 2020-05-10 SP | Cajamar | 95 | 11 | . 2020-05-10 SP | Poá | 94 | 14 | . 2020-05-10 SP | Ribeirão Pires | 93 | 10 | . 2020-05-10 SP | Cubatão | 91 | 5 | . 2020-05-10 SP | Araçatuba | 91 | 3 | . 2020-05-10 RJ | Nova Friburgo | 87 | 8 | . 2020-05-10 RJ | Teresópolis | 80 | 8 | . 2020-05-10 SC | Tubarão | 77 | 3 | . 2020-05-10 RS | São Leopoldo | 75 | 1 | . 2020-05-10 SC | Camboriú | 74 | 3 | . 2020-05-10 RJ | Barra Mansa | 73 | 1 | . 2020-05-10 SP | Hortolândia | 73 | 8 | . 2020-05-10 MG | Contagem | 73 | 3 | . 2020-05-10 RJ | Rio das Ostras | 68 | 8 | . 2020-05-10 SP | Barretos | 68 | 4 | . 2020-05-10 SP | Jaú | 68 | 1 | . 2020-05-10 SP | Sumaré | 67 | 2 | . 2020-05-10 RJ | Itaguaí | 67 | 11 | . 2020-05-10 RJ | Resende | 66 | 4 | . 2020-05-10 SC | São José | 66 | 1 | . 2020-05-10 RS | Caxias do Sul | 65 | 1 | . 2020-05-10 SP | Caraguatatuba | 65 | 4 | . 2020-05-10 SP | Limeira | 61 | 1 | . 2020-05-10 MG | Uberaba | 60 | 4 | . 2020-05-10 SC | Brusque | 60 | 0 | . 2020-05-10 SP | Americana | 59 | 4 | . 2020-05-10 SP | Presidente Prudente | 59 | 4 | . 2020-05-10 SP | Mairiporã | 58 | 6 | . 2020-05-10 MG | Importados/Indefinidos | 56 | 0 | . 2020-05-10 MT | Rondonópolis | 56 | 2 | . 2020-05-10 SP | Jacareí | 56 | 4 | . 2020-05-10 MG | Pouso Alegre | 56 | 3 | . 2020-05-10 SP | Pariquera-Açu | 54 | 1 | . 2020-05-10 RJ | Saquarema | 53 | 4 | . 2020-05-10 RJ | Paraty | 52 | 2 | . 2020-05-10 SP | Taubaté | 49 | 4 | . 2020-05-10 SP | Embu-Guaçu | 48 | 5 | . 2020-05-10 RJ | Japeri | 47 | 2 | . 2020-05-10 SC | Lindóia do Sul | 46 | 0 | . 2020-05-10 MG | Extrema | 46 | 3 | . 2020-05-10 RJ | Araruama | 43 | 2 | . 2020-05-10 SP | Atibaia | 42 | 2 | . 2020-05-10 RS | Novo Hamburgo | 42 | 2 | . 2020-05-10 SP | Birigui | 41 | 0 | . 2020-05-10 RJ | Paracambi | 41 | 3 | . 2020-05-10 SP | Valinhos | 41 | 3 | . 2020-05-10 SP | Itapetininga | 41 | 2 | . 2020-05-10 SP | Registro | 39 | 4 | . 2020-05-10 SP | Piedade | 39 | 1 | . 2020-05-10 SP | São Pedro | 39 | 0 | . 2020-05-10 RS | Canoas | 38 | 2 | . 2020-05-10 RJ | Barra do Piraí | 38 | 3 | . 2020-05-10 RJ | São Pedro da Aldeia | 37 | 4 | . 2020-05-10 SP | Araras | 37 | 2 | . 2020-05-10 MG | Governador Valadares | 37 | 3 | . 2020-05-10 SC | Palhoça | 37 | 1 | . 2020-05-10 SP | São Carlos | 36 | 3 | . 2020-05-10 SP | Indaiatuba | 36 | 8 | . 2020-05-10 SC | Jaraguá do Sul | 36 | 1 | . 2020-05-10 SC | Lages | 36 | 0 | . 2020-05-10 MT | Várzea Grande | 36 | 1 | . 2020-05-10 RS | Estrela | 35 | 1 | . 2020-05-10 RS | Serafina Corrêa | 35 | 1 | . 2020-05-10 RJ | Rio Bonito | 35 | 4 | . 2020-05-10 SP | Pirassununga | 34 | 0 | . 2020-05-10 SC | Sombrio | 34 | 3 | . 2020-05-10 RS | Carlos Barbosa | 34 | 1 | . 2020-05-10 RS | Garibaldi | 34 | 3 | . 2020-05-10 SP | Vinhedo | 33 | 2 | . 2020-05-10 SC | Irani | 33 | 0 | . 2020-05-10 RS | Venâncio Aires | 33 | 4 | . 2020-05-10 MG | Varginha | 32 | 1 | . 2020-05-10 SP | Santa Isabel | 32 | 5 | . 2020-05-10 MG | Muriaé | 32 | 0 | . 2020-05-10 SP | Várzea Paulista | 31 | 4 | . 2020-05-10 SP | Catanduva | 31 | 3 | . 2020-05-10 RJ | São Fidélis | 31 | 0 | . 2020-05-10 SP | Votorantim | 31 | 3 | . 2020-05-10 RS | Santa Maria | 31 | 0 | . 2020-05-10 SP | Paulínia | 31 | 1 | . 2020-05-10 SP | Peruíbe | 31 | 3 | . 2020-05-10 RS | Arroio do Meio | 30 | 0 | . 2020-05-10 RS | Três Passos | 30 | 0 | . 2020-05-10 RJ | Três Rios | 30 | 1 | . 2020-05-10 RJ | Casimiro de Abreu | 30 | 2 | . 2020-05-10 RS | Viamão | 29 | 0 | . 2020-05-10 RS | Farroupilha | 29 | 4 | . 2020-05-10 SP | Tatuí | 29 | 2 | . 2020-05-10 RS | Bagé | 29 | 0 | . 2020-05-10 SP | Avaré | 29 | 2 | . 2020-05-10 SC | Imbituba | 28 | 0 | . 2020-05-10 SP | Santa Cruz do Rio Pardo | 28 | 0 | . 2020-05-10 MG | Teófilo Otoni | 28 | 1 | . 2020-05-10 SC | Gaspar | 28 | 1 | . 2020-05-10 SP | Mogi Guaçu | 27 | 1 | . 2020-05-10 MG | Betim | 27 | 1 | . 2020-05-10 SP | Ubatuba | 27 | 0 | . 2020-05-10 RJ | Iguaba Grande | 27 | 4 | . 2020-05-10 SC | Ipumirim | 27 | 0 | . 2020-05-10 SC | Importados/Indefinidos | 27 | 0 | . 2020-05-10 MG | Poços de Caldas | 27 | 3 | . 2020-05-10 SP | Rio Grande da Serra | 27 | 2 | . 2020-05-10 SP | São Roque | 26 | 2 | . 2020-05-10 RS | Pelotas | 26 | 0 | . 2020-05-10 SP | Campo Limpo Paulista | 26 | 3 | . 2020-05-10 SP | São João da Boa Vista | 26 | 1 | . 2020-05-10 RS | Torres | 25 | 1 | . 2020-05-10 SP | Louveira | 25 | 2 | . 2020-05-10 RS | Taquari | 25 | 0 | . 2020-05-10 RS | Soledade | 25 | 0 | . 2020-05-10 SP | Franca | 25 | 1 | . 2020-05-10 RS | Gravataí | 25 | 1 | . 2020-05-10 MG | São Francisco | 24 | 2 | . 2020-05-10 MT | Barra do Garças | 24 | 2 | . 2020-05-10 RJ | Tanguá | 24 | 6 | . 2020-05-10 SP | Votuporanga | 24 | 0 | . 2020-05-10 RS | Cachoeirinha | 24 | 0 | . 2020-05-10 SP | Itu | 24 | 4 | . 2020-05-10 MG | Montes Claros | 24 | 2 | .",
            "url": "https://covid19graficos.github.io/relatorio/coronavirus/2020/05/11/corona-brasil-cidades.html",
            "relUrl": "/coronavirus/2020/05/11/corona-brasil-cidades.html",
            "date": " • May 11, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Mundo - Projeção de Óbitos",
            "content": "O gráfico mostra a taxa de crescimento no número de óbitos em cada país ou região em função do total de óbitos em escala logarítmica. A taxa de crescimento é estimada como a média geométrica do crescimento observado num período de 7 dias. . Observa-se uma relação quase linear com a taxa de crescimento desacelerando em função do tempo. Esse comportamento é consistente com um modelo de Gompertz. . Baseado nesse ansatz, fazemos uma projeção linear para estimar o número total de óbitos até o fim da epidemia. O declive da reta de projeção é estimado a partir da média mundial e é mantido fixo. . Esse modelo é extremamente simplificado e não tem uma base teórica bem fundamentada. O intuito é meramente indicar uma tendência para progressão da epidemia em cada país. .",
            "url": "https://covid19graficos.github.io/relatorio/coronavirus/2020/05/08/projecao-mundo.html",
            "relUrl": "/coronavirus/2020/05/08/projecao-mundo.html",
            "date": " • May 8, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Brasil - Projeção de Casos e Óbitos",
            "content": "Gr&#225;ficos . Proje&#231;&#227;o do n&#250;mero de casos no Brasil para a pr&#243;xima semana . Proje&#231;&#227;o do n&#250;mero de &#243;bitos no Brasil para a pr&#243;xima semana . N&#250;mero de Casos Novos Confirmados . N&#250;meros de &#211;bitos Novos . Agradecimentos e Contribui&#231;&#245;es . Ívi M. de Carvalho, D. Sc. | . (Para Programadores) C&#243;digo para gera&#231;&#227;o dos gr&#225;ficos . NOTA: O resto desse relatório está focado no desenvolvimento dos gráficos mostrados acima. Somente é relevante caso tenha interesse em Python e Data Analysis . Neste relatório vamos desenvolver em Python uma projeção que pode ser atualizada em tempo real do número de casos de Covid-19 no Brasil. Devido à sua natureza com crescimento exponencial, podemos fazer projeções de curto/médio prazo de acordo com tal tendência. É importante salientar que não existe nenhuma exponencial pura. Em algum momento haverá um ponto de inflexão (quando o número de casos começa a diminuir) e esta exponencial se tornará um sigmóide (como já é o caso da China). Portanto, como não há como prever quando ocorrerá essa inflexão, as projeções somente são úteis para curto e médio prazo. Sem mais delongas, vamos começar! Primeiramente, todas as importações que serão utilizadas: . #collapse # Todas as importações vem aqui import numpy as np import pandas as pd; import matplotlib.pyplot as plt import seaborn as sns; from sklearn.linear_model import LinearRegression from datetime import date . . E também parâmetros: . #collapse FIGSIZE = (8,4) . . Em seguida, vamos importar a base de dados disponibilizada pelo repositório da John Hopkins University. Há duas bases relevantes para nosso caso, uma com o histórico do número de casos e outro com o histório do número de mortes (ambos obtido a partir dos relatórios diários da OMS). . #collapse CASOS_URL = &#39;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv&#39; MORTES_URL = &#39;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv&#39; . . Ambos são urls diretas para arquivos .CSV, portanto podemos importá-los diretamente para a biblioteca Pandas do Python, sem precisar baixá-los: . #collapse casos = pd.read_csv(CASOS_URL) mortes = pd.read_csv(MORTES_URL) . . Vamos visualizar o cabeçalho de cada um: . casos.head() . Province/State Country/Region Lat Long 1/22/20 1/23/20 1/24/20 1/25/20 1/26/20 1/27/20 1/28/20 1/29/20 1/30/20 1/31/20 2/1/20 2/2/20 2/3/20 2/4/20 2/5/20 2/6/20 2/7/20 2/8/20 2/9/20 2/10/20 2/11/20 2/12/20 2/13/20 2/14/20 2/15/20 2/16/20 2/17/20 2/18/20 2/19/20 2/20/20 2/21/20 2/22/20 2/23/20 2/24/20 2/25/20 2/26/20 ... 3/30/20 3/31/20 4/1/20 4/2/20 4/3/20 4/4/20 4/5/20 4/6/20 4/7/20 4/8/20 4/9/20 4/10/20 4/11/20 4/12/20 4/13/20 4/14/20 4/15/20 4/16/20 4/17/20 4/18/20 4/19/20 4/20/20 4/21/20 4/22/20 4/23/20 4/24/20 4/25/20 4/26/20 4/27/20 4/28/20 4/29/20 4/30/20 5/1/20 5/2/20 5/3/20 5/4/20 5/5/20 5/6/20 5/7/20 5/8/20 . 0 NaN | Afghanistan | 33.0000 | 65.0000 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | ... | 170 | 174 | 237 | 273 | 281 | 299 | 349 | 367 | 423 | 444 | 484 | 521 | 555 | 607 | 665 | 714 | 784 | 840 | 906 | 933 | 996 | 1026 | 1092 | 1176 | 1279 | 1351 | 1463 | 1531 | 1703 | 1828 | 1939 | 2171 | 2335 | 2469 | 2704 | 2894 | 3224 | 3392 | 3563 | 3778 | . 1 NaN | Albania | 41.1533 | 20.1683 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 223 | 243 | 259 | 277 | 304 | 333 | 361 | 377 | 383 | 400 | 409 | 416 | 433 | 446 | 467 | 475 | 494 | 518 | 539 | 548 | 562 | 584 | 609 | 634 | 663 | 678 | 712 | 726 | 736 | 750 | 766 | 773 | 782 | 789 | 795 | 803 | 820 | 832 | 842 | 850 | . 2 NaN | Algeria | 28.0339 | 1.6596 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | ... | 584 | 716 | 847 | 986 | 1171 | 1251 | 1320 | 1423 | 1468 | 1572 | 1666 | 1761 | 1825 | 1914 | 1983 | 2070 | 2160 | 2268 | 2418 | 2534 | 2629 | 2718 | 2811 | 2910 | 3007 | 3127 | 3256 | 3382 | 3517 | 3649 | 3848 | 4006 | 4154 | 4295 | 4474 | 4648 | 4838 | 4997 | 5182 | 5369 | . 3 NaN | Andorra | 42.5063 | 1.5218 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 370 | 376 | 390 | 428 | 439 | 466 | 501 | 525 | 545 | 564 | 583 | 601 | 601 | 638 | 646 | 659 | 673 | 673 | 696 | 704 | 713 | 717 | 717 | 723 | 723 | 731 | 738 | 738 | 743 | 743 | 743 | 745 | 745 | 747 | 748 | 750 | 751 | 751 | 752 | 752 | . 4 NaN | Angola | -11.2027 | 17.8739 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 7 | 7 | 8 | 8 | 8 | 10 | 14 | 16 | 17 | 19 | 19 | 19 | 19 | 19 | 19 | 19 | 19 | 19 | 19 | 24 | 24 | 24 | 24 | 25 | 25 | 25 | 25 | 26 | 27 | 27 | 27 | 27 | 30 | 35 | 35 | 35 | 36 | 36 | 36 | 43 | . 5 rows × 112 columns . mortes.head() . Province/State Country/Region Lat Long 1/22/20 1/23/20 1/24/20 1/25/20 1/26/20 1/27/20 1/28/20 1/29/20 1/30/20 1/31/20 2/1/20 2/2/20 2/3/20 2/4/20 2/5/20 2/6/20 2/7/20 2/8/20 2/9/20 2/10/20 2/11/20 2/12/20 2/13/20 2/14/20 2/15/20 2/16/20 2/17/20 2/18/20 2/19/20 2/20/20 2/21/20 2/22/20 2/23/20 2/24/20 2/25/20 2/26/20 ... 3/30/20 3/31/20 4/1/20 4/2/20 4/3/20 4/4/20 4/5/20 4/6/20 4/7/20 4/8/20 4/9/20 4/10/20 4/11/20 4/12/20 4/13/20 4/14/20 4/15/20 4/16/20 4/17/20 4/18/20 4/19/20 4/20/20 4/21/20 4/22/20 4/23/20 4/24/20 4/25/20 4/26/20 4/27/20 4/28/20 4/29/20 4/30/20 5/1/20 5/2/20 5/3/20 5/4/20 5/5/20 5/6/20 5/7/20 5/8/20 . 0 NaN | Afghanistan | 33.0000 | 65.0000 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 4 | 4 | 4 | 6 | 6 | 7 | 7 | 11 | 14 | 14 | 15 | 15 | 18 | 18 | 21 | 23 | 25 | 30 | 30 | 30 | 33 | 36 | 36 | 40 | 42 | 43 | 47 | 50 | 57 | 58 | 60 | 64 | 68 | 72 | 85 | 90 | 95 | 104 | 106 | 109 | . 1 NaN | Albania | 41.1533 | 20.1683 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 11 | 15 | 15 | 16 | 17 | 20 | 20 | 21 | 22 | 22 | 23 | 23 | 23 | 23 | 23 | 24 | 25 | 26 | 26 | 26 | 26 | 26 | 26 | 27 | 27 | 27 | 27 | 28 | 28 | 30 | 30 | 31 | 31 | 31 | 31 | 31 | 31 | 31 | 31 | 31 | . 2 NaN | Algeria | 28.0339 | 1.6596 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 35 | 44 | 58 | 86 | 105 | 130 | 152 | 173 | 193 | 205 | 235 | 256 | 275 | 293 | 313 | 326 | 336 | 348 | 364 | 367 | 375 | 384 | 392 | 402 | 407 | 415 | 419 | 425 | 432 | 437 | 444 | 450 | 453 | 459 | 463 | 465 | 470 | 476 | 483 | 488 | . 3 NaN | Andorra | 42.5063 | 1.5218 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 8 | 12 | 14 | 15 | 16 | 17 | 18 | 21 | 22 | 23 | 25 | 26 | 26 | 29 | 29 | 31 | 33 | 33 | 35 | 35 | 36 | 37 | 37 | 37 | 37 | 40 | 40 | 40 | 40 | 41 | 42 | 42 | 43 | 44 | 45 | 45 | 46 | 46 | 47 | 47 | . 4 NaN | Angola | -11.2027 | 17.8739 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | 2 | . 5 rows × 112 columns . Como para este relatório temos interesse em apenas dados do Brasil, vamos atribuir duas novas variáveis à ambos: . def filter_country(df, country): # Filtrar pais df = df[df[&#39;Country/Region&#39;]==country] # Remover colunas iniciais, manter somente as datas df = df.iloc[:, 4:] # Transpor df = df.T # Redefinir coluna df.columns = [country] # Definir index para Datetime df.index = pd.to_datetime(df.index) return df casos_brasil = filter_country(casos, &#39;Brazil&#39;) mortes_brasil = filter_country(mortes, &#39;Brazil&#39;) . Vamos ver como ficaram os novos dataframes: . casos_brasil.tail() . Brazil . 2020-05-04 108620 | . 2020-05-05 115455 | . 2020-05-06 126611 | . 2020-05-07 135773 | . 2020-05-08 146894 | . mortes_brasil.tail() . Brazil . 2020-05-04 7367 | . 2020-05-05 7938 | . 2020-05-06 8588 | . 2020-05-07 9190 | . 2020-05-08 10017 | . Podemos facilmente também plotar tais dados para ver como estão: . casos_brasil.plot(title=&#39;Número de casos&#39;); . mortes_brasil.plot(title=&#39;Número de mortes&#39;); . Podemos conferir se o número de casos está se acelerando ou não plotando um gráfico de barras do número de casos por dia. Isso será importante para identificar a inflexão! . casos_novos_brasil = casos_brasil[1:]-casos_brasil[:-1].values casos_novos_brasil.tail() . Brazil . 2020-05-04 6794 | . 2020-05-05 6835 | . 2020-05-06 11156 | . 2020-05-07 9162 | . 2020-05-08 11121 | . mortes_novas_brasil = mortes_brasil[1:]-mortes_brasil[:-1].values mortes_novas_brasil.tail() . Brazil . 2020-05-04 316 | . 2020-05-05 571 | . 2020-05-06 650 | . 2020-05-07 602 | . 2020-05-08 827 | . Em seguida vamos visualizar ambos em um gráfico de barras: . # Funcao personalizada def plot_bar_novos(df, title): df.index = df.index.strftime(&#39;%d/%m&#39;)#astype(&#39;str&#39;) ax = df.plot.bar( title=title, figsize=FIGSIZE ) _=plt.xticks(rotation=50) return ax . primeiro_caso_filtro = casos_novos_brasil.values&gt;0 ax=plot_bar_novos(casos_novos_brasil[primeiro_caso_filtro], title=&#39;Casos novos (sem acumular, a partir do primeiro caso)&#39;, ) . # Filtrar a partir do primeiro obito primeiro_obito_filtro = mortes_novas_brasil.values&gt;0 # Criar plot ax=plot_bar_novos(mortes_novas_brasil[primeiro_obito_filtro], title=&#39;Óbitos novos (sem acumular, a partir do primeiro óbito)&#39; ) . ax.figure.savefig(&#39;obitos_novos.png&#39;, dpi=300) . Vamos agora dar início à modelagem das projeções. Primeiramente, vamos fazer alguns plots em cima do log dos dados: . casos_brasil[&#39;Brazil&#39;].apply(np.log).plot(marker=&#39;o&#39;, linestyle=&#39;&#39;, title=&#39;Log do Número de casos&#39;); . mortes_brasil[&#39;Brazil&#39;].apply(np.log).plot(marker=&#39;o&#39;, linestyle=&#39;&#39;, title=&#39;Log do Número de Mortes&#39;); . casos_novos_brasil.apply(np.log).plot(marker=&#39;o&#39;, linestyle=&#39;&#39;, title=&#39;Log do número de casos novos&#39;); . mortes_novas_brasil.apply(np.log).plot(marker=&#39;o&#39;, linestyle=&#39;&#39;, title=&#39;Log de novas mortes&#39;); . Todas as curvas acima não representam uma reta perfeita, o que são ótimas notícias: Significa que talvez não esteja mais seguindo uma tendência exponencial. De qualquer forma, vou usar como ponto de partida uma regressão linear, apesar de haverem ressalvas sobre o uso dela. Por simplificação, vou começar com uma projeção do número total de casos e de mortes. Primeiramente, vou juntar todos os dados em um único dataframe: . brasil = pd.DataFrame({ &#39;Confirmados Cumulativo&#39;: casos_brasil[&#39;Brazil&#39;].values[1:], &#39;Confirmados Novos&#39;: casos_novos_brasil[&#39;Brazil&#39;].values, &#39;Mortes Cumulativa&#39;: mortes_brasil[&#39;Brazil&#39;].values[1:], &#39;Mortes Novas&#39;: mortes_novas_brasil[&#39;Brazil&#39;].values }) brasil.index = casos_novos_brasil.index brasil.tail() . Confirmados Cumulativo Confirmados Novos Mortes Cumulativa Mortes Novas . 2020-05-04 108620 | 6794 | 7367 | 316 | . 2020-05-05 115455 | 6835 | 7938 | 571 | . 2020-05-06 126611 | 11156 | 8588 | 650 | . 2020-05-07 135773 | 9162 | 9190 | 602 | . 2020-05-08 146894 | 11121 | 10017 | 827 | . Também podemos criar um dataframe com o log de todos os dados: . brasil_log = brasil.apply(np.log1p) brasil_log.tail() . Confirmados Cumulativo Confirmados Novos Mortes Cumulativa Mortes Novas . 2020-05-04 11.595620 | 8.823942 | 8.904902 | 5.758902 | . 2020-05-05 11.656645 | 8.829958 | 8.979543 | 6.349139 | . 2020-05-06 11.748883 | 9.319822 | 9.058238 | 6.478510 | . 2020-05-07 11.818747 | 9.122929 | 9.125980 | 6.401917 | . 2020-05-08 11.897473 | 9.316680 | 9.212139 | 6.719013 | . Vamos visualizar a distribuição de cada um e também scatter plots de cada um versus o outro: . pd.plotting.scatter_matrix(brasil_log, figsize = (14,8), diagonal = &#39;kde&#39;); . O plot acima fica um pouco enviesado pois há um grande acúmulo de zeros. Vamos filtrar as datas a partir do promeiro óbito: . primeiro_obito = brasil_log.index[brasil_log[&#39;Mortes Cumulativa&#39;]&gt;0][0] primeiro_obito_filtro = brasil_log.index&gt;=primeiro_obito primeiro_obito . Timestamp(&#39;2020-03-17 00:00:00&#39;) . Como é uma base bastante recente, vamos também pegar o primeiro caso: . primeiro_caso = brasil_log.index[brasil_log[&#39;Confirmados Cumulativo&#39;]&gt;0][0] primeiro_caso_filtro = brasil_log.index&gt;=primeiro_caso primeiro_caso . Timestamp(&#39;2020-02-26 00:00:00&#39;) . Vamos repetir o scatter matrix acima a partir dos filtros que definimos: . g = sns.pairplot(brasil[primeiro_obito_filtro], kind=&quot;reg&quot;) g.fig.tight_layout() g.fig.subplots_adjust(top=0.88) g.fig.suptitle(&#39;Grade de gráficos, dados a partir do primeiro óbito&#39;, y=0.92); . g = sns.pairplot(brasil[primeiro_caso_filtro], kind=&quot;reg&quot;) g.fig.suptitle(&#39;Scatter Matrix com filtro a partir do primeiro caso&#39;, y=1.08); . g = sns.pairplot(brasil_log[primeiro_obito_filtro], kind=&quot;reg&quot;) g.fig.suptitle(&#39;Scatter Matrix do Log dos dados com filtro a partir do primeiro óbito&#39;, y=1.08); . g = sns.pairplot(brasil_log[primeiro_obito_filtro], kind=&quot;reg&quot;) g.fig.suptitle(&#39;Scatter Matrix do Log dos dados com filtro a partir do primeiro óbito&#39;, y=1.08); . Os plots acima, talvez pareçam informação irrelevante, mas o fiz para ter uma ideia sobre a distribuição dos dados e se há alguma distribuição normal em algum caso, que justificaria o uso do desvio padrão (uma vez que o mesmo é em relação à distribuição normal). De qualquer forma, para manter as coisas simples inicialmente, vou manter meu plano inicial de criar uma projeção do número de casos incluindo o intervalo do desvio padrão. Então vamos começar pegando o as estatísticas filtrando a partir do primeiro caso: . std = brasil_log[primeiro_caso_filtro].std() . Visualizar um plot da tendência que vamos modelar: . brasil_log[primeiro_caso_filtro][&#39;Confirmados Cumulativo&#39;].plot() . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f1766093d30&gt; . Em seguida ajustar uma regressão linear em cima do log: . def fitar(x, y): lr = LinearRegression() lr.fit(x,y) return lr x = np.arange(sum(primeiro_caso_filtro)).reshape(-1,1) y = brasil_log[primeiro_caso_filtro][&#39;Confirmados Cumulativo&#39;].values lr_casos = fitar(x, y) . def projetar(lr, x, y, plot=True): y_pred = lr.predict(x) if plot: plt.scatter(x, y) plt.plot(y_pred, &#39;r&#39;) plt.title(&quot;Projeção logarítmica&quot;) plt.show() plt.scatter(x, np.expm1(y)) plt.plot(np.expm1(y_pred), &#39;r&#39;) plt.title(&quot;Projeção exponencial&quot;) plt.show() return y_pred y_pred = projetar(lr_casos, x, y) . A projeção acima não ficou boa, vamos testar suavizar com um exponential moving average: . def generate_moving_average(data, mom=0.7): MOM = 0.7 rolling_mean = [data[0]] for d in data[1:]: rolling_mean.append(rolling_mean[-1]*MOM + (1-MOM)*d) return np.array(rolling_mean) def fitar_projetar(x, y, mom=None): if mom is not None: y_old = y y = generate_moving_average(y) lr = fitar(x, y) y_pred = projetar(lr, x, y, plot=not mom) # Plota se mom for nulo if mom is not None: y_pred_exp = np.expm1(y_pred) reversed_mv = [(rm-rm_*mom)/(1-mom) for rm, rm_ in zip(y_pred_exp[1:], y_pred_exp[:-1])] plt.scatter(x, np.expm1(y_old), label=&quot;Original&quot;) plt.scatter(x, np.expm1(y), label=&quot;Exp. Moving Average&quot;) plt.plot(y_pred_exp, &#39;r&#39;, label=&quot;Projeção do EMA&quot;) plt.plot(reversed_mv, label=&quot;EMA reverso para projeção real&quot;) plt.legend() plt.title(f&quot;Projeção com Exp. Moving Average (momentum = {mom})&quot;) plt.show() return y_pred y_pred = fitar_projetar(x, y, mom=0.5) . Também não ficou muito boa. Um dos motivos de estas funções não estarem se saindo bem é que o erro está sendo inferido na escala logarítmica, ou seja, enquanto estamos na escala logarítmica, o erro em termos absolutos é pequeno, no entanto, quando passamos à escala normal, o erro aumenta consideravelmente. Parra corrigir isso, precisamos ajustar uma função exponencial diretamente sem realizar a transformação logarítmica. Precisamos de uma função de custo que infira o erro diretamente da exponencial. Podemos fazer isso com o auxílio de otimizadores de redes neurais. Vamos também aproveitar para ajustar uma sigmóide. E aqui um detalhe: para quem é de machine learning, as boas práticas de seleção de modelos não se aplicam aqui (por exemplo, divisão treinamento e teste). Como os modelos a serem ajustados são bastante simples, não há a necessidade de reservar um conjunto de validação/teste. . # Creating a model from keras.models import Sequential; from keras.layers import Dense from keras import backend as K from keras.optimizers import Adam from keras.activations import sigmoid, elu def get_keras_model(lr=0.001, activation=&#39;exp&#39;): if activation==&#39;exp&#39;: def activ_func(x): return K.exp(x) - 1 elif activation==&#39;sigm&#39;: activ_func = sigmoid elif activation==&#39;elu&#39;: activ_func = elu # Usage model = Sequential(); model.add(Dense(1, input_dim=1, activation=activ_func)) model.compile(optimizer=Adam(lr=lr), loss=&#39;mean_squared_error&#39;) return model . # Definir entrada e saida x = np.arange(sum(primeiro_caso_filtro)).reshape(-1,1) y = brasil[primeiro_caso_filtro][&#39;Confirmados Cumulativo&#39;].values . # Preparar dados def preparar_dados(x, y): x_mean = x.mean() x_std = x.std() y_mean = y.mean() y_std = y.std() x_prep = (x-x_mean)/x_std y_prep = (y-y_mean)/y_std return x_prep, y_prep x_prep, y_prep = preparar_dados(x, y) . #hide_output model = get_keras_model(lr=0.1) model.fit(x_prep, y_prep, epochs=100, verbose=0); . from sklearn.metrics import r2_score . def projetar_keras(model, x, y, days_ahead=0, plot=True, model_func=&quot;exponencial&quot;, tipo=&#39;caso&#39;, exibir_pontos=False, anotar_dados_reais=True, dados_reais_step=2): title = f&#39;Projeção {model_func} de {tipo}s de Covid-19 no Brasil&#39; + f&#39; para os próximos {days_ahead} dias&#39; hoje = date.today() hoje = hoje.strftime(&quot;%d/%m&quot;) x_mean = x.mean() x_std = x.std() y_mean = y.mean() y_std = y.std() n_days = len(x) x_proj = np.arange(n_days+days_ahead).reshape(-1,1) x_prep = (x_proj-x_mean)/x_std y_prep = (y-y_mean)/y_std y_pred = model.predict(x_prep) y_pred = y_pred*y_std + y_mean #Reverse y_pred back y_pred = y_pred.astype(int) y_pred = np.clip(y_pred, 0, None) y_pred = y_pred.squeeze() #print(y) #print(y_pred) r2 = r2_score(y, y_pred[:-days_ahead]) if plot: fig = plt.figure(figsize=FIGSIZE) # Plotar projeção plt.plot(x_proj[-days_ahead-1:], y_pred[-days_ahead-1:], &#39;-&#39;, color=&#39;red&#39;, label=&#39;Projeção&#39;) # Plotar função if exibir_pontos: plt.plot(x_proj[:-days_ahead], y_pred[:-days_ahead], &#39;-&#39;, color=&#39;red&#39;, label=f&#39;Ajuste {model_func} (R²={r2:.3f})&#39;, alpha=0.4) #plt.scatter(x, y, label=&#39;Dados reais&#39;, color=&#39;orange&#39;) plt.plot(y, &#39;.&#39;, label=&#39;Dados reais&#39;) plt.title(title) for x_anot, y_anot in zip(x_proj[-days_ahead:], y_pred[-days_ahead:]): plt.annotate(y_anot, (x_anot, y_anot), ha=&#39;right&#39;, color=&#39;red&#39;) plt.annotate(f&#39;({hoje}): {y[-1]}&#39;, (x[-1], y[-1]), ha=&#39;right&#39;, color=&#39;black&#39;, textcoords=&quot;offset points&quot;, xytext=(-5,0)) if anotar_dados_reais: for x_anot, y_anot in zip(x[:-1:dados_reais_step], y[:-1:dados_reais_step]): plt.annotate(y_anot, (x_anot, y_anot), ha=&#39;right&#39;, color=&#39;midnightblue&#39;, textcoords=&quot;offset points&quot;, xytext=(-5,3) ) plt.grid(color=&#39;black&#39;, linestyle=&#39;--&#39;, linewidth=0.17) plt.legend() plt.xlabel(f&quot;Dias desde o primeiro {tipo} no Brasil&quot;) plt.ylabel(f&#39;{tipo.capitalize()}s confirmados acumulados&#39;) plt.xticks(x_proj[::2]) plt.show() return y_pred, fig . y_pred, fig = projetar_keras(model, x, y, days_ahead=7, exibir_pontos=True, anotar_dados_reais=False, dados_reais_step=3) . Por curiosidade, vamos testar ajustar um sigmóide: . #hide_output model = get_keras_model(lr=1, activation=&#39;sigm&#39;) model.fit(x_prep, y_prep, epochs=100, verbose=0); . y_pred, fig = projetar_keras(model, x, y, days_ahead=5, model_func=&#39;sigmóide&#39;, exibir_pontos=True) . Bem distante do esperado :) Vamos testar também o ELU: . #hide_output model = get_keras_model(lr=0.1, activation=&#39;elu&#39;) model.fit(x_prep, y_prep, epochs=100, verbose=0); . y_pred, fig = projetar_keras(model, x, y, days_ahead=7, model_func=&quot;ELU (Exp. Linear Unit)&quot;, exibir_pontos=True) . Um pouco melhor, mas neste caso com tendência linear. Vamos também replicar estes dois últimos para o número de óbitos. . # Definir entrada e saida x = np.arange(sum(primeiro_obito_filtro)).reshape(-1,1) y = brasil[primeiro_obito_filtro][&#39;Mortes Cumulativa&#39;].values x_prep, y_prep = preparar_dados(x, y) . #hide_output model = get_keras_model(lr=0.1, activation=&#39;exp&#39;) model.fit(x_prep, y_prep, epochs=100, verbose=0); . y_pred, fig = projetar_keras(model, x, y, days_ahead=7, model_func=&quot;exponencial&quot;, tipo=&#39;obito&#39;, exibir_pontos=True, anotar_dados_reais=False, dados_reais_step=3) . #hide_output model = get_keras_model(lr=0.1, activation=&#39;elu&#39;) model.fit(x_prep, y_prep, epochs=100, verbose=0); . y_pred, fig = projetar_keras(model, x, y, days_ahead=7, model_func=&quot;ELU (Exp. Linear Unit)&quot;, tipo=&#39;obito&#39;, exibir_pontos=True) .",
            "url": "https://covid19graficos.github.io/relatorio/coronavirus/2020/05/08/projecao-brasil.html",
            "relUrl": "/coronavirus/2020/05/08/projecao-brasil.html",
            "date": " • May 8, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Sobre este website . Este website foi criado utilizando fastpages no qual permite a conversão automática de arquivos do Jupyter notebook em páginas da web. Temos o objetivo de tornar análises comparativas do Brasil com o resto do mundo de maneira à melhor informar a população. Sugestões de relatórios podem ser submetidas em nosso repositório. . Desenvolvedores . Vinicius Bastos Gomes Linkedin: https://www.linkedin.com/in/vinicius-gomes-phd-490557163/ | Github: https://github.com/ViniciusBG | . | Fernando Marcos Wittmann LinkedIn: https://www.linkedin.com/in/fernandowittmann/ | GitHub: https://github.com/WittmannF | . | . Fontes . John Hopkins University: https://github.com/CSSEGISandData/COVID-19 | Brasil.io: https://brasil.io/dataset/covid19/boletim | Ministério da Saúde: https://covid.saude.gov.br/ | . As fontes de cada relatório podem também ser conferidas em nossos notebooks. .",
          "url": "https://covid19graficos.github.io/relatorio/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}